1
00:00:00,160 --> 00:00:05,195
In the last section, we saw how our DNN was able to model time-series data,

2
00:00:05,195 --> 00:00:08,185
and I told you that we could still improve upon its performance.

3
00:00:08,185 --> 00:00:10,455
In this section, we'll try to do just that.

4
00:00:10,455 --> 00:00:11,855
But in order to do so,

5
00:00:11,855 --> 00:00:13,815
we actually need to go backwards a bit.

6
00:00:13,815 --> 00:00:18,420
Earlier, I asked you to start thinking about what images and sequences have in common.

7
00:00:18,420 --> 00:00:20,455
Did you come up with anything?

8
00:00:20,455 --> 00:00:23,360
Think again about exponential smoothing models

9
00:00:23,360 --> 00:00:26,240
and what inspired us to constrain the weight values.

10
00:00:26,240 --> 00:00:29,390
The intuition was that more recent observations played

11
00:00:29,390 --> 00:00:33,810
a greater role in determining what happens at time t than less recent observations.

12
00:00:33,810 --> 00:00:35,970
To put it another way,

13
00:00:35,970 --> 00:00:39,020
just as locality played a role in the image domain,

14
00:00:39,020 --> 00:00:43,165
where pixels in the neighborhood of a given pixel were much more likely to be related,

15
00:00:43,165 --> 00:00:46,475
so too does locality play a role in sequence modeling.

16
00:00:46,475 --> 00:00:50,630
To see what I mean, consider how convolution could work in one dimension.

17
00:00:50,630 --> 00:00:53,085
Let's say that we have this sequence,

18
00:00:53,085 --> 00:00:55,655
and let's say that our task is to detect

19
00:00:55,655 --> 00:00:59,170
anomalies like the one that occurs at t equals 4.

20
00:00:59,170 --> 00:01:03,645
Which convolution filters would be highly active at t equals 4?

21
00:01:03,645 --> 00:01:06,320
To figure out how active a filter is,

22
00:01:06,320 --> 00:01:08,960
slide it across the sequence and compute the product of

23
00:01:08,960 --> 00:01:13,745
the filter times the elements within the current window and then add the result.

24
00:01:13,745 --> 00:01:17,360
The answer is the 33, negative 67,

25
00:01:17,360 --> 00:01:19,800
33 filter, and the 1.2,

26
00:01:19,800 --> 00:01:23,320
1.0, negative 0.75, 1.0 filters.

27
00:01:23,320 --> 00:01:27,455
Here's the result of applying a filter to the raw sequence data.

28
00:01:27,455 --> 00:01:32,255
Note how it spikes when the raw data matches the pattern in the filter.

29
00:01:32,255 --> 00:01:34,085
Now, of those that were active,

30
00:01:34,085 --> 00:01:35,955
which is more specific?

31
00:01:35,955 --> 00:01:39,070
The filter that begins with 1.2 is.

32
00:01:39,070 --> 00:01:43,040
The reason this filter is more specific is because it's longer.

33
00:01:43,040 --> 00:01:46,190
To understand how length is analogous to specificity,

34
00:01:46,190 --> 00:01:48,940
think back to the last course on image models.

35
00:01:48,940 --> 00:01:52,430
In the last course, we saw how CNNs learn a hierarchy of

36
00:01:52,430 --> 00:01:55,985
features that grow more specific as we progress through the network.

37
00:01:55,985 --> 00:02:00,465
Whereas earlier layers will be most active for simple highly local patterns,

38
00:02:00,465 --> 00:02:04,890
later layers would respond to more complicated things like parts of faces.

39
00:02:04,890 --> 00:02:07,515
If you think about these more complicated patterns,

40
00:02:07,515 --> 00:02:09,065
they were also bigger.

41
00:02:09,065 --> 00:02:11,685
The same thing applies in this context.

42
00:02:11,685 --> 00:02:15,049
So, what if instead of a single drop anomaly detector,

43
00:02:15,049 --> 00:02:18,555
we wanted to detect when there were two drops in quick succession?

44
00:02:18,555 --> 00:02:21,575
One approach we could take is to use a longer filter.

45
00:02:21,575 --> 00:02:24,480
Another, is to use additional layers.

46
00:02:24,480 --> 00:02:28,460
To apply convolution in one dimension requires five steps.

47
00:02:28,460 --> 00:02:30,775
First, flatten the input sequence.

48
00:02:30,775 --> 00:02:35,595
Then, use conv1d to apply a number of filters to the sequence.

49
00:02:35,595 --> 00:02:39,965
Then, use max_pooling to add some spatial invariance and down scaling.

50
00:02:39,965 --> 00:02:43,830
Then, flatten the resulting output into a sequence,

51
00:02:43,830 --> 00:02:48,055
and then send it through a fully connected layer with the appropriate output node.

52
00:02:48,055 --> 00:02:50,760
Let's see how we accomplish that encode.

53
00:02:50,760 --> 00:02:55,235
First, we reshape the inputs to be batch size by n inputs by 1.

54
00:02:55,235 --> 00:03:00,100
This is because the conv1d function requires a 3D tensor.

55
00:03:00,100 --> 00:03:01,785
For the number of filters,

56
00:03:01,785 --> 00:03:04,310
I chose to use half the number of inputs.

57
00:03:04,310 --> 00:03:07,430
We want to avoid overfitting by introducing too many filters.

58
00:03:07,430 --> 00:03:11,945
But as you know, the number of filters is something you could hyperparameterize.

59
00:03:11,945 --> 00:03:14,630
We then pass the convolved tensor through

60
00:03:14,630 --> 00:03:19,575
a max pooling layer to add some spatial invariance and to reduce the size of the tensor.

61
00:03:19,575 --> 00:03:23,390
Finally, we remove the inner dimension we added to accommodate

62
00:03:23,390 --> 00:03:26,210
the conv1d function and pass the tensor through

63
00:03:26,210 --> 00:03:29,825
a dense layer and a final linear prediction layer.

64
00:03:29,825 --> 00:03:35,320
Now, it's your turn. Let's apply a CNN to time-series data and see how it does.