Welcome to the first lab in the sequence models course. Our first lab is going to be using a linear model to predict time series data. Over the next series of labs, we're going to be continued to return in this particular notebook because it refers to all the models we'll be creating. You'll notice at the top, we have linear, DNN, CNN, and RNN. Eventually, we'll get to all of these and you'll have an easy way of comparing how each of these model types does in the same set of data. The first two cells allow the code to know what our particular account and project are so that we can actually run jobs on Cloud ML Engine. The next bit of code is code that we've already seen in lecture, it's used to create our synthetic data. Our synthetic data is going to be a bunch of randomly generated sine waves, and the random generation comes with respect to the frequency which we're generating here to be between 0.1 and 0.6. The amplitude which we're generating here to be between 0.5 and 1.5, and then a little bit of noise. What this function does is that it generates a certain number of observations. In this case, from zero to sequence length, where sequence length is set at the top to be 50. So, 50 observations of the sine wave that's parameterized by the frequency and amplitude that we've randomly generated. So, if we were to iterate over the number zero to five and call this function five times and then plot the results, we might have something like this. We have five different sine waves each with their own different characteristics. Some of them have a greater frequency and they oscillate more quickly, some have bigger amplitude and they oscillate over a greater range and all of them have little bits of random noise spiked in. Then we're going to use the two CSV function to write that data to disk in the form of two CSV files. We're going to have a training CSV and a validation CSV. With the training, CSV contains 1,000 lines, and the validation CSV contains 250. Each line in this file is going to be a comma delimited sets of floats where the number of floats and unusual line is going to be 50. So, if we take a peek at all the CSV files on disk and we print the first five lines, you'll notice that they conform to that expectation. So, each line is going to be a bunch of different floats and they're separated by commas. So now, we're at the actual tasks for the things that you need to do, and our task is going to be fill out model.py, so that the linear model can make a prediction. Once we've done that, we'll be able to execute this code block, and you'll notice that this basically called the gcloud ml-engine the local train. So, we're training a local model here. We've passed in the model parameter as linear. What we've done in task.py is to write code that is repurposable to call any sort of model that you might want. So by passing in the linear parameter, we're telling it, we'd like it to invoke the linear model function. Now, if you change this to something else, let's say DNN, then your code will try to cut to invoke the DNN function. That's fine if you've implemented DNN model but we haven't yet, so don't do that. Let's take a peek inside model.py. The first thing I want to call out is this constant at the top which is called time series column. Time series column is the key that we're going to be using to retrieve from our features dictionary. Because remember, our features dictionary is a set of key value pairs where the keys are allow us to retrieve the values which are tensors. The function that we're responsible for implementing is the linear model function. Each of these functions; linear model, DNN model, CNN model, all of them are simply responsible for making a prediction using the type of model that specified in their name. So now, were inside model.py. What I'd like to do is to give you a high-level sense of the code before diving into the details of what you need to do. The largest function at the top is the train_and_evaluate function. This won't change regardless of whether we're going to be calling a DNN or a CNN or an RNN later on. Essentially, the way this function works is that it defines a custom estimator using the sequence_regressor function. So, let's take a look at what that function does. The sequence_regressor function maintains a dictionary, and the dictionary here maps a key to another function which is either linear model, DNN model, et cetera. What happens is that we have specified the right key in our command line parameters which we showed you in the previous slide. So what that does is it looks for the command line parameter in order to retrieve the appropriate function to run. The rest of the code here should be pretty familiar to you. We've done it many times when we created estimators in the past. The one thing it's different is that we've introduced a new eval_metric_op called RMSE_same_as_last. When you train your model, this RMSE_same_as_last will allow you to compare the model you train against a very simple benchmark that simply uses the observation from the previous point in time to compare against. In this case, you can expect that the key here will be linear because we're trying to train a linear model. So model function will retrieve the linear model function. Model function here will retrieve the linear model function. So let's take a look now at what linear model does. Linear model as well as the other model functions like it, all except features, mode, and params because remember, these are model functions. Their responsibility is to take these features and then to return a prediction. In the case of a linear model, the implementation is really quite simple. We get the prediction simply by calling tf.layers.dense which is a dense layer. But unlike in a neural network where we would send an activation function, here, we're not using an activation function at all because it's simply a linear combination of our inputs, and so we're going to return that prediction. Once we've done that, we can then train our model which we can do by running the cell where we have the gcloud ml-engine local train, and you should get output that looks like this. Eventually, you'll have a saved model written to disk. After we've done that, we can then click train in Cloud ML Engine which I'm not going to do right now. But I'll explain to you a little bit about how the code works. Essentially, the only thing that's different is that we're going to generate more data first and then we're going to push that data to our Cloud storage bucket before initiating our Cloud ML Engine job. So, this is simply an iterative loop over the number zero to 10, each time we're creating a new slice of training and validation data. Then finally, we're going to copy that data to the Cloud, before finally initiating a Cloud ML Engine training job. Now, notice here that this code for initiating a Cloud ML Engine training job, iterates over all possible models; linear, DNN, CNN, RNN, et cetera. If you try to execute this before you've actually completed, those other functions which by the way we'll be doing in later labs, you'll get some errors. So, don't do that yet. However, if you want to get a peek and soon start running a Cloud ML Engine job now, you can, simply by removing these other values from this iteration. After you train your model, you can start up TensorBoard to see how it's doing or I should say while your model is training you can do that. Eventually, your model will stop training after 3,000 steps and you can see it's root mean square error. In this case, this is the root mean square error I got after training my linear model for 3,000 steps