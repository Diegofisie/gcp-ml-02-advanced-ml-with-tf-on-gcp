Welcome to the second lab, where we're going to train a DNN to learn our sinusoidal data from the previous lab. In the previous lab, we went over how the create time series function randomly generates a frequency and amplitude and a noise to return 50 observations from random sine function. We then wrote those files to disk and we trained the model using G-Cloud local ML Engine. Critically, we passed in a model parameter that determine which model function was called. In this lab, instead of the linear value here, we're going to change this to DNN and this will ensure that when the code actually executes it it's using our DNN model and not our linear model function. The tasks that you have to complete are all inside the model.py. So let's take a look there next. Your model.py should look like this and remember each of these model functions will get a bunch of features and its responsibility will be to return the predictions using those features. In the case of a DNN, our DNN looks very similar to the way our linear model looks but instead of a linear combination of its inputs, we're now going to do a non-linear combination of those inputs. What that looks like in code is something like this. So here for example I've taken our input X, that's the result of calling our features dictionary retrieving the time series column and then I've added two hidden layers. The first one gets X as input and then maps to 10 nodes and calls the relu activation function. The second one gets h1 as input and maps to three nodes. It's also dense and also uses the relu function and then finally we have the prediction layer and the prediction layer has only one output and it only uses the linear combination of its inputs and we return that predictions. After you've done that, you should be able to run this particular code block without any errors. Of course if you want to, you're going to initialize a Cloud ML Engine training job. In order to do that, you would once again have to change what we're iterating over in this final block over here and since theoretically you've also already implemented linear model, you can have it iterated over linear and DNN. When I train this model, I got slightly better performance on my DNN that I do by linear. The RMSE dropped from 0.15 to 0.101.