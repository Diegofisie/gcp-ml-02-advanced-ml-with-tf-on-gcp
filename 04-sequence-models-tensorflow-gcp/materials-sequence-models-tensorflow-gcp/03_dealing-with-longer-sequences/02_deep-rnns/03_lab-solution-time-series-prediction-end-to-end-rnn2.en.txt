In this lab, we'll expand our RNN model from one layer to two. Let's jump right into the model.py and locate the rnn2_model function. Once again, our input tensor is already provided to us in the correct shape. Now, instead of coding this from scratch, let's copy down the code from our RNN model and modify from there. We already have one cell, so let's create a second. We'll rename our first cell as cell1, and then add a second cell called cell2. Now, we can set the internal size of our second cell independently from the first. Let's try making the first cell larger, and the second cell smaller. You can experiment with different cell sizes to see how it impacts performance. Now that we have our cells defined, we need to create a multi-RNN cell object with it. Our multi-RNN cell takes a list of cells, cell1 and cell2, as its input. Our dynamic RNN instantiation is as before, except we pass in the multi-cell object by referring to the cells variable we just created. The rest of our code is the same with the exception of one small but important change. Since we now have two RNN cells, the state object returned by the dynamic RNN is no longer just a single vector but a list of two vectors corresponding to the final state of each of the two cells. We just want the last state vector in the list to pass on to our DNA, because it already takes into account the state from the previous layer. To extract this, we add a square bracket one to the list of states, which extracts only the second state. That's it, now we save our model.p y, and switch back to our notebook to confirm our code works. Be sure to change your dash dash model parameter to rnn2, so that we're calling the function we just created. Great, our code is working, up until now we've only been running for 10 steps and unlimited amount of data. Now let's generate some more data, and run for a longer period using Cloud Machine Learning Engine. This first cell generates 10 training files, and 10 validation files. Each training file contains 1,000 sequences for a total of 10,000 training sequences, and each validation file contains 250 sequences for a total of 2,500 validation sequences. Now that our data is created, this next cell copies it to the cloud using gsutil, so that our Cloud Machine Learning Engine job can access it. Finally, we're ready to run our training job. Note that we're kicking off not one, but six training jobs, as you can see here, one for each model type. This is one of the great advantages of using cloud machine learning engine, we can run multiple trials in parallel. Also note, that we're now training and for 3,000 steps, instead of just 10. Once you've kicked off your jobs, switchover to Cloud console, and click on the Cloud Machine Learning Engine job, to verify your jobs have started. It will take about 15 minutes for all the jobs to complete. Once the job's complete there are two ways you can check the results. The first is by checking the cloud logs directly. To do this, I click on the View logs "button" next to the job. Then I can filter the logs by a search term, in this case I look for our evaluation metric RMSE. Depending on how recently you run the job, you may need to click the Load older logs "button". Looks like our RMSE for this job was 0.099. While looking at the logs will get the job done, it's a bit onerous to repeat this process for all six trials. A better way is to look at Tensor Board, and then we can compare all six results at once. Here, I have the tensor board results for a job I ran earlier, because all my trial share the same parent output directory, I can see the results side-by-side here. To do so, I will hover over the RMSE graph, and a dialog box with the RMSE values for each trial will pop up. Smoothing is turned on by default. So, make sure you're reading the actual values which are to the right of the smooth values. A few things stand out to me here, the first is that one model type performed significantly worse than all the others. Unsurprisingly, that is our simple linear model. After that the performance of all the other models is pretty similar. However, the best performing one something called RNN, with an RMSE of 0.095. We'll talk about what that model is, and why it may perform best next.