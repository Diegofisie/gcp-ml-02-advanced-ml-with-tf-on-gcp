Hi there, my name is Vijay, and I'm a Machine Learning Solutions Engineer at Google. In the last module, you got an introduction to RNNs. In this module, we'll dive deeper into that topic. We'll talk about LSTMs, deep RNNs, working with real data and more. Let's start by talking about the shortcoming of RNNs. At least the type of RNNs we've discussed to this point. The problem is long sequences. Recall that RNNs only consists of a single cell with a single set of weights. At each new time-step, we feed a new set of features, x, and a new hidden state, h, into the cell. To make that process easier to visualize and reason about, we usually depict RNNs in an unrolled format. The diagram on the left and the right are just two representations of the same thing. We call the total number of times need to feed features back into the RNN cell your max sequence length. In this diagram, the max sequence length is three. Now let's take a real world example, let's say I want to build a model to predict the next word in a sentence given its previous words. If the previous words were "Michael C was born in Paris France, his mother tongue is?" Fill in the blank, you could guess that the next word should be French. But how would an RNN learn this. An RNN can only learn dependencies and data up to its max sequence length. You could argue that a max sequence length of five would work here because counting five words back from the label French would get you to the context word France. But just to be safe, let's say we want to be able to read in the whole sentence. That would mean our max sequence length would need to be 11. Now, what if our training examples were more like this. In this case, for the RNN to learn the relevant context to predict the label, it would need a much much longer max sequence length. The relevant context is all the way at the beginning of the sequence so a max sequence length of 80 would be necessary to learn this. However, an RNN that you unroll across 80 time steps is very similar to an 80 layer deep neural network and therein lies the problem. Remember when we talked about the vanishing gradient problem in the course on image models? It's the idea that the more layers a model has to backpropagate through, the smaller the gradient gets. This results in weights in the earlier layers of the network having very little effect on the output. The solution researchers found this problem is called LSTM which stands for Long Short-Term Memory.