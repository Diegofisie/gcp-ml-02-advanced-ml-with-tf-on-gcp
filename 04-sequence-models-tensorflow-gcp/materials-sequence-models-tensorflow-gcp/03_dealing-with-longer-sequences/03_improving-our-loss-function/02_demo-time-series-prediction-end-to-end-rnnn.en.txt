The code for the rnnN_model, is already implemented for you. But we'll walk through how to build it here. Once again, let's start from our previous model, rnn2, and modify it from there. Now, the main modification we're going to make here, is instead of returning just one prediction using the final hidden state, we're going to generate a prediction from every intermediate hidden state as well. Multiple predictions allow us to calculate multiple losses, and then take the average. To do this, we now take advantage of the outputs tensor return by our dynamic rnn. Recall that outputs contains, not just the final hidden state, but the hidden state at every time step. So now, instead of having just one state vector, we have 49. We want to generate a prediction for every one of these 49 hidden states. So, we'll feed the outputs tensor as our input to the dense layer, whereas, previously we fed in the state tensor. Effectively, we're creating 49 equivalent DNNs. Each one takes in a state vector and outputs a single prediction. Finally, we flatten this from a 49 by one tensor, into a single vector that contains 49 predictions and return this. Now at this point, you may be thinking, why are we returning 49 predictions? Don't we just want to compute loss on the last k state vectors, as we talked about before. Well, you're right, but we handle that in a separate part of the code. Specifically, the compute errors function below. Here is where we distinguish between our regular loss function and our rnnN loss function. In the regular case, where we just return one prediction, we simply compute the loss on that single prediction. However, if we return multiple predictions, then we implement our loss averaging code. Now to calculate loss over multiple predictions, you need a label for each of those predictions. Our input function only provides a label for the final prediction. So, we can calculate the remaining labels here. Since our label is actually just our input features shifted one time step ahead, we can generate a labels tensor by extracting from the features tensor, starting one position forward. We do that using slicing notation. Next, is where we determine what portion of the predictions we want to calculate loss over. This determination is a hyperparameter that you can experiment with. But here we chose to use the last third. Finally, we use the tf.losses.mean_squared_error function and pass in our labels tensor and our predictions tensor. But slice to just the last third of the values, because those are the only ones we want to consider in our loss function. It's important to note here, that customizing our loss function doesn't affect how we calculate our evaluation metric. When calculating rmse, we still only consider loss on the single last prediction, because that's ultimately what we care about for our model. Averaging our loss over multiple predictions, is just a more efficient way to optimize to that goal.