1
00:00:00,620 --> 00:00:04,080
Welcome to the lab, where we're going to use TensorFlow Hub

2
00:00:04,080 --> 00:00:06,630
to download and use some pretrained embeddings,

3
00:00:06,630 --> 00:00:09,075
and then assess the quality of those embeddings.

4
00:00:09,075 --> 00:00:13,030
This lab illustrates how to instantiate a TensorFlow Hub module,

5
00:00:13,030 --> 00:00:16,710
how to find pre-trained TensorFlow Hub modules for a variety of purposes,

6
00:00:16,710 --> 00:00:18,960
how to examine the quality of those embeddings,

7
00:00:18,960 --> 00:00:21,120
how one takes the representation of

8
00:00:21,120 --> 00:00:24,540
a single word and composes it into be a representation of a sentence,

9
00:00:24,540 --> 00:00:26,880
and then finally how you can assess the quality of

10
00:00:26,880 --> 00:00:29,820
your word embeddings using a more formal test.

11
00:00:30,020 --> 00:00:32,295
In the beginning parts of this code,

12
00:00:32,295 --> 00:00:35,160
we install the TensorFlow Hub library.

13
00:00:35,160 --> 00:00:37,035
As we talked about in lecture,

14
00:00:37,035 --> 00:00:40,625
the first thing you need to know about TensorFlow Hub is this concept of a module.

15
00:00:40,625 --> 00:00:44,000
A module is a reusable part of TensorFlow graph,

16
00:00:44,000 --> 00:00:46,250
and because it's a part of a TensorFlow graph,

17
00:00:46,250 --> 00:00:48,500
in order to actually get some value out of it,

18
00:00:48,500 --> 00:00:50,720
in order to see the results of your embeddings,

19
00:00:50,720 --> 00:00:53,845
you need to execute it in the context of a session in a graph,

20
00:00:53,845 --> 00:00:56,110
but executing is actually really easy.

21
00:00:56,110 --> 00:00:58,140
So, here's some sort of pseudo code.

22
00:00:58,140 --> 00:01:00,905
In order to download a module and use it,

23
00:01:00,905 --> 00:01:03,855
first we create a path to a hub module.

24
00:01:03,855 --> 00:01:06,995
We'll figure out what the appropriate value for this is in a second.

25
00:01:06,995 --> 00:01:09,800
We pass that to the constructor, so hub.module,

26
00:01:09,800 --> 00:01:11,660
we pass in our module url,

27
00:01:11,660 --> 00:01:13,460
and now we have this function called embed,

28
00:01:13,460 --> 00:01:15,110
and calling it as simply as easy

29
00:01:15,110 --> 00:01:18,315
as putting some parenthesis in front and treating it as a function,

30
00:01:18,315 --> 00:01:21,540
and the way you pass in is going to vary from module to module.

31
00:01:21,540 --> 00:01:27,575
In this case, the intention is that is as easy as passing in a list of words.

32
00:01:27,575 --> 00:01:29,610
Once you have the embeddings,

33
00:01:29,610 --> 00:01:33,110
of course you need an actual session to collect the values there.

34
00:01:33,110 --> 00:01:35,000
So, that's what we do later on.

35
00:01:35,000 --> 00:01:36,780
We've created a session,

36
00:01:36,780 --> 00:01:40,885
we initialize our variables and then we simply run the embeddings tensor,

37
00:01:40,885 --> 00:01:43,600
and that will then print the values.

38
00:01:43,730 --> 00:01:47,330
So, the first thing we need to do is explore on the documentation page a

39
00:01:47,330 --> 00:01:50,885
little bit and see what hub modules there are.

40
00:01:50,885 --> 00:01:55,590
You'll notice that the hub modules are aligned by specific input domains.

41
00:01:55,590 --> 00:01:59,980
So, there's an M1 for some for images some protects and some for other modules entirely.

42
00:01:59,980 --> 00:02:01,785
In our case we're working with texts,

43
00:02:01,785 --> 00:02:03,680
so you can browse this page right here,

44
00:02:03,680 --> 00:02:06,360
and you'll notice that it's organized by the different types of models,

45
00:02:06,360 --> 00:02:09,895
and so there's a universal sentence encoder and a bunch of others.

46
00:02:09,895 --> 00:02:12,650
Within each model you can see different options,

47
00:02:12,650 --> 00:02:16,520
in this case the NNLM module,

48
00:02:16,520 --> 00:02:19,405
has versions for all these different languages,

49
00:02:19,405 --> 00:02:21,590
some that are normalized and some that are not,

50
00:02:21,590 --> 00:02:24,750
and some that are 50 dimensions and some that are 128,

51
00:02:24,750 --> 00:02:27,600
and of course there's a quality usefulness trade-off here.

52
00:02:27,600 --> 00:02:28,820
The more dimensions you have,

53
00:02:28,820 --> 00:02:32,085
the more memory your model is going to consume when it's running in the Cloud,

54
00:02:32,085 --> 00:02:35,340
but the higher quality those representations might be.

55
00:02:35,340 --> 00:02:38,330
Now, to collect that module URL that I told you that,

56
00:02:38,330 --> 00:02:41,420
it's as simple as selecting the link address for

57
00:02:41,420 --> 00:02:45,000
the particular link that you want to incorporate.

58
00:02:45,000 --> 00:02:47,480
So, in this case I've copy that link for English,

59
00:02:47,480 --> 00:02:51,080
and I could paste that into this particular embedding,

60
00:02:51,080 --> 00:02:54,540
the constructor here, in order to instantiate the module.

61
00:02:54,540 --> 00:02:58,260
That's exactly what I've done over here.

62
00:02:59,370 --> 00:03:03,255
So, I set the module URL to be the result of copying that link,

63
00:03:03,255 --> 00:03:06,940
and then constructed the module right here,

64
00:03:06,940 --> 00:03:09,655
and I've asked it to make representation for the word cat,

65
00:03:09,655 --> 00:03:12,040
and then I've invoked in the context of a session.

66
00:03:12,040 --> 00:03:14,330
You can see that this monster float right

67
00:03:14,330 --> 00:03:18,385
here is what the module thinks that cat represents.

68
00:03:18,385 --> 00:03:22,810
So that's great, but it's hard to understand anything about a bunch of floats.

69
00:03:22,810 --> 00:03:25,180
What you really need to do is start making comparisons

70
00:03:25,180 --> 00:03:26,920
between those different embeddings and

71
00:03:26,920 --> 00:03:28,855
have a sense that the quality of the representation,

72
00:03:28,855 --> 00:03:32,090
and that's what we're going to do in our informal representation.

73
00:03:32,090 --> 00:03:36,640
So, the next thing I asked you to do is to come up with three words,

74
00:03:36,640 --> 00:03:38,170
such that we assume the words are

75
00:03:38,170 --> 00:03:40,490
similar to each other and one of them's a little bit different.

76
00:03:40,490 --> 00:03:45,255
Now, in my case I chose those words to be cat, dog and potato.

77
00:03:45,255 --> 00:03:47,475
The next thing that we do is,

78
00:03:47,475 --> 00:03:50,220
we look at the embeddings for each of those three words.

79
00:03:50,220 --> 00:03:52,960
So, the process here is the same as we used before.

80
00:03:52,960 --> 00:03:55,270
We're going to have to either construct

81
00:03:55,270 --> 00:03:57,905
knew hub module or use the one we've already created,

82
00:03:57,905 --> 00:04:00,075
and then invoke it in the context of a session,

83
00:04:00,075 --> 00:04:01,700
and that's what I've done here.

84
00:04:01,700 --> 00:04:03,230
In order to make things a little easier though,

85
00:04:03,230 --> 00:04:06,010
I created a custom function called create embeddings,

86
00:04:06,010 --> 00:04:10,220
where a create embeddings accepts a list of words as well as the hub module

87
00:04:10,220 --> 00:04:14,265
that's used for the embedding and then invokes in the context of a session.

88
00:04:14,265 --> 00:04:19,935
It also then prints the representation of that embedding.

89
00:04:19,935 --> 00:04:21,680
It only prints the first few floats

90
00:04:21,680 --> 00:04:24,680
because it's exhausting to look at so many on the screen.

91
00:04:24,790 --> 00:04:27,270
So, in this case you'll see that

92
00:04:27,270 --> 00:04:30,690
the representation for cat begins with these three floats,

93
00:04:30,690 --> 00:04:31,930
for dog, with those three,

94
00:04:31,930 --> 00:04:34,645
and for potato, with the three in the bottom.

95
00:04:34,645 --> 00:04:38,155
The next thing we do is, that we start doing something much more interesting,

96
00:04:38,155 --> 00:04:42,070
which is to compare how similar these representations are.

97
00:04:42,070 --> 00:04:46,490
To do that, we are going to make use of a heatmap.

98
00:04:46,490 --> 00:04:50,330
Your task in this case was to figure out how to determine

99
00:04:50,330 --> 00:04:55,510
the correlation between the vector representations for each of these three words.

100
00:04:55,510 --> 00:04:58,390
There are many different ways of comparing vectors.

101
00:04:58,390 --> 00:05:02,695
In this case, you could have for instance compute the Euclidean distance between them,

102
00:05:02,695 --> 00:05:05,150
but what I'd like you to do is to compute what's equivalent to

103
00:05:05,150 --> 00:05:10,210
cosine similarity and look at the inner product of these tensors.

104
00:05:10,210 --> 00:05:14,790
So, that's what I've done here. I've simply passed in,

105
00:05:14,790 --> 00:05:18,260
I called the np.inner function and I passed in embeddings twice.

106
00:05:18,260 --> 00:05:20,930
That's because we're going to compute the inner product

107
00:05:20,930 --> 00:05:24,385
of all of the different vectors with each other.

108
00:05:24,385 --> 00:05:26,720
When you think about it what a heatmap is,

109
00:05:26,720 --> 00:05:27,820
it makes sense why we're doing this,

110
00:05:27,820 --> 00:05:29,990
because we're going to look at the similarity of

111
00:05:29,990 --> 00:05:33,140
things to themselves as well as things to other things.

112
00:05:33,140 --> 00:05:35,845
Then I simply use the seaborne heatmap function,

113
00:05:35,845 --> 00:05:39,740
with the correlations and some parameters through to make it visually more interesting,

114
00:05:39,740 --> 00:05:43,245
and the result is you should get something like this.

115
00:05:43,245 --> 00:05:46,700
Of course the most striking part is that everything is identical to itself.

116
00:05:46,700 --> 00:05:47,975
That's not so surprising,

117
00:05:47,975 --> 00:05:51,230
but the really cool thing is that you'll notice that cat is far

118
00:05:51,230 --> 00:05:55,355
more similar to dog because it's much redder here than it is to potato.

119
00:05:55,355 --> 00:06:00,100
We got all that, just all we need to do is invoke a TensorFlow Hub module.

120
00:06:00,100 --> 00:06:02,430
So, how would you take those representations of

121
00:06:02,430 --> 00:06:05,440
individual words and compose them into representations of sentences?

122
00:06:05,440 --> 00:06:07,890
It was actually really quite easy.

123
00:06:07,890 --> 00:06:10,970
All you have to do in the case of the particular module that

124
00:06:10,970 --> 00:06:13,675
we're using is instead of passing in a single word,

125
00:06:13,675 --> 00:06:16,140
is to pass an entire sentence.

126
00:06:16,140 --> 00:06:18,550
The reason you'll know this is,

127
00:06:18,550 --> 00:06:21,240
if you actually take a look at the module,

128
00:06:22,240 --> 00:06:28,825
you'll see that it can accept as input a spaced limited set of words,

129
00:06:28,825 --> 00:06:30,290
and you'll see here in the input it says,

130
00:06:30,290 --> 00:06:33,050
the module takes a batch of sentences in 1-D tensor of strings as

131
00:06:33,050 --> 00:06:37,860
input and then furthermore the pre-processing splits by spaces.

132
00:06:41,030 --> 00:06:46,830
So, what I've done here is I've come up with a couple different sentences.

133
00:06:46,830 --> 00:06:49,140
Cat, the cat sat on the mat.

134
00:06:49,140 --> 00:06:51,035
Dog, and the cat sat on the dog,

135
00:06:51,035 --> 00:06:52,960
and I've created embeddings for all those,

136
00:06:52,960 --> 00:06:55,985
and then I've done just as before I plotted their similarity.

137
00:06:55,985 --> 00:06:58,805
The reason I picked these sentences is because,

138
00:06:58,805 --> 00:07:02,840
what's interesting about this model is how it takes the representations of

139
00:07:02,840 --> 00:07:07,485
the individual words and composes it when you have a bunch of words in a sentence,

140
00:07:07,485 --> 00:07:11,420
and the really surprising thing is that you'll notice that cat is

141
00:07:11,420 --> 00:07:14,920
actually more similar to dog than it is to the sentence,

142
00:07:14,920 --> 00:07:18,540
the cat sat on the mat, and that's strikingly wrong.

143
00:07:18,540 --> 00:07:21,740
You'd think that any subject that featuring the cat as the subject. I'm sorry.

144
00:07:21,740 --> 00:07:23,990
Any sentence featuring the cat as a subject will be more

145
00:07:23,990 --> 00:07:27,470
similar to the idea of cat than cat would be to dog.

146
00:07:27,470 --> 00:07:31,760
The reason for this is because if you look inside the TensorFlow Hub module,

147
00:07:31,760 --> 00:07:33,785
you'll notice that the way these are

148
00:07:33,785 --> 00:07:36,575
composed together is by using a square root combiner.

149
00:07:36,575 --> 00:07:39,740
Which basically means we're using a deterministic procedure,

150
00:07:39,740 --> 00:07:44,195
independent of the number of things that we're trying to combine to put them together.

151
00:07:44,195 --> 00:07:48,110
In other words, it is not all as nuances as the RNNs that we've created in

152
00:07:48,110 --> 00:07:50,720
previous modules which are designed to

153
00:07:50,720 --> 00:07:53,990
handle these nuanced relationships of information over time.

154
00:07:53,990 --> 00:07:56,900
However, they're great as a simple way of

155
00:07:56,900 --> 00:08:00,045
combining a bunch of different representations together.

156
00:08:00,045 --> 00:08:02,160
All right. So this is all well and good.

157
00:08:02,160 --> 00:08:03,490
We've had this informal comparison.

158
00:08:03,490 --> 00:08:07,975
We've seen the limitations of this naive method of composing representations together.

159
00:08:07,975 --> 00:08:10,170
What if we want to do a more formal evaluation?

160
00:08:10,170 --> 00:08:13,725
Well, thankfully we're not the first set of people to wonder about this sort of thing.

161
00:08:13,725 --> 00:08:16,010
Computational linguists have been doing this for a long time

162
00:08:16,010 --> 00:08:19,095
and they've come up with a number of different benchmarks.

163
00:08:19,095 --> 00:08:21,380
In this cases, benchmark is derived from

164
00:08:21,380 --> 00:08:24,740
human subjects rating the similarity of different word pairs,

165
00:08:24,740 --> 00:08:27,050
and you can assess the degree to which the similarity that

166
00:08:27,050 --> 00:08:29,665
human beings think given pair of words have,

167
00:08:29,665 --> 00:08:33,970
with the similarities of these two vectors have in our embedding space.

168
00:08:33,970 --> 00:08:40,010
In this particular section, we download the Python DataFrame of the sentence pairs,

169
00:08:40,010 --> 00:08:43,220
and so you'll see for a given row in this DataFrame we have two sentences,

170
00:08:43,220 --> 00:08:45,385
in this case a man with a hard hat is dancing,

171
00:08:45,385 --> 00:08:47,315
and a man wearing a hard hat is dancing.

172
00:08:47,315 --> 00:08:48,695
That has perfect similarity.

173
00:08:48,695 --> 00:08:52,105
What if you have, a young child is riding a horse versus a child is riding a horse?

174
00:08:52,105 --> 00:08:55,925
While they have a similarity of 4.75. So it's a little bit lower.

175
00:08:55,925 --> 00:08:59,680
The next thing that we do is we build an evaluation graph.

176
00:08:59,680 --> 00:09:01,984
So, we retrieve the embeddings,

177
00:09:01,984 --> 00:09:04,730
we normalize them and then we compute

178
00:09:04,730 --> 00:09:09,450
the cosine similarity is by using a couple of nested Tensorflow functions right here,

179
00:09:09,450 --> 00:09:12,620
we clip them and then we set the scores to be one

180
00:09:12,620 --> 00:09:16,840
minus the arc cosine of the cosine similarities.

181
00:09:17,350 --> 00:09:20,930
Then after we've done all that we can take

182
00:09:20,930 --> 00:09:23,240
the Pearson correlation coefficient between

183
00:09:23,240 --> 00:09:26,645
the embedding space and the ones that the human subjects generated,

184
00:09:26,645 --> 00:09:28,040
in this case it's 0.51,

185
00:09:28,040 --> 00:09:30,630
indicating a moderate correlation.

186
00:09:30,630 --> 00:09:34,250
The really powerful thing is that you'll notice that the score you

187
00:09:34,250 --> 00:09:37,510
get will depend in part upon which module you choose.

188
00:09:37,510 --> 00:09:42,035
So, you should always be sure to choose the one with its most suited to your task,

189
00:09:42,035 --> 00:09:46,080
and there, of course, are many different modules for you to choose from.

190
00:09:49,250 --> 00:09:52,760
Finally, check out this blog post we have about how

191
00:09:52,760 --> 00:09:56,270
bias can affect texts embeddings. It's definitely worth a read.