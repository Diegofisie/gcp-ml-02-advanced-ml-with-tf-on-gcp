Just as in contextually pre-filtering, the contextual postfiltering algorithm begins with our initial user by item, multidimensional context tensor containing ratings. However, notice here, we are sending our initial data directly to our traditional two-dimensional recommendation system. How can this be? Why did we not apply the contexts filter before the recommender? What happens to all the context dimensions? Well, we simply ignore them. We ignore a context. We process the data as if it was just a user item interaction matrix. This is good in the respect that we can use our traditional collaborative filtering technology, but are the recommendation going to be the same as if we never had the contexts that it to begin with? Let's wait and see to find out. We then apply our users vector to the output embeddings to get the representation in embedding space. This gives us our recommendations. But these are exactly the same as if we never had contexts data because the machine learning, it has such a shame to throughout possibly good data, how do we fix this problem? Well, we can try to adjust our non-contractual recommendations by applying the context back in. As you can see, this happens after the recommender hence it is called the contextual postfiltering. This can be done by filtering out recommendations that don't match the current context, or altering the ranking of the predictions or recommendations returned by the recommender. These adjustments can be determined using either heuristic or model-based approaches. For example, if our user from before still wants to see a movie on Thursday after work and on Thursday they usually watch action movies, our postfiltering can filter out all non-action movies for the recommendations returned by our non-contractual recommender. This then gets us finally to the contextual recommendations that we wanted. Contextual postfiltering has several methods of which weight and filter are the most popular and are based on adjusting the non-contextual recommendations based on the contexts relevance to the user. To find this relevance, the contextual probability is calculated for user I, choosing item J, in context C. This is calculated by dividing the number of users similar to user I who shows the same item J in the same context C by the total number of users similar to user I. The weight method multiplies the non-contextualized ratings by the contextual probability to get the adjusted contextualize ratings. The filter method on the other hand, filters out predicted ratings below a certain threshold value of the conditional probability.