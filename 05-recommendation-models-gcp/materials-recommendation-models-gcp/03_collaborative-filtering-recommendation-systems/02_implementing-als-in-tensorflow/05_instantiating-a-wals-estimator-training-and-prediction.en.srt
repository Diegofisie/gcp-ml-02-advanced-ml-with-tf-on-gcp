1
00:00:00,000 --> 00:00:05,925
Excellent. We have our sparse tensors fixed now after our remap keys function.

2
00:00:05,925 --> 00:00:08,760
There are a few items of business left to take care of before we

3
00:00:08,760 --> 00:00:11,520
are done with our WALSMatrixFactorization input function.

4
00:00:11,520 --> 00:00:16,950
Namely, how many times we should repeat and if we should add additional features.

5
00:00:16,950 --> 00:00:19,920
At the top of our parsed_tfrecords function,

6
00:00:19,920 --> 00:00:22,710
we need to determine the number of epochs we're going to go through,

7
00:00:22,710 --> 00:00:25,755
because we are using num_epochs in dataset.repeat.

8
00:00:25,755 --> 00:00:27,825
As usual, if we are in training,

9
00:00:27,825 --> 00:00:31,064
we want to cycle through the dataset over and over until the estimator,

10
00:00:31,064 --> 00:00:32,970
which is the number of train steps.

11
00:00:32,970 --> 00:00:36,645
For evaluation, we want to run through the dataset only once.

12
00:00:36,645 --> 00:00:39,600
Usually, when we think about recommendation systems,

13
00:00:39,600 --> 00:00:42,120
we think of a model that recommends items to users,

14
00:00:42,120 --> 00:00:43,765
whether that is items to buy,

15
00:00:43,765 --> 00:00:46,130
places to visit, or movies to watch.

16
00:00:46,130 --> 00:00:49,400
But why should we always choose a user and return items?

17
00:00:49,400 --> 00:00:51,720
Couldn't we also provide the transpose since WALS

18
00:00:51,720 --> 00:00:54,755
serves both users and items simultaneously?

19
00:00:54,755 --> 00:00:57,169
We could be developing a targeting model,

20
00:00:57,169 --> 00:01:00,560
in such models we might be trying to decide which users to send coupons

21
00:01:00,560 --> 00:01:04,270
for an item to or who bust a call for pulling, et cetera.

22
00:01:04,270 --> 00:01:06,590
To flip our recommendations from users to items,

23
00:01:06,590 --> 00:01:08,480
we can add a feature to our input functions

24
00:01:08,480 --> 00:01:12,920
feature dictionary called WALSMatrixFactorization.PROJECT_ROW.

25
00:01:12,920 --> 00:01:15,935
This is a boolean tensor that if set to true,

26
00:01:15,935 --> 00:01:18,245
will protect rows and if set to false,

27
00:01:18,245 --> 00:01:20,825
it will protect columns during inference.

28
00:01:20,825 --> 00:01:23,360
So, now that we've gone through the entire input function,

29
00:01:23,360 --> 00:01:25,385
let's see how it fits in with the estimator.

30
00:01:25,385 --> 00:01:29,350
Here's our train input function where we pass the train estimator ModeKeys,

31
00:01:29,350 --> 00:01:32,210
so that will go an indefinite number of epochs through the dataset

32
00:01:32,210 --> 00:01:35,645
until we reach our number of train steps calculated above,

33
00:01:35,645 --> 00:01:38,030
and here's our eval input function,

34
00:01:38,030 --> 00:01:40,250
where we would go through the dataset only once.

35
00:01:40,250 --> 00:01:43,035
Remember at the moment WALS is a contrib Estimator,

36
00:01:43,035 --> 00:01:45,190
so I'm using to experiment and learn_runner.

37
00:01:45,190 --> 00:01:49,340
The current implementation of WALS handles batching, but not distribution.

38
00:01:49,340 --> 00:01:53,050
When it is updated to also handle distribution, it will move to core.

39
00:01:53,050 --> 00:01:55,370
The goal is that all core estimators distribute to

40
00:01:55,370 --> 00:01:57,695
multiple machines without any code changes.

41
00:01:57,695 --> 00:01:59,870
Here's the call with an experiment to see

42
00:01:59,870 --> 00:02:03,295
the setup for WALSMatrixFactorization estimators.

43
00:02:03,295 --> 00:02:05,980
We still need to create a certain input function for

44
00:02:05,980 --> 00:02:08,710
making recommendations, but we'll get to that later.

45
00:02:08,710 --> 00:02:13,415
Lastly, going to kick out the action with learn_runner running our experiment function.

46
00:02:13,415 --> 00:02:16,005
Using the WALSMatrixfactorization model,

47
00:02:16,005 --> 00:02:19,390
it is possible to predict the ratings between all items and users,

48
00:02:19,390 --> 00:02:21,295
if given the row and column factors.

49
00:02:21,295 --> 00:02:25,600
However typically, we just store the top K items per user or users per

50
00:02:25,600 --> 00:02:30,100
item to save space and computation by not filling out the entire radio matrix,

51
00:02:30,100 --> 00:02:31,795
which can be very large.

52
00:02:31,795 --> 00:02:37,870
Let's define a function called find_top_K that takes the user factors particular user U,

53
00:02:37,870 --> 00:02:43,475
and the item factors of all items V that the WALSMatrixFactorization model solve for.

54
00:02:43,475 --> 00:02:46,190
We also want to pass to the function K,

55
00:02:46,190 --> 00:02:49,550
so that it knows how many users or items to return.

56
00:02:49,550 --> 00:02:53,270
Instead of multiplying a vector from each factor matrix to get

57
00:02:53,270 --> 00:02:58,160
a specific user item rating prediction as we did earlier in our user movie example,

58
00:02:58,160 --> 00:03:01,895
we can matrix multiply instead to get all of the ratings for the user.

59
00:03:01,895 --> 00:03:04,070
Because this is just one user,

60
00:03:04,070 --> 00:03:06,785
user factors is a vector specific to that user.

61
00:03:06,785 --> 00:03:08,530
Before we can do the matrix multiply,

62
00:03:08,530 --> 00:03:12,145
we need to expand dims of user factors to make it a rank two tensor.

63
00:03:12,145 --> 00:03:15,155
Thus, where matrix multiplying a one by

64
00:03:15,155 --> 00:03:18,830
latent factors matrix with a latent factors by items matrix,

65
00:03:18,830 --> 00:03:21,985
which will result in a one by items matrix.

66
00:03:21,985 --> 00:03:25,670
Now that we have a tensor of all item ratings for a user,

67
00:03:25,670 --> 00:03:29,210
we can use tf.nn.top_k to

68
00:03:29,210 --> 00:03:32,989
get a tensor object of the top K values and their associated indices,

69
00:03:32,989 --> 00:03:35,200
which would be the item IDs in this case.

70
00:03:35,200 --> 00:03:38,700
Lastly, we want to return the top K items for our user.

71
00:03:38,700 --> 00:03:42,815
So, we'll return the indices member tensor of our top K object.

72
00:03:42,815 --> 00:03:47,260
Because these are indices will cast them to integers before we exit the function.

73
00:03:47,260 --> 00:03:52,025
If we want to find the top K items for all users we can create a batch prediction job.

74
00:03:52,025 --> 00:03:54,020
Note the session creation,

75
00:03:54,020 --> 00:03:56,105
this is a complete TensorFlow function,

76
00:03:56,105 --> 00:03:58,450
it is not part of any other graph.

77
00:03:58,450 --> 00:04:01,145
We define our estimator which will load the model

78
00:04:01,145 --> 00:04:04,100
from our output directory we wrote to during training.

79
00:04:04,100 --> 00:04:06,860
We extract the user factors from our estimator by

80
00:04:06,860 --> 00:04:09,360
getting the row factors which will be a rank two tensor,

81
00:04:09,360 --> 00:04:12,715
we shaped number of users by number of embedding dimensions.

82
00:04:12,715 --> 00:04:15,260
Likewise, we extract the item factors

83
00:04:15,260 --> 00:04:17,330
from our estimator by getting the column factor which will be

84
00:04:17,330 --> 00:04:22,615
a rank two tensor which shape number of items by number of embedding dimensions.

85
00:04:22,615 --> 00:04:28,610
We can reuse the fine top K function we just made and put it in a map function,

86
00:04:28,610 --> 00:04:30,650
we'll use our entire user factors matrix as

87
00:04:30,650 --> 00:04:33,890
the elements to our map function where it will pass a row or

88
00:04:33,890 --> 00:04:39,905
user from the matrix by the lambda function to find our top K as a user.

89
00:04:39,905 --> 00:04:41,760
This will create a stack of matrices,

90
00:04:41,760 --> 00:04:44,165
so we will squeeze it to get her down to a rank two tensor,

91
00:04:44,165 --> 00:04:47,450
we shape users by top K. We'll

92
00:04:47,450 --> 00:04:50,770
create a file IO stream to our batch prediction output file,

93
00:04:50,770 --> 00:04:55,160
and we'll create a loop where we evaluate the top K within the session we created,

94
00:04:55,160 --> 00:04:57,500
each row in the file in this case will be

95
00:04:57,500 --> 00:05:01,530
a comma delimited string of the top K best items for that user.

96
00:05:01,530 --> 00:05:03,490
Let's now test your knowledge,

97
00:05:03,490 --> 00:05:06,485
we saw how to recommend the top K items for users,

98
00:05:06,485 --> 00:05:10,800
but what if we wanted to instead recommend the top K users for items,

99
00:05:10,800 --> 00:05:14,175
which would be the correct change in our batch prediction function?

100
00:05:14,175 --> 00:05:17,180
Choose the answer that best fills in the blanks.

101
00:05:17,180 --> 00:05:19,610
The correct answer is B,

102
00:05:19,610 --> 00:05:22,430
are changing argument through the Lambda function to

103
00:05:22,430 --> 00:05:26,065
our find_top_K function will be an item for both.

104
00:05:26,065 --> 00:05:29,030
We will be matrix multiplying this item vector which will

105
00:05:29,030 --> 00:05:32,215
expand dams into a matrix by the user factors matrix.

106
00:05:32,215 --> 00:05:37,010
Lastly, the elements we will mapping from will be from our items factors matrix of

107
00:05:37,010 --> 00:05:38,660
shape number of items by number of

108
00:05:38,660 --> 00:05:43,200
embedding dimensions where it'll be pull a row per map from.