1
00:00:00,360 --> 00:00:04,052
Now, let's examine a specific workflow DAG
that you'll be completing as part of your

2
00:00:04,052 --> 00:00:05,720
end-to-end lab.

3
00:00:05,720 --> 00:00:08,984
Read through the four operators here and
take your best guess at

4
00:00:08,984 --> 00:00:12,944
what this pipeline is achieving in
the short pop-up quiz that'll appear.

5
00:00:14,692 --> 00:00:16,170
Now, let's read through it together.

6
00:00:17,270 --> 00:00:21,076
Here, you see four tasks,
t1, t2, t3, and t4, and

7
00:00:21,076 --> 00:00:26,220
the four operators corresponding to
four Google Cloud Platform services.

8
00:00:26,220 --> 00:00:27,790
The name should look familiar.

9
00:00:27,790 --> 00:00:31,840
You can probably even start to guess
what this workflow does at a high level,

10
00:00:31,840 --> 00:00:33,890
just by reading them in order.

11
00:00:33,890 --> 00:00:38,123
The first two are concerned with getting
fresh model data from the BigQuery data

12
00:00:38,123 --> 00:00:43,155
set and into GCS for consumption by
our ML model later on in the workflow.

13
00:00:44,190 --> 00:00:45,880
In the lab you're going to work on later,

14
00:00:45,880 --> 00:00:48,270
the date set will be one that
you're already familiar with.

15
00:00:48,270 --> 00:00:50,980
It's the Google Analytics
news article sample data set.

16
00:00:52,260 --> 00:00:55,450
Let's see the parameters
the BigQueryOperator takes.

17
00:00:55,450 --> 00:00:58,523
The BigQueryOperator allows
you to specify a SQL query to

18
00:00:58,523 --> 00:01:01,190
run against a BigQuery data set.

19
00:01:01,190 --> 00:01:05,490
In this quick example, we're passing in
a query which returns the top 100 most

20
00:01:05,490 --> 00:01:09,590
popular Stack Overflow posts from
the BigQuery public data set for

21
00:01:09,590 --> 00:01:13,140
a specified date range that you
see there in the WHERE clause.

22
00:01:13,140 --> 00:01:16,360
You notice anything different about
the filters in the WHERE clause?

23
00:01:16,360 --> 00:01:20,918
Yeah, there are parameters in this
case for max date and min date.

24
00:01:20,918 --> 00:01:24,890
You can parameterize pieces of this
SQL statement, like what we did here,

25
00:01:24,890 --> 00:01:30,950
to only return posts for January 2018 with
a min query date and a max query date.

26
00:01:30,950 --> 00:01:34,500
What's really neat is that you can
make the parameters themselves dynamic

27
00:01:34,500 --> 00:01:36,820
instead of the static ones
that are shown here, and

28
00:01:36,820 --> 00:01:39,466
you can have them be based
on the DAG schedule date.

29
00:01:39,466 --> 00:01:42,997
Like macros.ds_add(ds, -7),

30
00:01:42,997 --> 00:01:47,400
which just means this is a week
before the DAG is scheduled to run.

31
00:01:47,400 --> 00:01:48,780
That's what that date
value is going to be.

32
00:01:49,810 --> 00:01:53,930
For workflows, you want to be really
careful with the window of data you use

33
00:01:53,930 --> 00:01:56,450
for training, evaluation, and testing.

34
00:01:56,450 --> 00:02:01,830
What if data two weeks ago was fine, but
last week the upstream pipeline failed and

35
00:02:01,830 --> 00:02:03,780
there were no records returned for
the query?

36
00:02:04,950 --> 00:02:08,620
Zero records returned for
a SQL query is still a valid result,

37
00:02:08,620 --> 00:02:11,140
but you can still imagine
the implications.

38
00:02:11,140 --> 00:02:14,970
You didn't have somehow or someway of
validating the upstream data sources

39
00:02:14,970 --> 00:02:17,240
that you're feeding into your workflow.

40
00:02:17,240 --> 00:02:20,610
This is especially true for recommendation
models, which rely on timely,

41
00:02:20,610 --> 00:02:23,730
fresh training data to make
those good recommendations.

42
00:02:23,730 --> 00:02:28,300
And avoid stale, or even worse, incorrect
or inappropriate recommendations for

43
00:02:28,300 --> 00:02:29,570
your users.

44
00:02:29,570 --> 00:02:33,350
So what can you do to guard our
workflows against upstream data issues?

45
00:02:33,350 --> 00:02:36,030
Two words, health checks.

46
00:02:36,030 --> 00:02:39,980
Running SQL statements on BigQuery is not
only good at giving you correct insights

47
00:02:39,980 --> 00:02:43,910
from clean data, it can also
alert you if something is amiss.

48
00:02:43,910 --> 00:02:46,050
Let's take a look at an example.

49
00:02:46,050 --> 00:02:50,150
There's an operator you can use,
called BigQueryCheckOperator,

50
00:02:50,150 --> 00:02:53,550
which sounds exactly like something
we could use in our workflow.

51
00:02:53,550 --> 00:02:57,480
How it works is, say we had an upstream
data source that tracked the number of

52
00:02:57,480 --> 00:03:00,315
students that went through
training classes cumulated for

53
00:03:00,315 --> 00:03:02,710
all time,
like the one that you're taking now.

54
00:03:02,710 --> 00:03:06,759
This is a data table that logically should
never have zero records passed as part of

55
00:03:06,759 --> 00:03:08,150
our workflow.

56
00:03:08,150 --> 00:03:09,750
So we're expecting
something more like this.

57
00:03:09,750 --> 00:03:13,330
10,000 records or so
are passed into our ML training data set,

58
00:03:13,330 --> 00:03:17,440
and the rest of the workflow handles the
model retraining and deployment as usual.

59
00:03:17,440 --> 00:03:19,910
Let's say for whatever reason or
data anomaly,

60
00:03:19,910 --> 00:03:24,850
the upstream data table was accidentally
offline, or truncated, or moved, and now

61
00:03:24,850 --> 00:03:29,610
it's giving us zero records after we do
a select star into our training data set.

62
00:03:29,610 --> 00:03:32,830
Again, this is still a valid SQL query,
but zero records to train and

63
00:03:32,830 --> 00:03:35,440
retrain our recommendation model
is going to be really, really,

64
00:03:35,440 --> 00:03:37,590
really bad when it comes
to ML model training.

65
00:03:37,590 --> 00:03:41,610
And that's where
the BigQueryCheckOperator can help us out.

66
00:03:41,610 --> 00:03:46,270
If the result of this health check query
returns zero or false, the health check

67
00:03:46,270 --> 00:03:50,600
will fail, and then you can have
the rest of this workflow fail as well.

68
00:03:50,600 --> 00:03:54,990
But even beyond that, you can say you
have a sad path branch of your DAG that

69
00:03:54,990 --> 00:03:57,650
even sends an email alert or
notification for

70
00:03:57,650 --> 00:04:01,260
critical pipeline failures to a human
team for immediate investigation.

71
00:04:02,590 --> 00:04:06,316
I've shown just a sample of,
if the upstream data table zero records,

72
00:04:06,316 --> 00:04:07,440
then fail to work flow.

73
00:04:07,440 --> 00:04:11,680
We can also build a much more complex
logic in SQL using your own health checks

74
00:04:11,680 --> 00:04:15,350
by using something like case statements or
joins against other tables.

75
00:04:15,350 --> 00:04:19,440
And the benefit for you and your team
is that all these checks are written as

76
00:04:19,440 --> 00:04:24,080
part of the DAG in that SQL so they get
and controlled and very highly visible.

77
00:04:24,080 --> 00:04:26,590
Kind of like unit testing for programming.

78
00:04:26,590 --> 00:04:28,220
Now, here's the tricky dilemma.

79
00:04:28,220 --> 00:04:31,860
We saw how easy it is to check for
zero records with a count star and

80
00:04:31,860 --> 00:04:33,220
fail the pipeline.

81
00:04:33,220 --> 00:04:38,080
But what about the case where something
in the data values themselves changed?

82
00:04:38,080 --> 00:04:41,760
We're still getting records passed
through, but they're really different or

83
00:04:41,760 --> 00:04:43,180
strange values.

84
00:04:43,180 --> 00:04:44,930
Take a look at an example.

85
00:04:44,930 --> 00:04:49,000
We have a daily workflow that ingest
the average temperature of the day.

86
00:04:49,000 --> 00:04:51,780
Notice anything funny about October?

87
00:04:51,780 --> 00:04:54,860
That value is way lower than the others.

88
00:04:54,860 --> 00:04:58,019
Now, if you had to make a guess,
what do you think happened?

89
00:05:00,456 --> 00:05:05,185
Barring really strange summer weather
patterns, our upstream data team likely

90
00:05:05,185 --> 00:05:10,430
switched the scale from Fahrenheit to
Celsius somewhere on or about October 1st.

91
00:05:10,430 --> 00:05:12,560
And didn't tell
the downstream engineering or

92
00:05:12,560 --> 00:05:16,850
data science teams who are consuming this
BigQuery table as part of their workflows.

93
00:05:16,850 --> 00:05:20,490
If we use the simple,
does the training data have any records,

94
00:05:20,490 --> 00:05:25,095
this check would have passed and the model
would have been trained, none the wiser.

95
00:05:25,095 --> 00:05:29,645
Instead, we can use
BigQueryIntervalCheckOperator,

96
00:05:29,645 --> 00:05:33,425
which can notice huge changes or
swings in the data distribution, and

97
00:05:33,425 --> 00:05:36,485
then fail the workflow until
further investigation.

98
00:05:36,485 --> 00:05:40,115
This operator checks the values of
metrics, given as SQL expressions,

99
00:05:40,115 --> 00:05:42,733
whether or
not they're within a certain distance or

100
00:05:42,733 --> 00:05:47,160
tolerance of the ones from our parameter
value that you sent, called days back.

101
00:05:47,160 --> 00:05:49,690
Which looks backwards at
your data history for

102
00:05:49,690 --> 00:05:52,680
previous DAG runs to compare it against.

103
00:05:52,680 --> 00:05:53,780
Keep in mind, for

104
00:05:53,780 --> 00:05:57,680
both BigQueryCheckOperator and
BigQueryIntervalCheckOperator,

105
00:05:57,680 --> 00:06:01,490
you can have more than one check
run as a node in your workflow.

106
00:06:01,490 --> 00:06:04,310
A good idea for
machine learning is to set up a check for

107
00:06:04,310 --> 00:06:07,883
each of your key features to test for
null, zero, out of bounds, or

108
00:06:07,883 --> 00:06:11,797
irregular values before they make
their way into your training data set.

109
00:06:11,797 --> 00:06:16,082
And of course, you can always revisit and
update these checks as you engineer more

110
00:06:16,082 --> 00:06:18,890
features, or continue to tune and
train your model.

111
00:06:20,460 --> 00:06:24,490
The next two operators handle retraining
the model by submitting a job to

112
00:06:24,490 --> 00:06:26,050
Cloud Machine Learning Engine, and

113
00:06:26,050 --> 00:06:30,220
then deploying the updated model
to App Engine via an API endpoint.

114
00:06:30,220 --> 00:06:33,600
The ML Engine training operator is
how Cloud Composer interacts with

115
00:06:33,600 --> 00:06:36,690
Cloud Machine Learning Engine, and
thus gives it the ability to periodically

116
00:06:36,690 --> 00:06:41,720
schedule new jobs to be sent to CMLE
as part of your automated workflow.

117
00:06:41,720 --> 00:06:44,980
Take a look through the parameters
you provide to the operator.

118
00:06:44,980 --> 00:06:48,020
First, we specify an ID for
the task we're running and

119
00:06:48,020 --> 00:06:50,160
then the project that
we want to run it on.

120
00:06:50,160 --> 00:06:53,910
For our lab, this will be the same project
that's also managing the Airflow instance

121
00:06:53,910 --> 00:06:56,190
and everything else that
you're working with.

122
00:06:56,190 --> 00:06:58,718
Then you have the option of
creating your own job ID,

123
00:06:58,718 --> 00:07:03,380
which usually involves a concatenated time
stamp or a similar unique identifier.

124
00:07:03,380 --> 00:07:07,740
After that is the path to the actual model
code, which we'll have in a zip file,

125
00:07:07,740 --> 00:07:11,870
which is created by a shell script
after training is run in our lab.

126
00:07:11,870 --> 00:07:14,680
Then the actual Python module
name within your code to

127
00:07:14,680 --> 00:07:19,270
run within the ML Engine training
job after installing the package.

128
00:07:19,270 --> 00:07:21,649
In this example,
we've called it trainer.task.

129
00:07:22,770 --> 00:07:26,420
Next is a series of arguments for
training, which we store into an array,

130
00:07:26,420 --> 00:07:27,834
called training_args.

131
00:07:27,834 --> 00:07:32,630
Those includes the location of the job
directory, where the training files are,

132
00:07:32,630 --> 00:07:36,260
where the output directory is,
and what data we're using.

133
00:07:36,260 --> 00:07:41,250
And the next three, region, scale_tier,
and master_type are GCP infrastructure

134
00:07:41,250 --> 00:07:45,680
parameters where you want your job to
be ran and with what special hardware,

135
00:07:45,680 --> 00:07:48,120
like GPUs or TPUs, if you're using any.

136
00:07:49,480 --> 00:07:52,909
Lastly, once your model is retrained and
ready to be delivered as an API endpoint

137
00:07:52,909 --> 00:07:58,330
for serving, we need to redeploy our
App Engine project with the latest model.

138
00:07:58,330 --> 00:08:00,860
Here, the parameters are simple
since we're just redeploying

139
00:08:00,860 --> 00:08:04,610
our existing App Engine instance
associated with our project.

140
00:08:04,610 --> 00:08:08,730
And that's it, well, almost,
that's the last task.

141
00:08:08,730 --> 00:08:13,020
But at the end of most DAG files, you'll
find is the actual order in which we want

142
00:08:13,020 --> 00:08:15,019
these tasks and operators to be ran.

143
00:08:15,019 --> 00:08:18,320
This is what the D in DAG stands for,
directed.

144
00:08:18,320 --> 00:08:23,640
For example, task two, t2,
won't run until t1 is completed.

145
00:08:23,640 --> 00:08:27,430
This is what gives our graph
dependencies of a workflow.

146
00:08:27,430 --> 00:08:29,860
I can probably guess what
you're thinking at this point.

147
00:08:29,860 --> 00:08:33,670
You could build in some pretty cool
branching of multiple child nodes

148
00:08:33,670 --> 00:08:37,160
per upstream parent, and
absolutely that's totally possible.

149
00:08:37,160 --> 00:08:41,030
Just don't forget to comment your code,
so you know where one branch begins,

150
00:08:41,030 --> 00:08:44,660
where it's going, what tasks are involved,
and where it ends.

151
00:08:44,660 --> 00:08:48,870
As a tip, after you load in your
DAG file into the DAG folder,

152
00:08:48,870 --> 00:08:54,280
you can see the visualization of your DAG
in the Airflow UI as a directed graph,

153
00:08:54,280 --> 00:08:56,940
a Gantt chart, or a list if you wanted.

154
00:08:56,940 --> 00:09:00,000
Reviewing the visual
representation of the order tasks

155
00:09:00,000 --> 00:09:03,030
will help you confirm that your tasks
are ordered in the way that you want them.