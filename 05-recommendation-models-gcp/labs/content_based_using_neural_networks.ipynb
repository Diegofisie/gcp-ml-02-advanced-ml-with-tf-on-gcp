{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Filtering Using Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab relies on files created in the [content_based_preproc.ipynb](./content_based_preproc.ipynb) notebook. Be sure to complete the TODOs in that notebook and run the code there before completing this lab.  \n",
    "Also, we'll be using the **python3** kernel from here on out so don't forget to change the kernel if it's still python2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab illustrates:\n",
    "1. how to build feature columns for a model using tf.feature_column\n",
    "2. how to create custom evaluation metrics and add them to Tensorboard\n",
    "3. how to train a model and make predictions with the saved model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow Hub should already be installed. You can check using pip freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard==1.8.0\n",
      "tensorflow==1.8.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip freeze | grep tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If 'tensorflow-hub' isn't one of the outputs above, then you'll need to install it. Uncomment the cell below and execute the commands. After doing the pip install, click **\"Reset Session\"** on the notebook so that the Python environment picks up the new packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-hub\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow-hub) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow-hub) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow-hub) (3.6.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py3env/lib/python3.5/site-packages (from protobuf>=3.4.0->tensorflow-hub) (40.2.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.3.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install tensorflow-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0320 07:34:35.182858 139766874433280 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-0b5ac7ef62bf23c8\n",
      "qwiklabs-gcp-0b5ac7ef62bf23c8\n",
      "europe-west1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import shutil\n",
    "\n",
    "output = os.popen(\"gcloud config get-value project\").readlines()\n",
    "project_name = output[0][:-1]\n",
    "\n",
    "PROJECT = project_name\n",
    "BUCKET = project_name\n",
    "#BUCKET = BUCKET.replace(\"qwiklabs-gcp-\", \"inna-bckt-\")\n",
    "REGION = 'europe-west1'  ## note: Cloud ML Engine not availabe in europe-west3!\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'\n",
    "\n",
    "print(PROJECT)\n",
    "print(BUCKET)\n",
    "print(REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the feature columns for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we'll load the list of categories, authors and article ids we created in the previous **Create Datasets** notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = open(\"categories.txt\").read().splitlines()\n",
    "authors_list = open(\"authors.txt\").read().splitlines()\n",
    "content_ids_list = open(\"content_ids.txt\").read().splitlines()\n",
    "mean_months_since_epoch = 523"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below we'll define the feature columns to use in our model. If necessary, remind yourself the [various feature columns](https://www.tensorflow.org/api_docs/python/tf/feature_column) to use.  \n",
    "For the embedded_title_column feature column, use a Tensorflow Hub Module to create an embedding of the article title. Since the articles and titles are in German, you'll want to use a German language embedding module.  \n",
    "Explore the text embedding Tensorflow Hub modules [available here](https://alpha.tfhub.dev/). Filter by setting the language to 'German'. The 50 dimensional embedding should be sufficient for our purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO (done): use a Tensorflow Hub module to create a text embeddding column for the article \"title\". \n",
    "# Use the module available at https://alpha.tfhub.dev/ filtering by German language.\n",
    "embedded_title_column = hub.text_embedding_column(\n",
    "    key = \"title\",\n",
    "    module_spec = \"https://tfhub.dev/google/nnlm-de-dim50/1\",\n",
    "    trainable = False\n",
    ")\n",
    "\n",
    "#TODO (done): create an embedded categorical feature column for the article id; i.e. \"content_id\".\n",
    "content_id_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"content_id\",\n",
    "    hash_bucket_size = len(content_ids_list) + 1\n",
    ")\n",
    "embedded_content_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = content_id_column,\n",
    "    dimension = 10\n",
    ")\n",
    "\n",
    "#TODO (done): create an embedded categorical feature column for the article \"author\"\n",
    "author_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"author\",\n",
    "    hash_bucket_size = len(authors_list) + 1\n",
    ")\n",
    "embedded_author_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = author_column,\n",
    "    dimension = 3\n",
    ")\n",
    "\n",
    "#TODO (done): create a categorical feature column for the article \"category\"\n",
    "category_column_categorical = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    key = \"category\",\n",
    "    vocabulary_list = categories_list,\n",
    "    num_oov_buckets = 1\n",
    ")\n",
    "category_column = tf.feature_column.indicator_column(category_column_categorical)\n",
    "## note: indicator_column creates a multi-hot-encoded column.\n",
    "\n",
    "#TODO (done): create a bucketized numeric feature column of values for the \"months since epoch\"\n",
    "months_since_epoch_boundaries = list(range(400,700,20))\n",
    "months_since_epochs_numeric = tf.feature_column.numeric_column(key = \"months_since_epoch\")\n",
    "months_since_epoch_bucketized = tf.feature_column.bucketized_column(\n",
    "  source_column = months_since_epochs_numeric,\n",
    "  boundaries = months_since_epoch_boundaries\n",
    ")\n",
    "\n",
    "#TODO (done): create a crossed feature column using the \"category\" and \"months since epoch\" values\n",
    "crossed_months_since_category_column = tf.feature_column.indicator_column(\n",
    "  tf.feature_column.crossed_column(\n",
    "    keys = [category_column_categorical, months_since_epoch_bucketized], \n",
    "    hash_bucket_size = len(months_since_epoch_boundaries * (len(categories_list) + 1))\n",
    "  )\n",
    ")\n",
    "\n",
    "feature_columns = [embedded_content_column,\n",
    "                   embedded_author_column,\n",
    "                   category_column,\n",
    "                   embedded_title_column,\n",
    "                   crossed_months_since_category_column] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input function.\n",
    "\n",
    "Next we'll create the input function for our model. This input function reads the data from the csv files we created in the previous labs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_defaults = [[\"Unknown\"], [\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[mean_months_since_epoch],[\"Unknown\"]]\n",
    "column_keys = [\"visitor_id\", \"content_id\", \"category\", \"title\", \"author\", \"months_since_epoch\", \"next_content_id\"]\n",
    "label_key = \"next_content_id\"\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "      def decode_csv(value_column):\n",
    "          columns = tf.decode_csv(value_column,record_defaults=record_defaults)\n",
    "          features = dict(zip(column_keys, columns))          \n",
    "          label = features.pop(label_key)         \n",
    "          return features, label\n",
    "\n",
    "      # Create list of files that match pattern\n",
    "      file_list = tf.gfile.Glob(filename)\n",
    "\n",
    "      # Create dataset from file list\n",
    "      dataset = tf.data.TextLineDataset(file_list).map(decode_csv)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "          num_epochs = None # indefinitely\n",
    "          dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "      else:\n",
    "          num_epochs = 1 # end-of-input after this\n",
    "\n",
    "      dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "      return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model and train/evaluate\n",
    "\n",
    "\n",
    "Next, we'll build our model which recommends an article for a visitor to the Kurier.at website. Look through the code below. We use the input_layer feature column to create the dense input layer to our network. This is just a sigle layer network where we can adjust the number of hidden units as a parameter.\n",
    "\n",
    "Currently, we compute the accuracy between our predicted 'next article' and the actual 'next article' read next by the visitor. Resolve the TODOs in the cell below by adding additional performance metrics to assess our model. You will need to \n",
    "* use the [tf.metrics library](https://www.tensorflow.org/api_docs/python/tf/metrics) to compute an additional performance metric\n",
    "* add this additional metric to the metrics dictionary, and \n",
    "* include it in the tf.summary that is sent to Tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "  net = tf.feature_column.input_layer(features, params['feature_columns'])\n",
    "  for units in params['hidden_units']:\n",
    "        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\n",
    "   # Compute logits (1 per class).\n",
    "  logits = tf.layers.dense(net, params['n_classes'], activation=None) \n",
    "\n",
    "  predicted_classes = tf.argmax(logits, 1)\n",
    "  from tensorflow.python.lib.io import file_io\n",
    "    \n",
    "  with file_io.FileIO('content_ids.txt', mode='r') as ifp:\n",
    "    content = tf.constant([x.rstrip() for x in ifp])\n",
    "  predicted_class_names = tf.gather(content, predicted_classes)\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'class_ids': predicted_classes[:, tf.newaxis],\n",
    "        'class_names' : predicted_class_names[:, tf.newaxis],\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "        'logits': logits,\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "  table = tf.contrib.lookup.index_table_from_file(vocabulary_file=\"content_ids.txt\")\n",
    "  labels = table.lookup(labels)\n",
    "  # Compute loss.\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Compute evaluation metrics.\n",
    "  accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                 predictions=predicted_classes,\n",
    "                                 name='acc_op')\n",
    "  #TODO (done): Compute the top_10 accuracy, using the tf.nn.in_top_k and tf.metrics.mean functions in Tensorflow\n",
    "  top_10_accuracy = tf.metrics.mean(\n",
    "    tf.nn.in_top_k(predictions = logits, targets = labels, k = 10)\n",
    "  )\n",
    "  \n",
    "  metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    #TODO (done): Add top_10_accuracy to the metrics dictionary\n",
    "    'top_10_accuracy': top_10_accuracy\n",
    "  }\n",
    "  \n",
    "  ## note: second element [1] is the `update_op`, which is the updated metric after each batch...\n",
    "  tf.summary.scalar('accuracy', accuracy[1])\n",
    "  #TODO (done): Add the top_10_accuracy metric to the Tensorboard summary\n",
    "  tf.summary.scalar('top_10_accuracy', top_10_accuracy[1])\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "      return tf.estimator.EstimatorSpec(\n",
    "          mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "  # Create training op.\n",
    "  assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "  train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "  return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:47.799170 139766874433280 tf_logging.py:116] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1de0aa68d0>, '_task_type': 'worker', '_master': '', '_num_ps_replicas': 0, '_model_dir': 'content_based_model_trained', '_save_checkpoints_steps': None, '_is_chief': True, '_train_distribute': None, '_session_config': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_evaluation_master': '', '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:47.806472 139766874433280 tf_logging.py:116] Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1de0aa68d0>, '_task_type': 'worker', '_master': '', '_num_ps_replicas': 0, '_model_dir': 'content_based_model_trained', '_save_checkpoints_steps': None, '_is_chief': True, '_train_distribute': None, '_session_config': None, '_save_summary_steps': 100, '_global_id_in_cluster': 0, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_task_id': 0, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_evaluation_master': '', '_service': None, '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:47.816347 139766874433280 tf_logging.py:116] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:47.820190 139766874433280 tf_logging.py:116] Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:47.888497 139766874433280 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:48.167494 139766874433280 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:48.956489 139766874433280 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:48.970116 139766874433280 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:49.448025 139766874433280 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:50.627632 139766874433280 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:51.789882 139766874433280 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:54.082758 139766874433280 tf_logging.py:116] Saving checkpoints for 1 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 9.656757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:55:54.600059 139766874433280 tf_logging.py:116] step = 1, loss = 9.656757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.99256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:44.786559 139766874433280 tf_logging.py:116] global_step/sec: 1.99256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 101, loss = 5.3687167 (50.198 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:44.797833 139766874433280 tf_logging.py:116] step = 101, loss = 5.3687167 (50.198 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 110 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:49.316921 139766874433280 tf_logging.py:116] Saving checkpoints for 110 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5.306711.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:51.637431 139766874433280 tf_logging.py:116] Loss for final step: 5.306711.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:51.697811 139766874433280 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:51.980008 139766874433280 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:52.337481 139766874433280 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-20-07:56:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:52.372967 139766874433280 tf_logging.py:116] Starting evaluation at 2019-03-20-07:56:52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:52.508660 139766874433280 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from content_based_model_trained/model.ckpt-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:52.518365 139766874433280 tf_logging.py:116] Restoring parameters from content_based_model_trained/model.ckpt-110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:52.990261 139766874433280 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:56:54.399979 139766874433280 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-20-07:57:10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:10.869024 139766874433280 tf_logging.py:116] Finished evaluation at 2019-03-20-07:57:10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 110: accuracy = 0.026407281, global_step = 110, loss = 5.4312987, top_10_accuracy = 0.20270324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:10.875278 139766874433280 tf_logging.py:116] Saving dict for global step 110: accuracy = 0.026407281, global_step = 110, loss = 5.4312987, top_10_accuracy = 0.20270324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:11.818247 139766874433280 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:12.100546 139766874433280 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:13.019013 139766874433280 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:13.041149 139766874433280 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:13.201533 139766874433280 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from content_based_model_trained/model.ckpt-110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:13.212512 139766874433280 tf_logging.py:116] Restoring parameters from content_based_model_trained/model.ckpt-110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:13.723168 139766874433280 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:14.857356 139766874433280 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 111 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:16.690572 139766874433280 tf_logging.py:116] Saving checkpoints for 111 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 111, loss = 5.3442545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:57:17.993168 139766874433280 tf_logging.py:116] step = 111, loss = 5.3442545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 200 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:02.329573 139766874433280 tf_logging.py:116] Saving checkpoints for 200 into content_based_model_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5.255849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:04.345735 139766874433280 tf_logging.py:116] Loss for final step: 5.255849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:04.405373 139766874433280 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:04.696885 139766874433280 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:05.091192 139766874433280 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-03-20-07:58:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:05.127994 139766874433280 tf_logging.py:116] Starting evaluation at 2019-03-20-07:58:05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:05.270436 139766874433280 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from content_based_model_trained/model.ckpt-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:05.278519 139766874433280 tf_logging.py:116] Restoring parameters from content_based_model_trained/model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:05.758121 139766874433280 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:07.023025 139766874433280 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-03-20-07:58:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:23.337346 139766874433280 tf_logging.py:116] Finished evaluation at 2019-03-20-07:58:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.030548068, global_step = 200, loss = 5.297825, top_10_accuracy = 0.2377046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 07:58:23.345363 139766874433280 tf_logging.py:116] Saving dict for global step 200: accuracy = 0.030548068, global_step = 200, loss = 5.297825, top_10_accuracy = 0.2377046\n"
     ]
    }
   ],
   "source": [
    "outdir = 'content_based_model_trained'\n",
    "shutil.rmtree(outdir, ignore_errors = True) # start fresh each time\n",
    "tf.summary.FileWriterCache.clear() # ensure filewriter cache is clear for TensorBoard events file\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn,\n",
    "    model_dir = outdir,\n",
    "    params={\n",
    "     'feature_columns': feature_columns,\n",
    "      'hidden_units': [200, 100, 50],\n",
    "      'n_classes': len(content_ids_list)\n",
    "    })\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = read_dataset(\"training_set.csv\", tf.estimator.ModeKeys.TRAIN),\n",
    "    max_steps = 200)\n",
    "\n",
    "eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = read_dataset(\"test_set.csv\", tf.estimator.ModeKeys.EVAL),\n",
    "    steps = None,\n",
    "    start_delay_secs = 30,\n",
    "    throttle_secs = 60)\n",
    "\n",
    "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions with the trained model. \n",
    "\n",
    "With the model now trained, we can make predictions by calling the predict method on the estimator. Let's look at how our model predicts on the first five examples of the training set.  \n",
    "To start, we'll create a new file 'first_5.csv' which contains the first five elements of our training set. We'll also save the target values to a file 'first_5_content_ids' so we can compare our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000196974485173657,299836841,News,\"ÖVP will Studiengebühren FPÖ in Verhandlungen \"\"flexibel\"\"\",Raffaela Lindorfer,574,299959410\n",
      "1000196974485173657,299959410,News,Koalition: Bildungspapier mit mehr Pflichten und Noten,Peter Temel,574,299925086\n",
      "1000196974485173657,299925086,News,Marihuana-Adventkalender findet in Kanada reißenden Absatz,,574,299826775\n",
      "1000196974485173657,299826775,Lifestyle,Auf Bank ausgeruht: Pensionist muss Strafe zahlen,Marlene Patsalidis,574,299930679\n",
      "1000196974485173657,299930679,News,Wintereinbruch naht: Erster Schnee im Osten möglich,Daniela Wahl,574,299950903\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "head -5 training_set.csv > first_5.csv\n",
    "head first_5.csv\n",
    "awk -F \"\\\"*,\\\"*\" '{print $2}' first_5.csv > first_5_content_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall, to make predictions on the trained model we pass a list of examples through the input function. Complete the code below to make predicitons on the examples contained in the \"first_5.csv\" file we created above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:47.323739 139766874433280 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:47.960026 139766874433280 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/e40ef097142ae1de637df7021ce148ffe836e262/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:48.277340 139766874433280 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:48.413286 139766874433280 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from content_based_model_trained/model.ckpt-200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:48.421568 139766874433280 tf_logging.py:116] Restoring parameters from content_based_model_trained/model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:48.890547 139766874433280 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0320 08:07:50.154239 139766874433280 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'class_ids': array([4]), 'class_names': array([b'299410466'], dtype=object), 'probabilities': array([1.1793807e-02, 2.0582383e-02, 1.1280167e-03, ..., 2.0453667e-06,\n",
      "       1.2166000e-06, 2.2878965e-06], dtype=float32), 'logits': array([ 8.577154  ,  9.134015  ,  6.2300406 , ..., -0.08259842,\n",
      "       -0.60211575,  0.02945683], dtype=float32)}, {'class_ids': array([59]), 'class_names': array([b'299836255'], dtype=object), 'probabilities': array([9.5619652e-03, 1.7562550e-02, 1.1298506e-03, ..., 3.4744508e-06,\n",
      "       2.2263582e-06, 3.9051861e-06], dtype=float32), 'logits': array([ 7.8327594 ,  8.440735  ,  5.6970515 , ..., -0.08735287,\n",
      "       -0.53242224,  0.02951602], dtype=float32)}, {'class_ids': array([59]), 'class_names': array([b'299836255'], dtype=object), 'probabilities': array([9.8370342e-03, 1.7713044e-02, 1.1635502e-03, ..., 3.7038003e-06,\n",
      "       2.3744481e-06, 4.1816338e-06], dtype=float32), 'logits': array([ 7.7908287 ,  8.378976  ,  5.6561503 , ..., -0.0937212 ,\n",
      "       -0.5383161 ,  0.02762089], dtype=float32)}, {'class_ids': array([4]), 'class_names': array([b'299410466'], dtype=object), 'probabilities': array([2.2448175e-02, 2.9793303e-02, 1.5914367e-03, ..., 1.7884923e-06,\n",
      "       1.0141998e-06, 1.9769486e-06], dtype=float32), 'logits': array([ 9.402774  ,  9.685848  ,  6.7562017 , ..., -0.03481725,\n",
      "       -0.60209066,  0.06536431], dtype=float32)}, {'class_ids': array([4]), 'class_names': array([b'299410466'], dtype=object), 'probabilities': array([1.0687636e-02, 1.8501464e-02, 1.2504261e-03, ..., 4.0029795e-06,\n",
      "       2.5272491e-06, 4.4479139e-06], dtype=float32), 'logits': array([ 7.8078384 ,  8.356601  ,  5.6622353 , ..., -0.08196531,\n",
      "       -0.5418727 ,  0.02343054], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "#TODO: Use the predict method on our trained model to find the predictions for the examples contained in \"first_5.csv\".\n",
    "output = list(\n",
    "  estimator.predict(\n",
    "    input_fn = read_dataset(filename = \"first_5.csv\", mode = tf.estimator.ModeKeys.PREDICT)\n",
    "  )\n",
    ")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "recommended_content_ids = [np.asscalar(d[\"class_names\"]).decode('UTF-8') for d in output]\n",
    "content_ids = open(\"first_5_content_ids\").read().splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll map the content id back to the article title. We can then compare our model's recommendation for the first of our examples. This can all be done in BigQuery. Look through the query below and make sure it is clear what is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current title: ÖVP will Studiengebühren, FPÖ in Verhandlungen \"flexibel\" \n",
      "Recommended title: Carfentanil: Der „serial killer“ ist in Österreich aufgetaucht\n"
     ]
    }
   ],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "recommended_title_sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "(SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title\n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) = \\\"{}\\\"\n",
    "LIMIT 1\"\"\".format(recommended_content_ids[0])\n",
    "\n",
    "current_title_sql=\"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "(SELECT MAX(IF(index=6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title\n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "  UNNEST(hits) AS hits\n",
    "WHERE \n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(hits.customDimensions)) = \\\"{}\\\"\n",
    "LIMIT 1\"\"\".format(content_ids[0])\n",
    "recommended_title = bq.Query(recommended_title_sql).execute().result().to_dataframe()['title'].tolist()[0]\n",
    "current_title = bq.Query(current_title_sql).execute().result().to_dataframe()['title'].tolist()[0]\n",
    "print(\"Current title: {} \".format(current_title))\n",
    "print(\"Recommended title: {}\".format(recommended_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard\n",
    "\n",
    "As usual, we can monitor the performance of our training job using Tensorboard. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4313. Click <a href=\"/_proxy/46023/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4313"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('content_based_model_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4295\n",
      "Stopped TensorBoard with pid 4313\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print(\"Stopped TensorBoard with pid {}\".format(pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
