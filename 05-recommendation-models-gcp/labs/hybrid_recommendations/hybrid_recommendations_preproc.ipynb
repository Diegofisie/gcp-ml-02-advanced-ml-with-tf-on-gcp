{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network hybrid recommendation system on Google Analytics data preprocessing\n",
    "\n",
    "This notebook demonstrates how to implement a hybrid recommendation system using a neural network to combine content-based and collaborative filtering recommendation models using Google Analytics data. We are going to use the learned user embeddings from [wals.ipynb](../wals.ipynb) and combine that with our previous content-based features from [content_based_using_neural_networks.ipynb](../content_based_using_neural_networks.ipynb)\n",
    "\n",
    "First we are going to preprocess our data using BigQuery and Cloud Dataflow to be used in our later neural network hybrid recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache Beam only works in Python 2 at the moment, so we're going to switch to the Python 2 kernel. In the above menu, click the dropdown arrow and select `python2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling google-cloud-dataflow-2.0.0:\n",
      "  Successfully uninstalled google-cloud-dataflow-2.0.0\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local/envs/py2env\n",
      "\n",
      "  added / updated specs: \n",
      "    - pytz==2018.4\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.0.2r             |       h7b6447c_0         3.2 MB  defaults\n",
      "    certifi-2019.3.9           |           py27_0         155 KB  defaults\n",
      "    ca-certificates-2019.1.23  |                0         126 KB  defaults\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         3.4 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates: 2018.03.07-0      defaults --> 2019.1.23-0       defaults\n",
      "    certifi:         2018.11.29-py27_0 defaults --> 2019.3.9-py27_0   defaults\n",
      "    openssl:         1.0.2p-h14c3975_0 defaults --> 1.0.2r-h7b6447c_0 defaults\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting apache-beam[gcp]\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/d5/bd533f864219da7251be3497e622f45f1ac56b1ee2eaa1b601b6b222044f/apache_beam-2.11.0-cp27-cp27mu-manylinux1_x86_64.whl (2.5MB)\n",
      "Requirement already satisfied: avro<2.0.0,>=1.8.1; python_version < \"3.0\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.8.2)\n",
      "Collecting pyvcf<0.7.0,>=0.6.8; python_version < \"3.0\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/20/b6/36bfb1760f6983788d916096193fc14c83cce512c7787c93380e09458c09/PyVCF-0.6.8.tar.gz\n",
      "Collecting pydot<1.3,>=1.2.0 (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
      "Collecting dill<0.2.10,>=0.2.9 (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/42/bfe2e0857bc284cbe6a011d93f2a9ad58a22cb894461b199ae72cfef0f29/dill-0.2.9.tar.gz (150kB)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.13)\n",
      "Collecting pyarrow<0.12.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/34/65/a3cd43e1834a748d9650e962ce43083063bf0c778e634d6ae5ca6e62438c/pyarrow-0.11.1-cp27-cp27mu-manylinux1_x86_64.whl (11.6MB)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2018.4)\n",
      "Collecting typing<3.7.0,>=3.6.0; python_version < \"3.5.0\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/3e/29f92b7aeda5b078c86d14f550bf85cff809042e3429ace7af6193c3bc9f/typing-3.6.6-py2-none-any.whl\n",
      "Collecting httplib2<=0.11.3,>=0.8 (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/fd/ce/aa4a385e3e9fd351737fd2b07edaa56e7a730448465aceda6b35086a0d9b/httplib2-0.11.3.tar.gz (215kB)\n",
      "Requirement already satisfied: oauth2client<4,>=2.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2.2.0)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.16.0)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.7)\n",
      "Collecting fastavro<0.22,>=0.21.4 (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/67/69/be1402c904506a5ec79ba65c7f0035342d506d5305cfd9ae8bc6f1c8db47/fastavro-0.21.19-cp27-cp27mu-manylinux1_x86_64.whl (1.0MB)\n",
      "Requirement already satisfied: futures<4.0.0,>=3.2.0; python_version < \"3.0\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.2.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.17.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.6.1)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2.0.0)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/96/4e/f82bd349c7893e1595429ecc95233369bc33c9a26e4859991439bfa01c1f/hdfs-2.2.2.tar.gz\n",
      "Collecting google-apitools<0.5.27,>=0.5.26; extra == \"gcp\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/74/12/065e04ed7bc9c9c45ff08429e0aa74176c4ea63608abb85a4786659889b1/google_apitools-0.5.26-py2-none-any.whl (335kB)\n",
      "Collecting google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/1b/2b95f2fefddbbece38110712c225bfb5649206f4056445653bd5ca4dc86d/google_cloud_bigquery-1.6.1-py2.py3-none-any.whl (83kB)\n",
      "Collecting google-cloud-bigtable==0.31.1; extra == \"gcp\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/00/58/8153616835b3ff7238c657400c8fc46c44b53074b39b22260dd06345f9ed/google_cloud_bigtable-0.31.1-py2.py3-none-any.whl (154kB)\n",
      "Requirement already satisfied: google-cloud-core==0.28.1; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.28.1)\n",
      "Requirement already satisfied: proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.90.0)\n",
      "Collecting google-cloud-pubsub==0.39.0; extra == \"gcp\" (from apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/30/c2e6611c3ffa45816e835b016a2b40bb2bd93f05d1055f78be16a9eb2e4d/google_cloud_pubsub-0.39.0-py2.py3-none-any.whl (99kB)\n",
      "Requirement already satisfied: googledatastore<7.1,>=7.0.1; python_version < \"3.0\" and extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (7.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyvcf<0.7.0,>=0.6.8; python_version < \"3.0\"->apache-beam[gcp]) (40.6.3)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pydot<1.3,>=1.2.0->apache-beam[gcp]) (2.3.0)\n",
      "Requirement already satisfied: six>=1.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyarrow<0.12.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"->apache-beam[gcp]) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.14 in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyarrow<0.12.0,>=0.11.1; python_version >= \"3.0\" or platform_system != \"Windows\"->apache-beam[gcp]) (1.14.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]) (0.2.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<4,>=2.0.1->apache-beam[gcp]) (3.4.2)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2,>=1.8->apache-beam[gcp]) (1.1.6)\n",
      "Requirement already satisfied: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]) (1.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]) (5.1.1)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/55/8f8cab2afd404cf578136ef2cc5dfb50baa1761b68c9da1fb1e4eed343c9/docopt-0.6.2.tar.gz\n",
      "Requirement already satisfied: requests>=2.7.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2.18.4)\n",
      "Collecting fasteners>=0.14 (from google-apitools<0.5.27,>=0.5.26; extra == \"gcp\"->apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/14/3a/096c7ad18e102d4f219f5dd15951f9728ca5092a3385d2e8f79a7c1e1017/fasteners-0.14.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-resumable-media>=0.2.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]) (0.3.2)\n",
      "Collecting google-api-core<2.0.0dev,>=1.0.0 (from google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/71/23a234ee35117c2ed1ebd5a62ae07ef29f9f0bae9ea816b91312bad81646/google_api_core-1.8.1-py2.py3-none-any.whl (65kB)\n",
      "Collecting grpc-google-iam-v1<0.12dev,>=0.11.4 (from google-cloud-bigtable==0.31.1; extra == \"gcp\"->apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/28/f26f67381cb23e81271b8d66c00a846ad9d25a909ae1ae1df8222fad2744/grpc-google-iam-v1-0.11.4.tar.gz\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.5.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\"->apache-beam[gcp]) (1.5.5)\n",
      "Requirement already satisfied: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock<3.0.0,>=1.0.1->apache-beam[gcp]) (1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2019.3.9)\n",
      "Collecting monotonic>=0.1 (from fasteners>=0.14->google-apitools<0.5.27,>=0.5.26; extra == \"gcp\"->apache-beam[gcp])\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]) (1.6.2)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.0.0->google-cloud-bigquery<1.7.0,>=1.6.0; extra == \"gcp\"->apache-beam[gcp]) (2.1.0)\n",
      "Building wheels for collected packages: pyvcf, pydot, dill, httplib2, hdfs, docopt, grpc-google-iam-v1\n",
      "  Running setup.py bdist_wheel for pyvcf: started\n",
      "  Running setup.py bdist_wheel for pyvcf: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/81/91/41/3272543c0b9c61da9c525f24ee35bae6fe8f60d4858c66805d\n",
      "  Running setup.py bdist_wheel for pydot: started\n",
      "  Running setup.py bdist_wheel for pydot: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
      "  Running setup.py bdist_wheel for dill: started\n",
      "  Running setup.py bdist_wheel for dill: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/5b/d7/0f/e58eae695403de585269f4e4a94e0cd6ca60ec0c202936fa4a\n",
      "  Running setup.py bdist_wheel for httplib2: started\n",
      "  Running setup.py bdist_wheel for httplib2: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/1b/9c/9e/1f6fdb21dbb1fe6a99101d697f12cb8c1fa96c1587df69adba\n",
      "  Running setup.py bdist_wheel for hdfs: started\n",
      "  Running setup.py bdist_wheel for hdfs: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/99/3f/b2/a09631bd4e2220031fa88949f4acc010cc48cc29011cb25922\n",
      "  Running setup.py bdist_wheel for docopt: started\n",
      "  Running setup.py bdist_wheel for docopt: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/9b/04/dd/7daf4150b6d9b12949298737de9431a324d4b797ffd63f526e\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1: started\n",
      "  Running setup.py bdist_wheel for grpc-google-iam-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/b6/c6/31/c20321a5a3fde456fc375b7c2814135e6e98bc0d74c40239d9\n",
      "Successfully built pyvcf pydot dill httplib2 hdfs docopt grpc-google-iam-v1\n",
      "Installing collected packages: pyvcf, pydot, dill, pyarrow, typing, httplib2, fastavro, docopt, hdfs, monotonic, fasteners, google-apitools, google-api-core, google-cloud-bigquery, grpc-google-iam-v1, google-cloud-bigtable, google-cloud-pubsub, apache-beam\n",
      "  Found existing installation: dill 0.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.6.8\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\r",
      "openssl-1.0.2r       | 3.2 MB    |            |   0% \r",
      "openssl-1.0.2r       | 3.2 MB    | #######6   |  76% \r",
      "openssl-1.0.2r       | 3.2 MB    | ########9  |  89% \r",
      "openssl-1.0.2r       | 3.2 MB    | #########9 | 100% \r",
      "openssl-1.0.2r       | 3.2 MB    | ########## | 100% \n",
      "\r",
      "certifi-2019.3.9     | 155 KB    |            |   0% \r",
      "certifi-2019.3.9     | 155 KB    | ########## | 100% \n",
      "\r",
      "ca-certificates-2019 | 126 KB    |            |   0% \r",
      "ca-certificates-2019 | 126 KB    | ########## | 100% \n",
      "google-cloud-monitoring 0.28.0 has requirement google-api-core<0.2.0dev,>=0.1.1, but you'll have google-api-core 1.8.1 which is incompatible.\n",
      "googledatastore 7.0.1 has requirement httplib2<0.10,>=0.9.1, but you'll have httplib2 0.11.3 which is incompatible.\n",
      "Cannot uninstall 'dill'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source activate py2env\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "conda install -y pytz==2018.4\n",
    "pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /usr/local\n",
      "\n",
      "  added / updated specs: \n",
      "    - conda\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openssl-1.1.1b             |       h7b6447c_1         4.0 MB  defaults\n",
      "    conda-4.6.8                |           py27_0         1.6 MB  defaults\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.6 MB\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "    ca-certificates: 2018.03.07-0      defaults --> 2019.1.23-0       defaults\n",
      "    certifi:         2018.11.29-py27_0 defaults --> 2019.3.9-py27_0   defaults\n",
      "    conda:           4.5.12-py27_0     defaults --> 4.6.8-py27_0      defaults\n",
      "    openssl:         1.1.1a-h7b6447c_0 defaults --> 1.1.1b-h7b6447c_1 defaults\n",
      "\n",
      "Proceed ([y]/n)? \n",
      "\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "openssl-1.1.1b       | 4.0 MB    |            |   0% \r",
      "openssl-1.1.1b       | 4.0 MB    | #######6   |  77% \r",
      "openssl-1.1.1b       | 4.0 MB    | #########9 |  99% \r",
      "openssl-1.1.1b       | 4.0 MB    | ########## | 100% \n",
      "\r",
      "conda-4.6.8          | 1.6 MB    |            |   0% \r",
      "conda-4.6.8          | 1.6 MB    | #######8   |  78% \r",
      "conda-4.6.8          | 1.6 MB    | #########  |  90% \r",
      "conda-4.6.8          | 1.6 MB    | #########9 | 100% \r",
      "conda-4.6.8          | 1.6 MB    | ########## | 100% \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "conda update -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-cloud-dataflow\n",
      "  Downloading https://files.pythonhosted.org/packages/72/29/3aaa67a276bcb07c3e85a6048b4d9610542082d262256cd6d232d6a8c00a/google-cloud-dataflow-2.5.0.tar.gz\n",
      "Collecting apache-beam[gcp]==2.5.0 (from google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/10/a59ba412f71fb65412ec7a322de6331e19ec8e75ca45eba7a0708daae31a/apache_beam-2.5.0-cp27-cp27mu-manylinux1_x86_64.whl (2.2MB)\n",
      "Collecting httplib2<0.10,>=0.8 (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/a9/5751cdf17a70ea89f6dde23ceb1705bfb638fd8cee00f845308bf8d26397/httplib2-0.9.2.tar.gz (205kB)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2.2.0)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (3.13)\n",
      "Collecting typing<3.7.0,>=3.6.0 (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/cc/3e/29f92b7aeda5b078c86d14f550bf85cff809042e3429ace7af6193c3bc9f/typing-3.6.6-py2-none-any.whl\n",
      "Requirement already satisfied: dill==0.2.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.2.6)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2018.4)\n",
      "Requirement already satisfied: pyvcf<0.7.0,>=0.6.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.6.8)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.16.0)\n",
      "Requirement already satisfied: avro<2.0.0,>=1.8.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.8.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.7)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2.0.0)\n",
      "Requirement already satisfied: futures<4.0.0,>=3.1.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (3.2.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.17.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (3.6.1)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "Requirement already satisfied: six<1.12,>=1.9 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.10.0)\n",
      "Collecting google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\" (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/0c/64f84f91643f775fdb64c6c10f4a4f0d827f8b0d98a2ba2b4bb9dc2f8646/google_apitools-0.5.20-py2-none-any.whl (330kB)\n",
      "Collecting proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\" (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/c0/a2/2eeffa0069830f00016196dfdd69491cf562372b5353f2e8e378b3c2cb0a/proto-google-cloud-pubsub-v1-0.15.4.tar.gz\n",
      "Collecting google-cloud-bigquery==0.25.0; extra == \"gcp\" (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/76/67/6165c516ff6ceaa62eb61f11d8451e1b0acc4d3775e181630aba9652babb/google_cloud_bigquery-0.25.0-py2.py3-none-any.whl (41kB)\n",
      "Collecting google-cloud-pubsub==0.26.0; extra == \"gcp\" (from apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/37/92/c74a643126d58505daec9addf872dfaffea3305981b90cc435f4b9213cdd/google_cloud_pubsub-0.26.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: googledatastore==7.0.1; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (7.0.1)\n",
      "Requirement already satisfied: proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.90.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.2.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (3.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyvcf<0.7.0,>=0.6.8->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (40.6.3)\n",
      "Requirement already satisfied: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (5.1.1)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2,>=1.8->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.1.6)\n",
      "Requirement already satisfied: requests>=2.7.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2.18.4)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "Collecting fasteners>=0.14 (from google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/3a/096c7ad18e102d4f219f5dd15951f9728ca5092a3385d2e8f79a7c1e1017/fasteners-0.14.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.5.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.5.5)\n",
      "Collecting google-cloud-core<0.26dev,>=0.25.0 (from google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/ef/dd/00e90bd1f6788f06ca5ea83a0ec8dd76350b38303bb8f09d2bf692eb1294/google_cloud_core-0.25.0-py2.py3-none-any.whl (52kB)\n",
      "Collecting gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0 (from google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a7/0225bd7a95e037a0afa90b2dd9534d0c79cd62283a5bddb30a3197579cbc/gapic-google-cloud-pubsub-v1-0.15.4.tar.gz\n",
      "Requirement already satisfied: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock<3.0.0,>=1.0.1->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2019.3.9)\n",
      "Collecting monotonic>=0.1 (from fasteners>=0.14->google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Using cached https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (0.0.3)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (1.6.2)\n",
      "Collecting google-gax<0.16dev,>=0.15.7 (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/b4/ff312fa42f91535c67567c1d08e972db0e7c548e9a63c6f3bcc5213b32fc/google_gax-0.15.16-py2.py3-none-any.whl (46kB)\n",
      "Collecting grpc-google-iam-v1<0.12dev,>=0.11.1 (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow) (2.1.0)\n",
      "Collecting ply==3.8 (from google-gax<0.16dev,>=0.15.7->gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]==2.5.0->google-cloud-dataflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/e0/430fcdb6b3ef1ae534d231397bee7e9304be14a47a267e82ebcb3323d0b5/ply-3.8.tar.gz (157kB)\n",
      "Building wheels for collected packages: google-cloud-dataflow, httplib2, proto-google-cloud-pubsub-v1, gapic-google-cloud-pubsub-v1, ply\n",
      "  Running setup.py bdist_wheel for google-cloud-dataflow: started\n",
      "  Running setup.py bdist_wheel for google-cloud-dataflow: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/76/31/36/1afb5551fe877ad8649343c5933b032b34470a8dfceff47914\n",
      "  Running setup.py bdist_wheel for httplib2: started\n",
      "  Running setup.py bdist_wheel for httplib2: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/36/f2/49/5adbf90fba31e02a7784e1147d7f8b6c4af3718739e568c8cb\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-pubsub-v1: started\n",
      "  Running setup.py bdist_wheel for proto-google-cloud-pubsub-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/d1/0d/9e/95e7192ab2625847ac40b2bc618800bf5b6c984cd572a83314\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-pubsub-v1: started\n",
      "  Running setup.py bdist_wheel for gapic-google-cloud-pubsub-v1: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/f4/2b/10/bdcbc9be2ae4e437232e118056f026025cf2cc46d6dcf0d69d\n",
      "  Running setup.py bdist_wheel for ply: started\n",
      "  Running setup.py bdist_wheel for ply: finished with status 'done'\n",
      "  Stored in directory: /content/.cache/pip/wheels/f2/21/c0/f0056cc96847933daa961a19eb59a2ecd0228fdbe3376e7a68\n",
      "Successfully built google-cloud-dataflow httplib2 proto-google-cloud-pubsub-v1 gapic-google-cloud-pubsub-v1 ply\n",
      "Installing collected packages: httplib2, typing, docopt, hdfs, monotonic, fasteners, google-apitools, proto-google-cloud-pubsub-v1, google-cloud-core, google-cloud-bigquery, ply, google-gax, grpc-google-iam-v1, gapic-google-cloud-pubsub-v1, google-cloud-pubsub, apache-beam, google-cloud-dataflow\n",
      "  Found existing installation: httplib2 0.12.0\n",
      "    Uninstalling httplib2-0.12.0:\n",
      "      Successfully uninstalled httplib2-0.12.0\n",
      "  Found existing installation: google-apitools 0.5.10\n",
      "    Uninstalling google-apitools-0.5.10:\n",
      "      Successfully uninstalled google-apitools-0.5.10\n",
      "  Found existing installation: google-cloud-core 0.28.1\n",
      "    Uninstalling google-cloud-core-0.28.1:\n",
      "      Successfully uninstalled google-cloud-core-0.28.1\n",
      "  Found existing installation: google-cloud-bigquery 0.23.0\n",
      "    Uninstalling google-cloud-bigquery-0.23.0:\n",
      "      Successfully uninstalled google-cloud-bigquery-0.23.0\n",
      "Successfully installed apache-beam-2.5.0 docopt-0.6.2 fasteners-0.14.1 gapic-google-cloud-pubsub-v1-0.15.4 google-apitools-0.5.20 google-cloud-bigquery-0.25.0 google-cloud-core-0.25.0 google-cloud-dataflow-2.5.0 google-cloud-pubsub-0.26.0 google-gax-0.15.16 grpc-google-iam-v1-0.11.4 hdfs-2.2.2 httplib2-0.9.2 monotonic-1.5 ply-3.8 proto-google-cloud-pubsub-v1-0.15.4 typing-3.6.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pandas-gbq 0.3.0 has requirement google-cloud-bigquery>=0.28.0, but you'll have google-cloud-bigquery 0.25.0 which is incompatible.\n",
      "google-cloud-monitoring 0.28.0 has requirement google-cloud-core<0.29dev,>=0.28.0, but you'll have google-cloud-core 0.25.0 which is incompatible.\n",
      "datalab 1.1.3 has requirement httplib2>=0.10.3, but you'll have httplib2 0.9.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install google-cloud-dataflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling google-cloud-dataflow-2.5.0:\n",
      "  Successfully uninstalled google-cloud-dataflow-2.5.0\n",
      "Collecting package metadata: ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: apache-beam[gcp] in /usr/local/envs/py2env/lib/python2.7/site-packages (2.5.0)\n",
      "Requirement already satisfied: httplib2<0.10,>=0.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.9.2)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2.2.0)\n",
      "Requirement already satisfied: pyyaml<4.0.0,>=3.12 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.13)\n",
      "Requirement already satisfied: typing<3.7.0,>=3.6.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.6.6)\n",
      "Requirement already satisfied: dill==0.2.6 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.2.6)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2018.4)\n",
      "Requirement already satisfied: pyvcf<0.7.0,>=0.6.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.6.8)\n",
      "Requirement already satisfied: future<1.0.0,>=0.16.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.16.0)\n",
      "Requirement already satisfied: avro<2.0.0,>=1.8.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.8.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.7)\n",
      "Requirement already satisfied: mock<3.0.0,>=1.0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2.0.0)\n",
      "Requirement already satisfied: futures<4.0.0,>=3.1.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.2.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.17.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.5.0.post1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (3.6.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (2.2.2)\n",
      "Requirement already satisfied: six<1.12,>=1.9 in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (1.10.0)\n",
      "Requirement already satisfied: google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.5.20)\n",
      "Requirement already satisfied: proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.15.4)\n",
      "Requirement already satisfied: google-cloud-bigquery==0.25.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.25.0)\n",
      "Requirement already satisfied: google-cloud-pubsub==0.26.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.26.0)\n",
      "Requirement already satisfied: googledatastore==7.0.1; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (7.0.1)\n",
      "Requirement already satisfied: proto-google-cloud-datastore-v1<=0.90.4,>=0.90.0; extra == \"gcp\" in /usr/local/envs/py2env/lib/python2.7/site-packages (from apache-beam[gcp]) (0.90.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]) (0.4.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]) (0.2.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from oauth2client<5,>=2.0.1->apache-beam[gcp]) (3.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py2env/lib/python2.7/site-packages (from pyvcf<0.7.0,>=0.6.8->apache-beam[gcp]) (40.6.3)\n",
      "Requirement already satisfied: funcsigs>=1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]) (1.0.0)\n",
      "Requirement already satisfied: pbr>=0.11 in /usr/local/envs/py2env/lib/python2.7/site-packages (from mock<3.0.0,>=1.0.1->apache-beam[gcp]) (5.1.1)\n",
      "Requirement already satisfied: enum34>=1.0.4 in /usr/local/envs/py2env/lib/python2.7/site-packages (from grpcio<2,>=1.8->apache-beam[gcp]) (1.1.6)\n",
      "Requirement already satisfied: requests>=2.7.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2.18.4)\n",
      "Requirement already satisfied: docopt in /usr/local/envs/py2env/lib/python2.7/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (0.6.2)\n",
      "Requirement already satisfied: fasteners>=0.14 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]) (0.14.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.5.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from proto-google-cloud-pubsub-v1==0.15.4; extra == \"gcp\"->apache-beam[gcp]) (1.5.5)\n",
      "Requirement already satisfied: google-cloud-core<0.26dev,>=0.25.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]) (0.25.0)\n",
      "Requirement already satisfied: gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]) (0.15.4)\n",
      "Requirement already satisfied: ordereddict in /usr/local/envs/py2env/lib/python2.7/site-packages (from funcsigs>=1->mock<3.0.0,>=1.0.1->apache-beam[gcp]) (1.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/envs/py2env/lib/python2.7/site-packages (from requests>=2.7.0->hdfs<3.0.0,>=2.1.0->apache-beam[gcp]) (2019.3.9)\n",
      "Requirement already satisfied: monotonic>=0.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from fasteners>=0.14->google-apitools<=0.5.20,>=0.5.18; extra == \"gcp\"->apache-beam[gcp]) (1.5)\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]) (0.0.3)\n",
      "Requirement already satisfied: google-auth<2.0.0dev,>=0.4.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]) (1.6.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<0.12dev,>=0.11.1 in /usr/local/envs/py2env/lib/python2.7/site-packages (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]) (0.11.4)\n",
      "Requirement already satisfied: google-gax<0.16dev,>=0.15.7 in /usr/local/envs/py2env/lib/python2.7/site-packages (from gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]) (0.15.16)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-auth<2.0.0dev,>=0.4.0->google-cloud-core<0.26dev,>=0.25.0->google-cloud-bigquery==0.25.0; extra == \"gcp\"->apache-beam[gcp]) (2.1.0)\n",
      "Requirement already satisfied: ply==3.8 in /usr/local/envs/py2env/lib/python2.7/site-packages (from google-gax<0.16dev,>=0.15.7->gapic-google-cloud-pubsub-v1<0.16dev,>=0.15.0->google-cloud-pubsub==0.26.0; extra == \"gcp\"->apache-beam[gcp]) (3.8)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "source activate py2env\n",
    "pip uninstall -y google-cloud-dataflow\n",
    "conda install -y pytz==2018.4\n",
    "pip install apache-beam[gcp]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now restart notebook's session kernel!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-ca86714dede2236a\n",
      "qwiklabs-gcp-ca86714dede2236a\n",
      "europe-west1\n"
     ]
    }
   ],
   "source": [
    "# Import helpful libraries and setup our project, bucket, and region\n",
    "import os\n",
    "\n",
    "output = os.popen(\"gcloud config get-value project\").readlines()\n",
    "project_name = output[0][:-1]\n",
    "\n",
    "# change these to try this notebook out\n",
    "PROJECT = project_name\n",
    "BUCKET = project_name\n",
    "#BUCKET = BUCKET.replace(\"qwiklabs-gcp-\", \"inna-bckt-\")\n",
    "REGION = 'europe-west1'  ## note: Cloud ML Engine not availabe in europe-west3!\n",
    "\n",
    "print(PROJECT)\n",
    "print(BUCKET)\n",
    "print(REGION)\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create ML dataset using Dataflow </h2>\n",
    "Let's use Cloud Dataflow to read in the BigQuery data, do some preprocessing, and write it out as CSV files.\n",
    "\n",
    "First, let's create our hybrid dataset query that we will use in our Cloud Dataflow pipeline. This will combine some content-based features and the user and item embeddings learned from our WALS Matrix Factorization Collaborative filtering lab that we extracted from our trained WALSMatrixFactorization Estimator and uploaded to BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_hybrid_dataset = \"\"\"\n",
    "WITH CTE_site_history AS (\n",
    "  SELECT\n",
    "      fullVisitorId as visitor_id,\n",
    "      (SELECT MAX(IF(index = 10, value, NULL)) FROM UNNEST(hits.customDimensions)) AS content_id,\n",
    "      (SELECT MAX(IF(index = 7, value, NULL)) FROM UNNEST(hits.customDimensions)) AS category, \n",
    "      (SELECT MAX(IF(index = 6, value, NULL)) FROM UNNEST(hits.customDimensions)) AS title,\n",
    "      (SELECT MAX(IF(index = 2, value, NULL)) FROM UNNEST(hits.customDimensions)) AS author_list,\n",
    "      SPLIT(RPAD((SELECT MAX(IF(index = 4, value, NULL)) FROM UNNEST(hits.customDimensions)), 7), '.') AS year_month_array,\n",
    "      LEAD(hits.customDimensions, 1) OVER (PARTITION BY fullVisitorId ORDER BY hits.time ASC) AS nextCustomDimensions\n",
    "  FROM \n",
    "    `cloud-training-demos.GA360_test.ga_sessions_sample`,   \n",
    "     UNNEST(hits) AS hits\n",
    "   WHERE \n",
    "     # only include hits on pages\n",
    "      hits.type = \"PAGE\"\n",
    "      AND\n",
    "      fullVisitorId IS NOT NULL\n",
    "      AND\n",
    "      hits.time != 0\n",
    "      AND\n",
    "      hits.time IS NOT NULL\n",
    "      AND\n",
    "      (SELECT MAX(IF(index = 10, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "),\n",
    "CTE_training_dataset AS (\n",
    "SELECT\n",
    "  (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) AS next_content_id,\n",
    "  \n",
    "  visitor_id,\n",
    "  content_id,\n",
    "  category,\n",
    "  REGEXP_REPLACE(title, r\",\", \"\") AS title,\n",
    "  REGEXP_EXTRACT(author_list, r\"^[^,]+\") AS author,\n",
    "  DATE_DIFF(DATE(CAST(year_month_array[OFFSET(0)] AS INT64), CAST(year_month_array[OFFSET(1)] AS INT64), 1), DATE(1970, 1, 1), MONTH) AS months_since_epoch\n",
    "FROM\n",
    "  CTE_site_history\n",
    "WHERE (SELECT MAX(IF(index=10, value, NULL)) FROM UNNEST(nextCustomDimensions)) IS NOT NULL)\n",
    "\n",
    "SELECT\n",
    "  CAST(next_content_id AS STRING) AS next_content_id,\n",
    "  \n",
    "  CAST(training_dataset.visitor_id AS STRING) AS visitor_id,\n",
    "  CAST(training_dataset.content_id AS STRING) AS content_id,\n",
    "  CAST(IFNULL(category, 'None') AS STRING) AS category,\n",
    "  CONCAT(\"\\\\\"\", REPLACE(TRIM(CAST(IFNULL(title, 'None') AS STRING)), \"\\\\\"\",\"\"), \"\\\\\"\") AS title,\n",
    "  CAST(IFNULL(author, 'None') AS STRING) AS author,\n",
    "  CAST(months_since_epoch AS STRING) AS months_since_epoch,\n",
    "  \n",
    "  IFNULL(user_factors._0, 0.0) AS user_factor_0,\n",
    "  IFNULL(user_factors._1, 0.0) AS user_factor_1,\n",
    "  IFNULL(user_factors._2, 0.0) AS user_factor_2,\n",
    "  IFNULL(user_factors._3, 0.0) AS user_factor_3,\n",
    "  IFNULL(user_factors._4, 0.0) AS user_factor_4,\n",
    "  IFNULL(user_factors._5, 0.0) AS user_factor_5,\n",
    "  IFNULL(user_factors._6, 0.0) AS user_factor_6,\n",
    "  IFNULL(user_factors._7, 0.0) AS user_factor_7,\n",
    "  IFNULL(user_factors._8, 0.0) AS user_factor_8,\n",
    "  IFNULL(user_factors._9, 0.0) AS user_factor_9,\n",
    "  \n",
    "  IFNULL(item_factors._0, 0.0) AS item_factor_0,\n",
    "  IFNULL(item_factors._1, 0.0) AS item_factor_1,\n",
    "  IFNULL(item_factors._2, 0.0) AS item_factor_2,\n",
    "  IFNULL(item_factors._3, 0.0) AS item_factor_3,\n",
    "  IFNULL(item_factors._4, 0.0) AS item_factor_4,\n",
    "  IFNULL(item_factors._5, 0.0) AS item_factor_5,\n",
    "  IFNULL(item_factors._6, 0.0) AS item_factor_6,\n",
    "  IFNULL(item_factors._7, 0.0) AS item_factor_7,\n",
    "  IFNULL(item_factors._8, 0.0) AS item_factor_8,\n",
    "  IFNULL(item_factors._9, 0.0) AS item_factor_9,\n",
    "  \n",
    "  FARM_FINGERPRINT(CONCAT(CAST(visitor_id AS STRING), CAST(content_id AS STRING))) AS hash_id\n",
    "FROM CTE_training_dataset AS training_dataset\n",
    "LEFT JOIN `cloud-training-demos.GA360_test.user_factors` AS user_factors\n",
    "  ON CAST(training_dataset.visitor_id AS FLOAT64) = CAST(user_factors.user_id AS FLOAT64)\n",
    "LEFT JOIN `cloud-training-demos.GA360_test.item_factors` AS item_factors\n",
    "  ON CAST(training_dataset.content_id AS STRING) = CAST(item_factors.item_id AS STRING)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull a sample of our data into a dataframe to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_content_id</th>\n",
       "      <th>visitor_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>months_since_epoch</th>\n",
       "      <th>user_factor_0</th>\n",
       "      <th>user_factor_1</th>\n",
       "      <th>user_factor_2</th>\n",
       "      <th>...</th>\n",
       "      <th>item_factor_1</th>\n",
       "      <th>item_factor_2</th>\n",
       "      <th>item_factor_3</th>\n",
       "      <th>item_factor_4</th>\n",
       "      <th>item_factor_5</th>\n",
       "      <th>item_factor_6</th>\n",
       "      <th>item_factor_7</th>\n",
       "      <th>item_factor_8</th>\n",
       "      <th>item_factor_9</th>\n",
       "      <th>hash_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>299837992</td>\n",
       "      <td>1000593816586876859</td>\n",
       "      <td>230814320</td>\n",
       "      <td>Stars &amp; Kultur</td>\n",
       "      <td>\"Kritik an Meghan Markle immer lauter\"</td>\n",
       "      <td>Elisabeth Spitzer</td>\n",
       "      <td>562</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.335446e-14</td>\n",
       "      <td>1.702269e-13</td>\n",
       "      <td>6.061748e-14</td>\n",
       "      <td>-5.093584e-16</td>\n",
       "      <td>-7.285724e-14</td>\n",
       "      <td>-1.158683e-13</td>\n",
       "      <td>-1.558101e-13</td>\n",
       "      <td>2.011165e-13</td>\n",
       "      <td>1.281463e-14</td>\n",
       "      <td>4641499907841586690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299826767</td>\n",
       "      <td>1001769331926555188</td>\n",
       "      <td>299836255</td>\n",
       "      <td>News</td>\n",
       "      <td>\"Blümel Kneissl &amp;Co.: Das sind die Fixstarter\"</td>\n",
       "      <td>None</td>\n",
       "      <td>574</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.072439e-05</td>\n",
       "      <td>7.677825e-04</td>\n",
       "      <td>1.595652e-04</td>\n",
       "      <td>3.168983e-04</td>\n",
       "      <td>-4.565390e-04</td>\n",
       "      <td>1.829965e-04</td>\n",
       "      <td>-6.903299e-04</td>\n",
       "      <td>8.621884e-04</td>\n",
       "      <td>1.151190e-04</td>\n",
       "      <td>-3618990996027508246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>299921761</td>\n",
       "      <td>1001769331926555188</td>\n",
       "      <td>299826767</td>\n",
       "      <td>Lifestyle</td>\n",
       "      <td>\"Titanic-Regisseur: Darum musste Jack sterben\"</td>\n",
       "      <td>Elisabeth Mittendorfer</td>\n",
       "      <td>574</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8356988980360872262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299912085</td>\n",
       "      <td>1001769331926555188</td>\n",
       "      <td>299921761</td>\n",
       "      <td>News</td>\n",
       "      <td>\"Bitcoin knackt 10.000-Dollar-Marke\"</td>\n",
       "      <td>Stefan Hofer</td>\n",
       "      <td>574</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>...</td>\n",
       "      <td>1.847323e+01</td>\n",
       "      <td>8.823291e+00</td>\n",
       "      <td>1.486902e+01</td>\n",
       "      <td>5.051981e+00</td>\n",
       "      <td>1.510309e+01</td>\n",
       "      <td>4.637218e+01</td>\n",
       "      <td>-2.384849e+01</td>\n",
       "      <td>-1.216274e+01</td>\n",
       "      <td>1.594312e+01</td>\n",
       "      <td>1549964685624042309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>299836841</td>\n",
       "      <td>1001769331926555188</td>\n",
       "      <td>299912085</td>\n",
       "      <td>News</td>\n",
       "      <td>\"Erster ÖBB-Containerzug nach China unterwegs\"</td>\n",
       "      <td>Stefan Hofer</td>\n",
       "      <td>574</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>-0.001529</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.662306e-12</td>\n",
       "      <td>-1.106192e-11</td>\n",
       "      <td>-1.411706e-11</td>\n",
       "      <td>5.926889e-12</td>\n",
       "      <td>-1.093412e-11</td>\n",
       "      <td>4.748844e-12</td>\n",
       "      <td>8.567720e-12</td>\n",
       "      <td>7.530454e-12</td>\n",
       "      <td>1.197553e-11</td>\n",
       "      <td>731115923694303975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  next_content_id           visitor_id content_id        category  \\\n",
       "0       299837992  1000593816586876859  230814320  Stars & Kultur   \n",
       "1       299826767  1001769331926555188  299836255            News   \n",
       "2       299921761  1001769331926555188  299826767       Lifestyle   \n",
       "3       299912085  1001769331926555188  299921761            News   \n",
       "4       299836841  1001769331926555188  299912085            News   \n",
       "\n",
       "                                            title                  author  \\\n",
       "0          \"Kritik an Meghan Markle immer lauter\"       Elisabeth Spitzer   \n",
       "1  \"Blümel Kneissl &Co.: Das sind die Fixstarter\"                    None   \n",
       "2  \"Titanic-Regisseur: Darum musste Jack sterben\"  Elisabeth Mittendorfer   \n",
       "3            \"Bitcoin knackt 10.000-Dollar-Marke\"            Stefan Hofer   \n",
       "4  \"Erster ÖBB-Containerzug nach China unterwegs\"            Stefan Hofer   \n",
       "\n",
       "  months_since_epoch  user_factor_0  user_factor_1  user_factor_2  \\\n",
       "0                562       0.000592       0.000627      -0.000848   \n",
       "1                574       0.000749       0.000923      -0.001529   \n",
       "2                574       0.000749       0.000923      -0.001529   \n",
       "3                574       0.000749       0.000923      -0.001529   \n",
       "4                574       0.000749       0.000923      -0.001529   \n",
       "\n",
       "          ...           item_factor_1  item_factor_2  item_factor_3  \\\n",
       "0         ...           -2.335446e-14   1.702269e-13   6.061748e-14   \n",
       "1         ...           -5.072439e-05   7.677825e-04   1.595652e-04   \n",
       "2         ...            0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "3         ...            1.847323e+01   8.823291e+00   1.486902e+01   \n",
       "4         ...           -6.662306e-12  -1.106192e-11  -1.411706e-11   \n",
       "\n",
       "   item_factor_4  item_factor_5  item_factor_6  item_factor_7  item_factor_8  \\\n",
       "0  -5.093584e-16  -7.285724e-14  -1.158683e-13  -1.558101e-13   2.011165e-13   \n",
       "1   3.168983e-04  -4.565390e-04   1.829965e-04  -6.903299e-04   8.621884e-04   \n",
       "2   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   0.000000e+00   \n",
       "3   5.051981e+00   1.510309e+01   4.637218e+01  -2.384849e+01  -1.216274e+01   \n",
       "4   5.926889e-12  -1.093412e-11   4.748844e-12   8.567720e-12   7.530454e-12   \n",
       "\n",
       "   item_factor_9              hash_id  \n",
       "0   1.281463e-14  4641499907841586690  \n",
       "1   1.151190e-04 -3618990996027508246  \n",
       "2   0.000000e+00 -8356988980360872262  \n",
       "3   1.594312e+01  1549964685624042309  \n",
       "4   1.197553e-11   731115923694303975  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "df_hybrid_dataset = bq.Query(query_hybrid_dataset + \"LIMIT 100\").execute().result().to_dataframe()\n",
    "df_hybrid_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_factor_0</th>\n",
       "      <th>user_factor_1</th>\n",
       "      <th>user_factor_2</th>\n",
       "      <th>user_factor_3</th>\n",
       "      <th>user_factor_4</th>\n",
       "      <th>user_factor_5</th>\n",
       "      <th>user_factor_6</th>\n",
       "      <th>user_factor_7</th>\n",
       "      <th>user_factor_8</th>\n",
       "      <th>user_factor_9</th>\n",
       "      <th>...</th>\n",
       "      <th>item_factor_1</th>\n",
       "      <th>item_factor_2</th>\n",
       "      <th>item_factor_3</th>\n",
       "      <th>item_factor_4</th>\n",
       "      <th>item_factor_5</th>\n",
       "      <th>item_factor_6</th>\n",
       "      <th>item_factor_7</th>\n",
       "      <th>item_factor_8</th>\n",
       "      <th>item_factor_9</th>\n",
       "      <th>hash_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>1.000000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>-3.461505e-04</td>\n",
       "      <td>-0.001118</td>\n",
       "      <td>-0.000110</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>-0.000347</td>\n",
       "      <td>7.827963e-04</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>...</td>\n",
       "      <td>5.248210e-01</td>\n",
       "      <td>-1.213014e-01</td>\n",
       "      <td>1.451377e-01</td>\n",
       "      <td>-8.779055e-02</td>\n",
       "      <td>3.551918e-01</td>\n",
       "      <td>1.528627e-01</td>\n",
       "      <td>-3.217224e-01</td>\n",
       "      <td>1.274825e-01</td>\n",
       "      <td>5.698840e-02</td>\n",
       "      <td>3.813501e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>1.405995e-03</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>1.600359e-03</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>...</td>\n",
       "      <td>3.702127e+00</td>\n",
       "      <td>2.453433e+00</td>\n",
       "      <td>1.491142e+00</td>\n",
       "      <td>1.174458e+00</td>\n",
       "      <td>2.399064e+00</td>\n",
       "      <td>5.682699e+00</td>\n",
       "      <td>2.435434e+00</td>\n",
       "      <td>2.951234e+00</td>\n",
       "      <td>1.955282e+00</td>\n",
       "      <td>5.393236e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.002702</td>\n",
       "      <td>-0.001083</td>\n",
       "      <td>-3.664789e-03</td>\n",
       "      <td>-0.005264</td>\n",
       "      <td>-0.002658</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.003360</td>\n",
       "      <td>-0.004766</td>\n",
       "      <td>-2.352181e-03</td>\n",
       "      <td>-0.006290</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.886719e-02</td>\n",
       "      <td>-2.270137e+01</td>\n",
       "      <td>-6.738291e-01</td>\n",
       "      <td>-1.019035e+01</td>\n",
       "      <td>-1.282159e-01</td>\n",
       "      <td>-3.237039e+01</td>\n",
       "      <td>-2.384849e+01</td>\n",
       "      <td>-1.216274e+01</td>\n",
       "      <td>-1.115637e+01</td>\n",
       "      <td>-9.124378e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.000357</td>\n",
       "      <td>-0.000337</td>\n",
       "      <td>-8.085197e-04</td>\n",
       "      <td>-0.002280</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.000053</td>\n",
       "      <td>-0.000739</td>\n",
       "      <td>-0.001188</td>\n",
       "      <td>-6.077433e-08</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.268464e-16</td>\n",
       "      <td>-7.290205e-17</td>\n",
       "      <td>-2.123815e-05</td>\n",
       "      <td>-1.145930e-03</td>\n",
       "      <td>-2.168568e-08</td>\n",
       "      <td>-3.884151e-15</td>\n",
       "      <td>-1.959489e-03</td>\n",
       "      <td>-2.505747e-14</td>\n",
       "      <td>-2.548617e-15</td>\n",
       "      <td>-4.253324e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>-3.112987e-04</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>3.225584e-04</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.627039e-26</td>\n",
       "      <td>2.244701e-16</td>\n",
       "      <td>-7.865934e-23</td>\n",
       "      <td>-3.780486e-16</td>\n",
       "      <td>-8.690795e-28</td>\n",
       "      <td>3.645398e-21</td>\n",
       "      <td>-9.524429e-16</td>\n",
       "      <td>2.543406e-24</td>\n",
       "      <td>1.783951e-24</td>\n",
       "      <td>7.393969e+17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.001067</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>3.298481e-07</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>1.384437e-03</td>\n",
       "      <td>0.001526</td>\n",
       "      <td>...</td>\n",
       "      <td>1.043613e-04</td>\n",
       "      <td>1.528129e-05</td>\n",
       "      <td>6.483593e-14</td>\n",
       "      <td>1.195606e-17</td>\n",
       "      <td>6.438866e-13</td>\n",
       "      <td>1.829965e-04</td>\n",
       "      <td>3.399927e-20</td>\n",
       "      <td>1.580518e-06</td>\n",
       "      <td>2.364778e-04</td>\n",
       "      <td>4.983149e+18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>3.817978e-03</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.003383</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>4.557515e-03</td>\n",
       "      <td>0.004465</td>\n",
       "      <td>...</td>\n",
       "      <td>3.229185e+01</td>\n",
       "      <td>8.823291e+00</td>\n",
       "      <td>1.486902e+01</td>\n",
       "      <td>5.051981e+00</td>\n",
       "      <td>1.877586e+01</td>\n",
       "      <td>4.637218e+01</td>\n",
       "      <td>1.651876e-02</td>\n",
       "      <td>2.671273e+01</td>\n",
       "      <td>1.594312e+01</td>\n",
       "      <td>8.962769e+18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_factor_0  user_factor_1  user_factor_2  user_factor_3  \\\n",
       "count     100.000000     100.000000   1.000000e+02     100.000000   \n",
       "mean        0.000231       0.000559  -3.461505e-04      -0.001118   \n",
       "std         0.001241       0.001661   1.405995e-03       0.001622   \n",
       "min        -0.002702      -0.001083  -3.664789e-03      -0.005264   \n",
       "25%        -0.000357      -0.000337  -8.085197e-04      -0.002280   \n",
       "50%         0.000353       0.000137  -3.112987e-04      -0.000554   \n",
       "75%         0.001067       0.000785   3.298481e-07      -0.000103   \n",
       "max         0.003468       0.006136   3.817978e-03       0.003158   \n",
       "\n",
       "       user_factor_4  user_factor_5  user_factor_6  user_factor_7  \\\n",
       "count     100.000000     100.000000     100.000000     100.000000   \n",
       "mean       -0.000110      -0.000146      -0.000074      -0.000347   \n",
       "std         0.001246       0.001433       0.001509       0.002023   \n",
       "min        -0.002658      -0.003539      -0.003360      -0.004766   \n",
       "25%        -0.001122      -0.000053      -0.000739      -0.001188   \n",
       "50%         0.000010       0.000012      -0.000107      -0.000078   \n",
       "75%         0.000416       0.000657       0.000147       0.000147   \n",
       "max         0.003781       0.003383       0.003922       0.004065   \n",
       "\n",
       "       user_factor_8  user_factor_9      ...       item_factor_1  \\\n",
       "count   1.000000e+02     100.000000      ...        1.000000e+02   \n",
       "mean    7.827963e-04       0.000331      ...        5.248210e-01   \n",
       "std     1.600359e-03       0.002058      ...        3.702127e+00   \n",
       "min    -2.352181e-03      -0.006290      ...       -3.886719e-02   \n",
       "25%    -6.077433e-08      -0.001001      ...       -2.268464e-16   \n",
       "50%     3.225584e-04      -0.000027      ...        3.627039e-26   \n",
       "75%     1.384437e-03       0.001526      ...        1.043613e-04   \n",
       "max     4.557515e-03       0.004465      ...        3.229185e+01   \n",
       "\n",
       "       item_factor_2  item_factor_3  item_factor_4  item_factor_5  \\\n",
       "count   1.000000e+02   1.000000e+02   1.000000e+02   1.000000e+02   \n",
       "mean   -1.213014e-01   1.451377e-01  -8.779055e-02   3.551918e-01   \n",
       "std     2.453433e+00   1.491142e+00   1.174458e+00   2.399064e+00   \n",
       "min    -2.270137e+01  -6.738291e-01  -1.019035e+01  -1.282159e-01   \n",
       "25%    -7.290205e-17  -2.123815e-05  -1.145930e-03  -2.168568e-08   \n",
       "50%     2.244701e-16  -7.865934e-23  -3.780486e-16  -8.690795e-28   \n",
       "75%     1.528129e-05   6.483593e-14   1.195606e-17   6.438866e-13   \n",
       "max     8.823291e+00   1.486902e+01   5.051981e+00   1.877586e+01   \n",
       "\n",
       "       item_factor_6  item_factor_7  item_factor_8  item_factor_9  \\\n",
       "count   1.000000e+02   1.000000e+02   1.000000e+02   1.000000e+02   \n",
       "mean    1.528627e-01  -3.217224e-01   1.274825e-01   5.698840e-02   \n",
       "std     5.682699e+00   2.435434e+00   2.951234e+00   1.955282e+00   \n",
       "min    -3.237039e+01  -2.384849e+01  -1.216274e+01  -1.115637e+01   \n",
       "25%    -3.884151e-15  -1.959489e-03  -2.505747e-14  -2.548617e-15   \n",
       "50%     3.645398e-21  -9.524429e-16   2.543406e-24   1.783951e-24   \n",
       "75%     1.829965e-04   3.399927e-20   1.580518e-06   2.364778e-04   \n",
       "max     4.637218e+01   1.651876e-02   2.671273e+01   1.594312e+01   \n",
       "\n",
       "            hash_id  \n",
       "count  1.000000e+02  \n",
       "mean   3.813501e+17  \n",
       "std    5.393236e+18  \n",
       "min   -9.124378e+18  \n",
       "25%   -4.253324e+18  \n",
       "50%    7.393969e+17  \n",
       "75%    4.983149e+18  \n",
       "max    8.962769e+18  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hybrid_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job preprocess-hybrid-recommendation-features-190321-093248 ... hang on\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import datetime, os\n",
    "\n",
    "def to_csv(rowdict):\n",
    "  # Pull columns from BQ and create a line\n",
    "  import hashlib\n",
    "  import copy\n",
    "  CSV_COLUMNS = 'next_content_id,visitor_id,content_id,category,title,author,months_since_epoch'.split(',')\n",
    "  FACTOR_COLUMNS = [\"user_factor_{}\".format(i) for i in range(10)] + [\"item_factor_{}\".format(i) for i in range(10)]\n",
    "    \n",
    "  # Write out rows for each input row for each column in rowdict\n",
    "  data = ','.join(['None' if k not in rowdict else (rowdict[k].encode('utf-8') if rowdict[k] is not None else 'None') for k in CSV_COLUMNS])\n",
    "  data += ','\n",
    "  data += ','.join([str(rowdict[k]) if k in rowdict else 'None' for k in FACTOR_COLUMNS])\n",
    "  yield ('{}'.format(data))\n",
    "  \n",
    "def preprocess(in_test_mode):\n",
    "  import shutil, os, subprocess\n",
    "  job_name = 'preprocess-hybrid-recommendation-features' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "\n",
    "  if in_test_mode:\n",
    "      print('Launching local job ... hang on')\n",
    "      OUTPUT_DIR = './preproc/features'\n",
    "      shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "      os.makedirs(OUTPUT_DIR)\n",
    "  else:\n",
    "      print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "      OUTPUT_DIR = 'gs://{0}/hybrid_recommendation/preproc/features/'.format(BUCKET)\n",
    "      try:\n",
    "        subprocess.check_call('gsutil -m rm -r {}'.format(OUTPUT_DIR).split())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  options = {\n",
    "      'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "      'job_name': job_name,\n",
    "      'project': PROJECT,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'no_save_main_session': True\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags = [], **options)\n",
    "  if in_test_mode:\n",
    "    RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "    RUNNER = 'DataflowRunner'\n",
    "  p = beam.Pipeline(RUNNER, options = opts)\n",
    "  \n",
    "  query = query_hybrid_dataset\n",
    "\n",
    "  if in_test_mode:\n",
    "    query = query + ' LIMIT 100' \n",
    "\n",
    "  for step in ['train', 'eval']:\n",
    "    if step == 'train':\n",
    "      selquery = 'SELECT * FROM ({}) WHERE MOD(ABS(hash_id), 10) < 9'.format(query)\n",
    "    else:\n",
    "      selquery = 'SELECT * FROM ({}) WHERE MOD(ABS(hash_id), 10) = 9'.format(query)\n",
    "\n",
    "    (p \n",
    "     | '{}_read'.format(step) >> beam.io.Read(beam.io.BigQuerySource(query = selquery, use_standard_sql = True))\n",
    "     | '{}_csv'.format(step) >> beam.FlatMap(to_csv)\n",
    "     | '{}_out'.format(step) >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '{}.csv'.format(step))))\n",
    "    )\n",
    "\n",
    "  job = p.run()\n",
    "  if in_test_mode:\n",
    "    job.wait_until_finish()\n",
    "    print(\"Done!\")\n",
    "    \n",
    "preprocess(in_test_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our files to make sure everything went as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf features\n",
    "mkdir features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/eval.csv-00000-of-00002...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/eval.csv-00001-of-00002...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/train.csv-00000-of-00004...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/train.csv-00001-of-00004...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/train.csv-00002-of-00004...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/features/train.csv-00003-of-00004...\n",
      "| [6/6 files][114.6 MiB/114.6 MiB] 100% Done                                    \n",
      "Operation completed over 6 objects/114.6 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://{BUCKET}/hybrid_recommendation/preproc/features/*.csv* features/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> features/eval.csv-00000-of-00002 <==\r\n",
      "299965853,7041455396912725884,299935287,Lifestyle,\"Nach Manspreading: Was es mit #Womanspreading auf sich hat\",Marlene Patsalidis,574,-0.000496511696838,0.000584936060477,-0.000896223180462,-0.000102142788819,-0.000267917377641,-0.000802059425041,0.000927461369429,-0.000913450552616,-0.000238060747506,0.000163289223565,-0.406514137983,0.459142923355,1.98274052143,-0.673829138279,-2.80434513092,1.27803337574,1.03079307079,-2.11008024216,-1.51691091061,0.213096797466\r\n",
      "299907275,2977646036924619540,299935287,Lifestyle,\"Nach Manspreading: Was es mit #Womanspreading auf sich hat\",Marlene Patsalidis,574,-1.19302658277e-05,-5.02647708345e-06,-6.38119900032e-06,8.50290507515e-06,7.17811872164e-07,-5.58365354664e-06,-8.84674136614e-06,-8.21020876174e-06,-1.57803640377e-06,2.38888187596e-05,-0.406514137983,0.459142923355,1.98274052143,-0.673829138279,-2.80434513092,1.27803337574,1.03079307079,-2.11008024216,-1.51691091061,0.213096797466\r\n",
      "299925700,6542063159932192817,299935287,Lifestyle,\"Nach Manspreading: Was es mit #Womanspreading auf sich hat\",Marlene Patsalidis,574,0.000815254694317,0.000150049323565,0.00130076811183,-0.000521220092196,-0.00146829511505,-0.00242463545874,-0.00110241619404,-0.000351122813299,8.1865953689e-05,0.00173285091296,-0.406514137983,0.459142923355,1.98274052143,-0.673829138279,-2.80434513092,1.27803337574,1.03079307079,-2.11008024216,-1.51691091061,0.213096797466\r\n",
      "\r\n",
      "==> features/eval.csv-00001-of-00002 <==\r\n",
      "710535,951784927766849126,710535,News,\"Haus aus Marmor und Grabsteinen\",None,503,-0.00170100899413,0.00496714003384,0.0040482301265,0.000690933316946,3.52509268851e-05,-0.00172890012618,0.00153049221262,0.00100265210494,0.00228979066014,-0.00201142113656,-5.59943889043e-19,7.42678684608e-19,-1.3985523895e-19,3.42277049416e-19,1.11620765154e-18,2.17990091471e-18,-2.42801472173e-19,1.5953545546e-19,-1.10792405809e-18,-4.38625547901e-19\r\n",
      "714237,4674958417287013114,711895,None,\"Impressum KURIER.at\",None,553,-0.000477781286463,0.00125698221382,-0.000599682505708,0.00186442385893,-0.00068538391497,0.00188264774624,0.000171602805494,-0.000178980146302,0.000812514859717,0.00132207910065,-6.17342042923,14.5652112961,17.5528583527,3.3229033947,-44.9284629822,29.9998893738,18.7066059113,-14.6920909882,-20.3173618317,-3.7755317688\r\n",
      "711895,8640555275627058154,711895,None,\"Impressum KURIER.at\",None,553,1.48057097249e-05,-1.99350433832e-05,-1.66832815012e-05,-7.71130453359e-06,-1.61893422046e-05,1.01407499642e-06,-8.83275151864e-06,-9.23535571928e-06,-1.45201977375e-06,2.7637850053e-06,-6.17342042923,14.5652112961,17.5528583527,3.3229033947,-44.9284629822,29.9998893738,18.7066059113,-14.6920909882,-20.3173618317,-3.7755317688\r\n",
      "\r\n",
      "==> features/train.csv-00000-of-00004 <==\r\n",
      "299830996,6044355009572871726,299865757,News,\"ÖVP und FPÖ wollen zurück zu alten Noten\",None,574,-9.28566169023e-06,5.99280838287e-06,4.30472828157e-05,-2.52604986599e-05,3.30413968186e-06,-1.55880316015e-05,-2.19407684199e-05,1.12517125217e-06,2.42603728111e-05,4.13563066104e-06,-5.64447035119e-13,3.0999890697e-13,1.90860876908e-13,6.17965043286e-13,-1.72767751711e-13,6.43886582507e-13,3.06376966982e-13,-9.22291350279e-14,-2.48576712599e-13,-8.8365670033e-13\r\n",
      "299836255,6912110794700532613,299865757,News,\"ÖVP und FPÖ wollen zurück zu alten Noten\",None,574,0.00145752925891,0.000598344195168,0.00135706854053,-0.00361371575855,-0.00263477186672,0.000314119301038,0.00368467974477,0.00108709943015,0.000496758904774,0.00047040413483,-5.64447035119e-13,3.0999890697e-13,1.90860876908e-13,6.17965043286e-13,-1.72767751711e-13,6.43886582507e-13,3.06376966982e-13,-9.22291350279e-14,-2.48576712599e-13,-8.8365670033e-13\r\n",
      "299912041,7654493598365887542,299865757,News,\"ÖVP und FPÖ wollen zurück zu alten Noten\",None,574,-0.000393408874515,0.000143735145684,-5.32092235517e-05,-7.93174986029e-05,-1.53213534304e-06,4.01299621444e-05,-4.52645217592e-05,2.26457923418e-05,0.000146138947457,-6.4949519583e-05,-5.64447035119e-13,3.0999890697e-13,1.90860876908e-13,6.17965043286e-13,-1.72767751711e-13,6.43886582507e-13,3.06376966982e-13,-9.22291350279e-14,-2.48576712599e-13,-8.8365670033e-13\r\n",
      "\r\n",
      "==> features/train.csv-00001-of-00004 <==\r\n",
      "733180,4457498454949488072,709531,Lifestyle,\"Thunfisch um 566.000 Euro versteigert\",None,504,-0.00163161556702,0.00118563103024,-0.00206252280623,0.000174878616235,-0.000371386762708,8.65281617735e-05,-0.000263485824689,-0.000245551520493,-0.000876758887898,6.79314553054e-06,1.19178007307e-12,-1.84806575425e-12,-3.35243334829e-13,-1.08242776721e-12,-6.03147197985e-13,-1.35153433584e-12,-4.69212938902e-13,-1.2847801165e-12,-7.35558153015e-13,7.33802612857e-13\r\n",
      "299907275,5684576675894832060,709763,Lifestyle,\"Waris Dirie lässt die Hüllen fallen\",Christine Scharfetter,503,-0.00205975957215,0.00373387616128,0.00113246438559,-0.000466885016067,0.0015372610651,0.000233920087339,-0.00135274045169,0.0016922946088,0.000412207999034,0.00150463567115,0.000206881333725,2.95793543046e-05,-0.000242229856667,0.000110112487164,5.73702527618e-05,-0.00017226851196,0.000104810045741,-0.000244620197918,-4.43018470833e-05,1.5213982806e-05\r\n",
      "710022,5624735506447562560,710022,News,\"Ein Haus mieten: 10 Fragen und Antworten\",Ursula Horvath,503,8.51739553241e-19,-1.49731064606e-18,-1.45964714821e-18,-2.06593072915e-18,-1.03758113579e-18,-1.27542864912e-18,1.27460291608e-18,-7.53578029949e-19,-2.28097866326e-18,-3.08035173836e-18,5.99711598656e-21,-3.65828623058e-21,3.48770082798e-21,-4.89903735847e-21,2.13146753176e-21,-6.97418511884e-21,-4.76741668636e-21,-3.89970947445e-21,5.3616425589e-21,5.38330152391e-21\r\n",
      "\r\n",
      "==> features/train.csv-00002-of-00004 <==\r\n",
      "299410466,3318651034184484786,299844825,News,\"Regierungsbildung: SPD und CDU bringen sich in Stellung\",Sandra Lumetsberger,574,6.90019951435e-05,-0.000151668500621,-0.00025928998366,-7.71417398937e-06,-0.00143352814484,-0.00210466352291,0.000985754071735,-0.00154163560364,0.00101193785667,0.00103687669616,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\r\n",
      "299836841,3883024361233507463,299844825,News,\"Regierungsbildung: SPD und CDU bringen sich in Stellung\",Sandra Lumetsberger,574,-0.00124156230595,0.00347947631963,6.93290712661e-05,-0.000297851191135,0.000633466464933,0.00040976415039,-0.00114113790914,0.0013101042714,0.000159210569109,0.00103969930205,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\r\n",
      "299836255,5628571307329728803,299844825,News,\"Regierungsbildung: SPD und CDU bringen sich in Stellung\",Sandra Lumetsberger,574,-0.00235241977498,0.000553445366677,-0.00111171917524,0.000805657822639,-0.00179874512833,-0.0035854417365,0.000421037373599,-0.00274048768915,0.00189092266373,0.00040734387585,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\r\n",
      "\r\n",
      "==> features/train.csv-00003-of-00004 <==\r\n",
      "299950903,1321510689127466525,299816215,News,\"Fahnenskandal von Mailand: Die Austria zeigt Flagge\",Alexander Strecha,574,6.26751425443e-05,-0.000110057328129,-0.000123114936287,-7.34870773158e-05,-0.000107832602225,1.64706580108e-05,-5.72218195884e-05,-7.7386124758e-05,5.52069923287e-06,2.5330014978e-05,1.91183576102e-24,-2.4342056474e-24,-3.10921873842e-24,-7.96838497783e-24,-1.7694536646e-24,-1.47818373585e-24,-1.33189549604e-24,4.5890606599e-24,-2.27099722864e-24,3.56772599578e-24\r\n",
      "299410466,1799101131098248658,299816215,News,\"Fahnenskandal von Mailand: Die Austria zeigt Flagge\",Alexander Strecha,574,0.00012431073992,0.000451879313914,-0.000392050598748,4.46017111244e-05,-0.000273866957286,0.000173527208972,-0.000117200092063,7.34613277018e-05,-9.43002378335e-05,-3.67321808881e-06,1.91183576102e-24,-2.4342056474e-24,-3.10921873842e-24,-7.96838497783e-24,-1.7694536646e-24,-1.47818373585e-24,-1.33189549604e-24,4.5890606599e-24,-2.27099722864e-24,3.56772599578e-24\r\n",
      "299935287,2011529522023576511,299816215,News,\"Fahnenskandal von Mailand: Die Austria zeigt Flagge\",Alexander Strecha,574,3.69638983102e-05,5.22179398104e-05,-6.11379218753e-05,2.10793095903e-05,-0.00013854415738,5.50913646293e-05,1.11891195047e-05,-7.3554328992e-05,-5.87516888118e-06,0.000143420547829,1.91183576102e-24,-2.4342056474e-24,-3.10921873842e-24,-7.96838497783e-24,-1.7694536646e-24,-1.47818373585e-24,-1.33189549604e-24,4.5890606599e-24,-2.27099722864e-24,3.56772599578e-24\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 features/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create vocabularies using Dataflow </h2>\n",
    "\n",
    "Let's use Cloud Dataflow to read in the BigQuery data, do some preprocessing, and write it out as CSV files.\n",
    "\n",
    "Now we'll create our vocabulary files for our categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vocabularies = \"\"\"\n",
    "SELECT\n",
    "  CAST((SELECT MAX(IF(index = index_value, value, NULL)) FROM UNNEST(hits.customDimensions)) AS STRING) AS grouped_by\n",
    "FROM `cloud-training-demos.GA360_test.ga_sessions_sample`,\n",
    "  UNNEST(hits) AS hits\n",
    "WHERE\n",
    "  # only include hits on pages\n",
    "  hits.type = \"PAGE\"\n",
    "  AND (SELECT MAX(IF(index = index_value, value, NULL)) FROM UNNEST(hits.customDimensions)) IS NOT NULL\n",
    "GROUP BY\n",
    "  grouped_by\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job preprocess-hybrid-recommendation-vocab-lists-190321-092057 ... hang on\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import datetime, os\n",
    "\n",
    "def to_txt(rowdict):\n",
    "  # Pull columns from BQ and create a line\n",
    "\n",
    "  # Write out rows for each input row for grouped by column in rowdict\n",
    "  return '{}'.format(rowdict['grouped_by'].encode('utf-8'))\n",
    "  \n",
    "def preprocess(in_test_mode):\n",
    "  import shutil, os, subprocess\n",
    "  job_name = 'preprocess-hybrid-recommendation-vocab-lists' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "\n",
    "  if in_test_mode:\n",
    "      print('Launching local job ... hang on')\n",
    "      OUTPUT_DIR = './preproc/vocabs'\n",
    "      shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "      os.makedirs(OUTPUT_DIR)\n",
    "  else:\n",
    "      print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "      OUTPUT_DIR = 'gs://{0}/hybrid_recommendation/preproc/vocabs/'.format(BUCKET)\n",
    "      try:\n",
    "        subprocess.check_call('gsutil -m rm -r {}'.format(OUTPUT_DIR).split())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  options = {\n",
    "      'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "      'job_name': job_name,\n",
    "      'project': PROJECT,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'no_save_main_session': True\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags = [], **options)\n",
    "  if in_test_mode:\n",
    "      RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "      RUNNER = 'DataflowRunner'\n",
    "      \n",
    "  p = beam.Pipeline(RUNNER, options = opts)\n",
    "  \n",
    "  def vocab_list(index, name):\n",
    "    query = query_vocabularies.replace(\"index_value\", \"{}\".format(index))\n",
    "\n",
    "    (p \n",
    "     | '{}_read'.format(name) >> beam.io.Read(beam.io.BigQuerySource(query = query, use_standard_sql = True))\n",
    "     | '{}_txt'.format(name) >> beam.Map(to_txt)\n",
    "     | '{}_out'.format(name) >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '{0}_vocab.txt'.format(name))))\n",
    "    )\n",
    "\n",
    "  # Call vocab_list function for each\n",
    "  vocab_list(10, 'content_id') # content_id\n",
    "  vocab_list(7, 'category') # category\n",
    "  vocab_list(2, 'author') # author\n",
    "  \n",
    "  job = p.run()\n",
    "  if in_test_mode:\n",
    "    job.wait_until_finish()\n",
    "    print(\"Done!\")\n",
    "    \n",
    "preprocess(in_test_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also get vocab counts from the length of the vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Dataflow job preprocess-hybrid-recommendation-vocab-counts-190321-093051 ... hang on\n"
     ]
    }
   ],
   "source": [
    "import apache_beam as beam\n",
    "import datetime, os\n",
    "\n",
    "def count_to_txt(rowdict):\n",
    "  # Pull columns from BQ and create a line\n",
    "\n",
    "  # Write out count\n",
    "  return '{}'.format(rowdict['count_number'])\n",
    "  \n",
    "def mean_to_txt(rowdict):\n",
    "  # Pull columns from BQ and create a line\n",
    "\n",
    "  # Write out mean\n",
    "  return '{}'.format(rowdict['mean_value'])\n",
    "  \n",
    "def preprocess(in_test_mode):\n",
    "  import shutil, os, subprocess\n",
    "  job_name = 'preprocess-hybrid-recommendation-vocab-counts' + '-' + datetime.datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "\n",
    "  if in_test_mode:\n",
    "      print('Launching local job ... hang on')\n",
    "      OUTPUT_DIR = './preproc/vocab_counts'\n",
    "      shutil.rmtree(OUTPUT_DIR, ignore_errors=True)\n",
    "      os.makedirs(OUTPUT_DIR)\n",
    "  else:\n",
    "      print('Launching Dataflow job {} ... hang on'.format(job_name))\n",
    "      OUTPUT_DIR = 'gs://{0}/hybrid_recommendation/preproc/vocab_counts/'.format(BUCKET)\n",
    "      try:\n",
    "        subprocess.check_call('gsutil -m rm -r {}'.format(OUTPUT_DIR).split())\n",
    "      except:\n",
    "        pass\n",
    "\n",
    "  options = {\n",
    "      'staging_location': os.path.join(OUTPUT_DIR, 'tmp', 'staging'),\n",
    "      'temp_location': os.path.join(OUTPUT_DIR, 'tmp'),\n",
    "      'job_name': job_name,\n",
    "      'project': PROJECT,\n",
    "      'teardown_policy': 'TEARDOWN_ALWAYS',\n",
    "      'no_save_main_session': True\n",
    "  }\n",
    "  opts = beam.pipeline.PipelineOptions(flags = [], **options)\n",
    "  if in_test_mode:\n",
    "      RUNNER = 'DirectRunner'\n",
    "  else:\n",
    "      RUNNER = 'DataflowRunner'\n",
    "      \n",
    "  p = beam.Pipeline(RUNNER, options = opts)\n",
    "  \n",
    "  def vocab_count(index, column_name):\n",
    "    query = \"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS count_number\n",
    "FROM ({})\n",
    "\"\"\".format(query_vocabularies.replace(\"index_value\", \"{}\".format(index)))\n",
    "\n",
    "    (p \n",
    "     | '{}_read'.format(column_name) >> beam.io.Read(beam.io.BigQuerySource(query = query, use_standard_sql = True))\n",
    "     | '{}_txt'.format(column_name) >> beam.Map(count_to_txt)\n",
    "     | '{}_out'.format(column_name) >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '{0}_vocab_count.txt'.format(column_name))))\n",
    "    )\n",
    "    \n",
    "  def global_column_mean(column_name):\n",
    "    query = \"\"\"\n",
    "SELECT\n",
    "  AVG(CAST({1} AS FLOAT64)) AS mean_value\n",
    "FROM ({0})\n",
    "\"\"\".format(query_hybrid_dataset, column_name)\n",
    "    \n",
    "    (p \n",
    "     | '{}_read'.format(column_name) >> beam.io.Read(beam.io.BigQuerySource(query = query, use_standard_sql = True))\n",
    "     | '{}_txt'.format(column_name) >> beam.Map(mean_to_txt)\n",
    "     | '{}_out'.format(column_name) >> beam.io.Write(beam.io.WriteToText(os.path.join(OUTPUT_DIR, '{0}_mean.txt'.format(column_name))))\n",
    "    )\n",
    "    \n",
    "  # Call vocab_count function for each column we want the vocabulary count for\n",
    "  vocab_count(10, 'content_id') # content_id\n",
    "  vocab_count(7, 'category') # category\n",
    "  vocab_count(2, 'author') # author\n",
    "  \n",
    "  # Call global_column_mean function for each column we want the mean for\n",
    "  global_column_mean('months_since_epoch') # months_since_epoch\n",
    "  \n",
    "  job = p.run()\n",
    "  if in_test_mode:\n",
    "    job.wait_until_finish()\n",
    "    print(\"Done!\")\n",
    "    \n",
    "preprocess(in_test_mode = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our files to make sure everything went as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf vocabs\n",
    "mkdir vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocabs/author_vocab.txt-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt-00000-of-00001...\n",
      "/ [3/3 files][178.5 KiB/178.5 KiB] 100% Done                                    \n",
      "Operation completed over 3 objects/178.5 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://{BUCKET}/hybrid_recommendation/preproc/vocabs/*.txt* vocabs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> vocabs/author_vocab.txt-00000-of-00001 <==\r\n",
      "Moritz Gottsauner-Wolf\r\n",
      "Brigitte Schokarth\r\n",
      "Ursula Horvath\r\n",
      "\r\n",
      "==> vocabs/category_vocab.txt-00000-of-00001 <==\r\n",
      "News\r\n",
      "Stars & Kultur\r\n",
      "Lifestyle\r\n",
      "\r\n",
      "==> vocabs/content_id_vocab.txt-00000-of-00001 <==\r\n",
      "299969709\r\n",
      "299326744\r\n",
      "299496976\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 vocabs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "rm -rf vocab_counts\n",
    "mkdir vocab_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocab_counts/author_vocab_count.txt-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocab_counts/category_vocab_count.txt-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocab_counts/content_id_vocab_count.txt-00000-of-00001...\n",
      "Copying gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocab_counts/months_since_epoch_mean.txt-00000-of-00001...\n",
      "/ [4/4 files][   26.0 B/   26.0 B] 100% Done                                    \n",
      "Operation completed over 4 objects/26.0 B.                                       \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp -r gs://{BUCKET}/hybrid_recommendation/preproc/vocab_counts/*.txt* vocab_counts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> vocab_counts/author_vocab_count.txt-00000-of-00001 <==\r\n",
      "1103\r\n",
      "\r\n",
      "==> vocab_counts/category_vocab_count.txt-00000-of-00001 <==\r\n",
      "3\r\n",
      "\r\n",
      "==> vocab_counts/content_id_vocab_count.txt-00000-of-00001 <==\r\n",
      "15634\r\n",
      "\r\n",
      "==> vocab_counts/months_since_epoch_mean.txt-00000-of-00001 <==\r\n",
      "573.60733908\r\n"
     ]
    }
   ],
   "source": [
    "!head -3 vocab_counts/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
