{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network hybrid recommendation system on Google Analytics data model and training\n",
    "\n",
    "This notebook demonstrates how to implement a hybrid recommendation system using a neural network to combine content-based and collaborative filtering recommendation models using Google Analytics data. We are going to use the learned user embeddings from [wals.ipynb](../wals.ipynb) and combine that with our previous content-based features from [content_based_using_neural_networks.ipynb](../content_based_using_neural_networks.ipynb)\n",
    "\n",
    "Now that we have our data preprocessed from BigQuery and Cloud Dataflow, we can build our neural network hybrid recommendation model to our preprocessed data. Then we can train locally to make sure everything works and then use the power of Google Cloud ML Engine to scale it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use TensorFlow Hub to use trained text embeddings, so let's first pip install that and reset our session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/f0/3a3ced04c8359e562f1b91918d9bde797c8a916fcfeddc8dc5d673d1be20/tensorflow_hub-0.3.0-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 6.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (1.14.0)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (3.6.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/envs/py3env/lib/python3.5/site-packages (from tensorflow_hub) (1.10.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/envs/py3env/lib/python3.5/site-packages (from protobuf>=3.4.0->tensorflow_hub) (40.2.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reset the notebook's session kernel! Since we're no longer using Cloud Dataflow, we'll be using the python3 kernel from here on out so don't forget to change the kernel if it's still python2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0401 13:36:41.444346 140160493156096 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-79ea9b31a1bf3bcb\n",
      "qwiklabs-gcp-79ea9b31a1bf3bcb\n",
      "europe-west1\n"
     ]
    }
   ],
   "source": [
    "# Import helpful libraries and setup our project, bucket, and region\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "output = os.popen(\"gcloud config get-value project\").readlines()\n",
    "project_name = output[0][:-1]\n",
    "\n",
    "# change these to try this notebook out\n",
    "PROJECT = project_name\n",
    "BUCKET = project_name\n",
    "#BUCKET = BUCKET.replace(\"qwiklabs-gcp-\", \"inna-bckt-\")\n",
    "REGION = 'europe-west1'  ## note: Cloud ML Engine not availabe in europe-west3!\n",
    "\n",
    "print(PROJECT)\n",
    "print(BUCKET)\n",
    "print(REGION)\n",
    "\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = '1.8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating gs://qwiklabs-gcp-79ea9b31a1bf3bcb/...\n",
      "ServiceException: 409 Bucket qwiklabs-gcp-79ea9b31a1bf3bcb already exists.\n",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/eval.csv-00000-of-00001 [Content-Type=text/plain]...\n",
      "/ [0 files][    0.0 B/ 11.4 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 13.6 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 16.0 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/tmp/staging/preprocess-hybrid-recommendation-features-181217-164834.1545065316.946936/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "/ [0 files][    0.0 B/ 16.1 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00000-of-00004 [Content-Type=text/plain]...\n",
      "/ [0 files][    0.0 B/ 18.0 MiB]                                                \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00001-of-00004 [Content-Type=text/plain]...\n",
      "-\r",
      "- [1/21 files][  2.3 MiB/128.8 MiB]   1% Done                                   \r",
      "- [1/21 files][  2.3 MiB/128.8 MiB]   1% Done                                   \r",
      "- [2/21 files][  4.6 MiB/128.8 MiB]   3% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00002-of-00004 [Content-Type=text/plain]...\n",
      "- [2/21 files][  4.6 MiB/128.8 MiB]   3% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00003-of-00004 [Content-Type=text/plain]...\n",
      "- [3/21 files][  4.7 MiB/128.8 MiB]   3% Done                                   \r",
      "- [3/21 files][  4.7 MiB/128.8 MiB]   3% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/author_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "- [4/21 files][  6.7 MiB/128.8 MiB]   5% Done                                   \r",
      "- [4/21 files][  6.7 MiB/128.8 MiB]   5% Done                                   \r",
      "- [5/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/category_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "- [5/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/content_id_vocab_count.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "\\\r",
      "\\ [6/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "\\ [6/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/months_since_epoch_mean.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "\\ [7/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "\\ [7/21 files][ 18.0 MiB/128.8 MiB]  14% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "\\ [8/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "\\ [8/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocab_counts/tmp/staging/preprocess-hybrid-recommendation-vocab-counts-181217-170736.1545066458.457255/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "|\r",
      "| [9/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "| [9/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                   \r",
      "| [10/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                  \r",
      "| [10/21 files][ 39.3 MiB/128.8 MiB]  30% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/author_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "| [11/21 files][ 41.5 MiB/128.8 MiB]  32% Done                                  \r",
      "| [11/21 files][ 41.5 MiB/128.8 MiB]  32% Done                                  \r",
      "| [12/21 files][ 70.9 MiB/128.8 MiB]  55% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "| [12/21 files][ 70.9 MiB/128.8 MiB]  55% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt-00000-of-00001 [Content-Type=text/plain]...\n",
      "/\r",
      "/ [13/21 files][ 71.0 MiB/128.8 MiB]  55% Done                                  \r",
      "/ [13/21 files][ 71.0 MiB/128.8 MiB]  55% Done                                  \r",
      "/ [14/21 files][ 73.3 MiB/128.8 MiB]  56% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/apache_beam-2.9.0-cp27-cp27mu-manylinux1_x86_64.whl [Content-Type=application/octet-stream]...\n",
      "/ [14/21 files][ 73.3 MiB/128.8 MiB]  56% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/dataflow_python_sdk.tar [Content-Type=application/octet-stream]...\n",
      "/ [15/21 files][ 73.3 MiB/128.8 MiB]  56% Done                                  \r",
      "/ [15/21 files][ 73.3 MiB/128.8 MiB]  56% Done                                  \r",
      "Copying gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/vocabs/tmp/staging/preprocess-hybrid-recommendation-vocab-lists-181217-170024.1545066026.063994/pipeline.pb [Content-Type=application/octet-stream]...\n",
      "/ [16/21 files][ 73.4 MiB/128.8 MiB]  56% Done                                  \r",
      "/ [16/21 files][ 73.4 MiB/128.8 MiB]  56% Done                                  \r",
      "-\r",
      "- [17/21 files][124.0 MiB/128.8 MiB]  96% Done                                  \r",
      "- [18/21 files][126.2 MiB/128.8 MiB]  97% Done                                  \r",
      "- [19/21 files][126.4 MiB/128.8 MiB]  98% Done                                  \r",
      "- [20/21 files][128.8 MiB/128.8 MiB]  99% Done                                  \r",
      "- [21/21 files][128.8 MiB/128.8 MiB] 100% Done                                  \r\n",
      "Operation completed over 21 objects/128.8 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/hybrid_recommendation/preproc; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "  # copy canonical set of preprocessed files if you didn't do preprocessing notebook\n",
    "  gsutil -m cp -R gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299930679,4124276913381016353,299853016,News,\"Schröcksnadel gegen Werdenigg: Keine Aussprache\",None,574,-0.000132977511385,0.00228702323511,-0.00420491816476,-0.0018632216379,-0.000125233927974,-0.00052978831809,0.00199878611602,-0.00292786653154,-9.54846836976e-05,-0.00292471889406,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "299814194,4227276538424609069,299853016,News,\"Schröcksnadel gegen Werdenigg: Keine Aussprache\",None,574,0.000635798787698,0.000632956798654,-0.000753425003495,-0.00143439311069,0.00159654486924,0.00240364903584,0.000762865995057,-0.000780026195571,0.000952163827606,-0.000651185924653,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "299817990,4330031728344002782,299853016,News,\"Schröcksnadel gegen Werdenigg: Keine Aussprache\",None,574,-0.00180920027196,0.00217268057168,-0.00317482789978,-0.00126856216229,-0.00208666571416,-0.00498688407242,0.00355341145769,0.00158221635502,0.00331125501543,0.00494551565498,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0\n",
      "299824032,1838603332593886980,299853016,News,\"Schröck"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gsutil cat -r 0-1024 gs://cloud-training-demos/courses/machine_learning/deepdive/10_recommendation/hybrid_recommendation/preproc/features/train.csv-00000-of-00004\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first get some of our aggregate information that we will use in the model from some of our preprocessed files we saved in Google Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_content_ids = 15634\n"
     ]
    }
   ],
   "source": [
    "# Get number of content ids from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/content_id_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_content_ids = int([x for x in ifp][0])\n",
    "print(\"number_of_content_ids = {}\".format(number_of_content_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_categories = 3\n"
     ]
    }
   ],
   "source": [
    "# Get number of categories from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/category_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_categories = int([x for x in ifp][0])\n",
    "print(\"number_of_categories = {}\".format(number_of_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_authors = 1103\n"
     ]
    }
   ],
   "source": [
    "# Get number of authors from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/author_vocab_count.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  number_of_authors = int([x for x in ifp][0])\n",
    "print(\"number_of_authors = {}\".format(number_of_authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_months_since_epoch = 573.60733908\n"
     ]
    }
   ],
   "source": [
    "# Get mean months since epoch from text file in Google Cloud Storage\n",
    "with file_io.FileIO(tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocab_counts/months_since_epoch_mean.txt*\".format(BUCKET))[0], mode = 'r') as ifp:\n",
    "  mean_months_since_epoch = float([x for x in ifp][0])\n",
    "print(\"mean_months_since_epoch = {}\".format(mean_months_since_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV and label columns\n",
    "NON_FACTOR_COLUMNS = 'next_content_id,visitor_id,content_id,category,title,author,months_since_epoch'.split(',')\n",
    "FACTOR_COLUMNS = [\"user_factor_{}\".format(i) for i in range(10)] + [\"item_factor_{}\".format(i) for i in range(10)]\n",
    "CSV_COLUMNS = NON_FACTOR_COLUMNS + FACTOR_COLUMNS\n",
    "LABEL_COLUMN = 'next_content_id'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "NON_FACTOR_DEFAULTS = [[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[\"Unknown\"],[mean_months_since_epoch]]\n",
    "FACTOR_DEFAULTS = [[0.0] for i in range(10)] + [[0.0] for i in range(10)] # user and item\n",
    "DEFAULTS = NON_FACTOR_DEFAULTS + FACTOR_DEFAULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create input function for training and evaluation to read from our preprocessed CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input function for train and eval\n",
    "def read_dataset(filename, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    def decode_csv(value_column):\n",
    "      columns = tf.decode_csv(records = value_column, record_defaults = DEFAULTS)\n",
    "      features = dict(zip(CSV_COLUMNS, columns))          \n",
    "      label = features.pop(LABEL_COLUMN)         \n",
    "      return features, label\n",
    "\n",
    "    # Create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename = filename)\n",
    "\n",
    "    # Create dataset from file list\n",
    "    dataset = tf.data.TextLineDataset(filenames = file_list).map(map_func = decode_csv)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "      num_epochs = None # indefinitely\n",
    "      dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "      num_epochs = 1 # end-of-input after this\n",
    "\n",
    "    dataset = dataset.repeat(count = num_epochs).batch(batch_size = batch_size)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create our feature columns using our read in features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature columns to be used in model\n",
    "def create_feature_columns(args):\n",
    "  # Create content_id feature column\n",
    "  content_id_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"content_id\",\n",
    "    hash_bucket_size = number_of_content_ids)\n",
    "\n",
    "  # Embed content id into a lower dimensional representation\n",
    "  embedded_content_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = content_id_column,\n",
    "    dimension = args['content_id_embedding_dimensions'])\n",
    "\n",
    "  # Create category feature column\n",
    "  categorical_category_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "    key = \"category\",\n",
    "    vocabulary_file = tf.gfile.Glob(\n",
    "      filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/category_vocab.txt*\".format(args['bucket']))[0],\n",
    "    num_oov_buckets = 1)\n",
    "\n",
    "  # Convert categorical category column into indicator column so that it can be used in a DNN\n",
    "  indicator_category_column = tf.feature_column.indicator_column(categorical_column = categorical_category_column)\n",
    "\n",
    "  # Create title feature column using TF Hub\n",
    "  embedded_title_column = hub.text_embedding_column(\n",
    "    key = \"title\", \n",
    "    module_spec = \"https://tfhub.dev/google/nnlm-de-dim50-with-normalization/1\",\n",
    "    trainable = False)\n",
    "\n",
    "  # Create author feature column\n",
    "  author_column = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    key = \"author\",\n",
    "    hash_bucket_size = number_of_authors + 1)\n",
    "\n",
    "  # Embed author into a lower dimensional representation\n",
    "  embedded_author_column = tf.feature_column.embedding_column(\n",
    "    categorical_column = author_column,\n",
    "    dimension = args['author_embedding_dimensions'])\n",
    "\n",
    "  # Create months since epoch boundaries list for our binning\n",
    "  months_since_epoch_boundaries = list(range(400, 700, 20))\n",
    "\n",
    "  # Create months_since_epoch feature column using raw data\n",
    "  months_since_epoch_column = tf.feature_column.numeric_column(\n",
    "    key = \"months_since_epoch\")\n",
    "\n",
    "  # Create bucketized months_since_epoch feature column using our boundaries\n",
    "  months_since_epoch_bucketized = tf.feature_column.bucketized_column(\n",
    "    source_column = months_since_epoch_column,\n",
    "    boundaries = months_since_epoch_boundaries)\n",
    "\n",
    "  # Cross our categorical category column and bucketized months since epoch column\n",
    "  crossed_months_since_category_column = tf.feature_column.crossed_column(\n",
    "    keys = [categorical_category_column, months_since_epoch_bucketized],\n",
    "    hash_bucket_size = len(months_since_epoch_boundaries) * (number_of_categories + 1))\n",
    "\n",
    "  # Convert crossed categorical category and bucketized months since epoch column into indicator column so that it can be used in a DNN\n",
    "  indicator_crossed_months_since_category_column = tf.feature_column.indicator_column(\n",
    "    categorical_column = crossed_months_since_category_column\n",
    "  )\n",
    "\n",
    "  # Create user and item factor feature columns from our trained WALS model\n",
    "  user_factors = [tf.feature_column.numeric_column(key = \"user_factor_\" + str(i)) for i in range(10)]\n",
    "  item_factors =  [tf.feature_column.numeric_column(key = \"item_factor_\" + str(i)) for i in range(10)]\n",
    "\n",
    "  # Create list of feature columns\n",
    "  feature_columns = [embedded_content_column,\n",
    "                     embedded_author_column,\n",
    "                     indicator_category_column,\n",
    "                     embedded_title_column,\n",
    "                     indicator_crossed_months_since_category_column] + user_factors + item_factors\n",
    "\n",
    "  return feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom model function for our custom estimator\n",
    "def model_fn(features, labels, mode, params):\n",
    "  # TODO: Create neural network input layer using our feature columns defined above\n",
    "  net = tf.feature_column.input_layer(\n",
    "    features = features,\n",
    "    feature_columns = params['feature_columns']\n",
    "  )\n",
    "\n",
    "  # TODO: Create hidden layers by looping through hidden unit list\n",
    "  for units in params['hidden_units']:\n",
    "    net = tf.layers.dense(\n",
    "      inputs = net,\n",
    "      units = units,\n",
    "      activation = tf.nn.relu\n",
    "    )\n",
    "\n",
    "  # TODO: Compute logits (1 per class) using the output of our last hidden layer\n",
    "  logits = tf.layers.dense(\n",
    "    inputs = net,\n",
    "    units = params['n_classes'],\n",
    "    activation = None\n",
    "  )\n",
    "\n",
    "  # TODO: Find the predicted class indices based on the highest logit (which will result in the highest probability)\n",
    "  predicted_classes = tf.argmax(input = logits, axis = 1) \n",
    "\n",
    "  # Read in the content id vocabulary so we can tie the predicted class indices to their respective content ids\n",
    "  with file_io.FileIO(\n",
    "    tf.gfile.Glob(filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt*\".format(BUCKET))[0], mode = 'r'\n",
    "  ) as ifp:\n",
    "    content_id_names = tf.constant(value = [x.rstrip() for x in ifp])\n",
    "\n",
    "  # Gather predicted class names based predicted class indices\n",
    "  predicted_class_names = tf.gather(params = content_id_names, indices = predicted_classes)\n",
    "\n",
    "  # If the mode is prediction\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Create predictions dict\n",
    "    predictions_dict = {\n",
    "        'class_ids': tf.expand_dims(input = predicted_classes, axis = -1),\n",
    "        'class_names' : tf.expand_dims(input = predicted_class_names, axis = -1),\n",
    "        'probabilities': tf.nn.softmax(logits = logits),\n",
    "        'logits': logits\n",
    "    }\n",
    "\n",
    "    # Create export outputs\n",
    "    export_outputs = {\n",
    "      \"predict_export_outputs\": tf.estimator.export.PredictOutput(outputs = predictions_dict)\n",
    "    }\n",
    "\n",
    "    return tf.estimator.EstimatorSpec( # return early since we're done with what we need for prediction mode\n",
    "      mode = mode,\n",
    "      predictions = predictions_dict,\n",
    "      loss = None,\n",
    "      train_op = None,\n",
    "      eval_metric_ops = None,\n",
    "      export_outputs = export_outputs)\n",
    "\n",
    "  # Continue on with training and evaluation modes\n",
    "\n",
    "  # Create lookup table using our content id vocabulary\n",
    "  table = tf.contrib.lookup.index_table_from_file(\n",
    "    vocabulary_file = tf.gfile.Glob(\n",
    "      filename = \"gs://{}/hybrid_recommendation/preproc/vocabs/content_id_vocab.txt*\".format(BUCKET)\n",
    "    )[0]\n",
    "  )\n",
    "\n",
    "  # Look up labels from vocabulary table\n",
    "  labels = table.lookup(keys = labels)\n",
    "\n",
    "  # TODO: Compute loss using the correct type of softmax cross entropy since this is classification and \n",
    "  # our labels (content id indices) and probabilities are mutually exclusive\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(\n",
    "    labels = labels,\n",
    "    logits = logits\n",
    "  )\n",
    "\n",
    "  # Compute evaluation metrics of total accuracy and the accuracy of the top k classes\n",
    "  accuracy = tf.metrics.accuracy(labels = labels, predictions = predicted_classes, name = 'acc_op')\n",
    "  top_k_accuracy = tf.metrics.mean(values = tf.nn.in_top_k(predictions = logits, targets = labels, k = params['top_k']))\n",
    "  map_at_k = tf.metrics.average_precision_at_k(labels = labels, predictions = predicted_classes, k = params['top_k'])\n",
    "\n",
    "  # Put eval metrics into a dictionary\n",
    "  eval_metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'top_k_accuracy': top_k_accuracy,\n",
    "    'map_at_k': map_at_k}\n",
    "\n",
    "  # Create scalar summaries to see in TensorBoard\n",
    "  tf.summary.scalar(name = 'accuracy', tensor = accuracy[1])\n",
    "  tf.summary.scalar(name = 'top_k_accuracy', tensor = top_k_accuracy[1])\n",
    "  tf.summary.scalar(name = 'map_at_k', tensor = map_at_k[1])\n",
    "\n",
    "  # Create scalar summaries to see in TensorBoard\n",
    "  #tf.summary.scalar(name = 'accuracy', tensor = accuracy[1])\n",
    "  #tf.summary.scalar(name = 'top_k_accuracy', tensor = top_k_accuracy[1])\n",
    "\n",
    "  # If the mode is evaluation\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    return tf.estimator.EstimatorSpec( # return early since we're done with what we need for evaluation mode\n",
    "        mode = mode,\n",
    "        predictions = None,\n",
    "        loss = loss,\n",
    "        train_op = None,\n",
    "        eval_metric_ops = eval_metrics,\n",
    "        export_outputs = None)\n",
    "\n",
    "  # Continue on with training mode\n",
    "\n",
    "  # If the mode is training\n",
    "  assert mode == tf.estimator.ModeKeys.TRAIN\n",
    "\n",
    "  # Create a custom optimizer\n",
    "  optimizer = tf.train.AdagradOptimizer(learning_rate = params['learning_rate'])\n",
    "\n",
    "  # Create train op\n",
    "  train_op = optimizer.minimize(loss = loss, global_step = tf.train.get_global_step())\n",
    "\n",
    "  return tf.estimator.EstimatorSpec( # final return since we're done with what we need for training mode\n",
    "    mode = mode,\n",
    "    predictions = None,\n",
    "    loss = loss,\n",
    "    train_op = train_op,\n",
    "    eval_metric_ops = None,\n",
    "    export_outputs = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a serving input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function\n",
    "def serving_input_fn():  \n",
    "  feature_placeholders = {\n",
    "    colname : tf.placeholder(dtype = tf.string, shape = [None]) \\\n",
    "    for colname in NON_FACTOR_COLUMNS[1:-1]\n",
    "  }\n",
    "  feature_placeholders['months_since_epoch'] = tf.placeholder(dtype = tf.float32, shape = [None])\n",
    "  \n",
    "  for colname in FACTOR_COLUMNS:\n",
    "    feature_placeholders[colname] = tf.placeholder(dtype = tf.float32, shape = [None])\n",
    "\n",
    "  features = {\n",
    "    key: tf.expand_dims(tensor, -1) \\\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "    \n",
    "  return tf.estimator.export.ServingInputReceiver(features, feature_placeholders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of the pieces are assembled let's create and run our train and evaluate loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and evaluate loop to combine all of the pieces together.\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "def train_and_evaluate(args):\n",
    "  estimator = tf.estimator.Estimator(\n",
    "    model_fn = model_fn,\n",
    "    model_dir = args['output_dir'],\n",
    "    params={\n",
    "      'feature_columns': create_feature_columns(args),\n",
    "      'hidden_units': args['hidden_units'],\n",
    "      'n_classes': number_of_content_ids,\n",
    "      'learning_rate': args['learning_rate'],\n",
    "      'top_k': args['top_k'],\n",
    "      'bucket': args['bucket']\n",
    "    })\n",
    "\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn = read_dataset(filename = args['train_data_paths'], mode = tf.estimator.ModeKeys.TRAIN, batch_size = args['batch_size']),\n",
    "    max_steps = args['train_steps'])\n",
    "\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "    input_fn = read_dataset(filename = args['eval_data_paths'], mode = tf.estimator.ModeKeys.EVAL, batch_size = args['batch_size']),\n",
    "    steps = None,\n",
    "    start_delay_secs = args['start_delay_secs'],\n",
    "    throttle_secs = args['throttle_secs'],\n",
    "    exporters = exporter)\n",
    "\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train_and_evaluate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-79ea9b31a1bf3bcb/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:44:48.541695 140160493156096 tf_logging.py:116] vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-79ea9b31a1bf3bcb/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:00.806884 140160493156096 tf_logging.py:116] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_service': None, '_evaluation_master': '', '_task_type': 'worker', '_session_config': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_model_dir': 'hybrid_recommendation_trained', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7967f517f0>, '_train_distribute': None, '_global_id_in_cluster': 0, '_is_chief': True, '_num_ps_replicas': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:00.819571 140160493156096 tf_logging.py:116] Using config: {'_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_save_summary_steps': 100, '_keep_checkpoint_max': 5, '_service': None, '_evaluation_master': '', '_task_type': 'worker', '_session_config': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_tf_random_seed': None, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_model_dir': 'hybrid_recommendation_trained', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7967f517f0>, '_train_distribute': None, '_global_id_in_cluster': 0, '_is_chief': True, '_num_ps_replicas': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:00.868501 140160493156096 tf_logging.py:116] Running training and evaluation locally (non-distributed).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:00.878852 140160493156096 tf_logging.py:116] Start train and evaluate loop. The evaluate will happen after 30 secs (eval_spec.throttle_secs) or training is finished.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:01.833020 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:04.616848 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:30.167813 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:30.182790 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:30.770390 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:31.808458 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:33.168314 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:35.858243 140160493156096 tf_logging.py:116] Saving checkpoints for 1 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 9.656906, step = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:36.360257 140160493156096 tf_logging.py:116] loss = 9.656906, step = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:52.034376 140160493156096 tf_logging.py:116] global_step/sec: 6.3798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.090904, step = 101 (15.685 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:46:52.045344 140160493156096 tf_logging.py:116] loss = 5.090904, step = 101 (15.685 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 158 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:00.544965 140160493156096 tf_logging.py:116] Saving checkpoints for 158 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 5.3378143.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:01.776310 140160493156096 tf_logging.py:116] Loss for final step: 5.3378143.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:01.935822 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:02.547288 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:03.247547 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:47:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:03.285043 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:47:03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:03.418675 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:03.427190 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:03.932085 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:05.420880 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:47:24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:24.275810 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:47:24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 158: accuracy = 0.02785265, global_step = 158, loss = 5.9954944, map_at_k = 0.06880972222222231, top_k_accuracy = 0.17477246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:24.282291 140160493156096 tf_logging.py:116] Saving dict for global step 158: accuracy = 0.02785265, global_step = 158, loss = 5.9954944, map_at_k = 0.06880972222222231, top_k_accuracy = 0.17477246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:25.317116 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:25.932144 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.420837 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.447016 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.454866 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.456843 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.503803 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.944339 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126446'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:26.966257 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126446'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126446'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:27.710416 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126446'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:27.922550 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:28.296831 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:29.493770 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:29.507726 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:29.669564 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:29.678856 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:30.244577 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:31.443989 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 159 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:36.255877 140160493156096 tf_logging.py:116] Saving checkpoints for 159 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.987445, step = 159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:36.742478 140160493156096 tf_logging.py:116] loss = 5.987445, step = 159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.74145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:51.575812 140160493156096 tf_logging.py:116] global_step/sec: 6.74145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.929761, step = 259 (14.844 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:51.586471 140160493156096 tf_logging.py:116] loss = 4.929761, step = 259 (14.844 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 315 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:47:59.620949 140160493156096 tf_logging.py:116] Saving checkpoints for 315 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.9357452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:01.320053 140160493156096 tf_logging.py:116] Loss for final step: 4.9357452.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:01.473930 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:01.856255 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:02.841750 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:48:02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:02.885373 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:48:02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:03.022520 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:03.030300 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:03.570918 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:04.791841 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:48:23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:23.366492 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:48:23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 315: accuracy = 0.02203211, global_step = 315, loss = 5.8925896, map_at_k = 0.06901805555555562, top_k_accuracy = 0.16867846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:23.375217 140160493156096 tf_logging.py:116] Saving dict for global step 315: accuracy = 0.02203211, global_step = 315, loss = 5.8925896, map_at_k = 0.06901805555555562, top_k_accuracy = 0.16867846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.121054 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.462843 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.925051 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.947414 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.954989 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:24.957488 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:25.006746 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:25.452927 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126504'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:25.474402 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126504'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126504'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:26.032068 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126504'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:26.202819 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:26.859469 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:27.804701 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:27.816923 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:27.982285 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:27.993520 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:28.582174 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:29.815055 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 316 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:31.717188 140160493156096 tf_logging.py:116] Saving checkpoints for 316 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.627655, step = 316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:34.739520 140160493156096 tf_logging.py:116] loss = 5.627655, step = 316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.60697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:49.874744 140160493156096 tf_logging.py:116] global_step/sec: 6.60697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.997776, step = 416 (15.146 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:49.885291 140160493156096 tf_logging.py:116] loss = 4.997776, step = 416 (15.146 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 470 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:57.830509 140160493156096 tf_logging.py:116] Saving checkpoints for 470 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.7786922.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:59.083303 140160493156096 tf_logging.py:116] Loss for final step: 4.7786922.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:59.242587 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:48:59.586743 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:00.264172 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:49:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:00.303431 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:49:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:00.428946 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:00.438444 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:00.962503 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:02.208206 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:49:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:20.392466 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:49:20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 470: accuracy = 0.02531349, global_step = 470, loss = 5.774227, map_at_k = 0.05557837301587304, top_k_accuracy = 0.20215634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:20.401165 140160493156096 tf_logging.py:116] Saving dict for global step 470: accuracy = 0.02531349, global_step = 470, loss = 5.774227, map_at_k = 0.05557837301587304, top_k_accuracy = 0.20215634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:21.057871 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:21.703269 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.180099 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.203200 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.211020 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.213327 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.259221 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.677777 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126562'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:22.697962 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126562'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126562'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:23.264117 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126562'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:23.449556 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:23.821359 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:25.034959 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:25.047126 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:25.204766 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:25.213928 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:25.750580 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:26.918590 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 471 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:30.218010 140160493156096 tf_logging.py:116] Saving checkpoints for 471 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.4925556, step = 471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:31.018266 140160493156096 tf_logging.py:116] loss = 5.4925556, step = 471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.57716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:46.222152 140160493156096 tf_logging.py:116] global_step/sec: 6.57716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.001187, step = 571 (15.214 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:46.232299 140160493156096 tf_logging.py:116] loss = 5.001187, step = 571 (15.214 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 630 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:55.133555 140160493156096 tf_logging.py:116] Saving checkpoints for 630 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.957397.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:57.344999 140160493156096 tf_logging.py:116] Loss for final step: 4.957397.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:57.489992 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:57.829351 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:58.851526 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:49:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:58.889667 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:49:58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:59.029673 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:59.042606 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:49:59.562184 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:00.782929 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:50:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:19.432966 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:50:19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 630: accuracy = 0.029571468, global_step = 630, loss = 5.730803, map_at_k = 0.04693174603174601, top_k_accuracy = 0.20211726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:19.441949 140160493156096 tf_logging.py:116] Saving dict for global step 630: accuracy = 0.029571468, global_step = 630, loss = 5.730803, map_at_k = 0.04693174603174601, top_k_accuracy = 0.20211726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.142089 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.480283 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.946568 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.971339 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.981061 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:20.983364 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:21.038437 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:21.487868 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126620'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:21.516081 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126620'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126620'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:22.095565 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126620'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:22.305112 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:22.982274 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:23.959670 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:23.972818 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:24.128687 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:24.138107 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:24.686486 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:25.893993 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 631 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:27.803076 140160493156096 tf_logging.py:116] Saving checkpoints for 631 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.5712824, step = 631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:30.324655 140160493156096 tf_logging.py:116] loss = 5.5712824, step = 631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.72124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:45.202511 140160493156096 tf_logging.py:116] global_step/sec: 6.72124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.1654577, step = 731 (14.889 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:45.214101 140160493156096 tf_logging.py:116] loss = 5.1654577, step = 731 (14.889 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 791 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:54.001698 140160493156096 tf_logging.py:116] Saving checkpoints for 791 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.9495897.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:55.337421 140160493156096 tf_logging.py:116] Loss for final step: 4.9495897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:55.486154 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:55.842984 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:56.550752 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:50:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:56.585475 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:50:56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:56.727451 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:56.736338 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:57.221827 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:50:58.456456 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:51:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:17.058527 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:51:17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 791: accuracy = 0.028477674, global_step = 791, loss = 5.6665382, map_at_k = 0.05026904761904761, top_k_accuracy = 0.22036017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:17.066905 140160493156096 tf_logging.py:116] Saving dict for global step 791: accuracy = 0.028477674, global_step = 791, loss = 5.6665382, map_at_k = 0.05026904761904761, top_k_accuracy = 0.22036017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:17.756625 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.394631 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.876773 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.899193 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.907004 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.909427 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:18.968044 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:19.374520 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126678'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:19.396270 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126678'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126678'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:19.987324 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126678'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:20.169672 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:20.532700 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:21.795702 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:21.811910 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:21.975316 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:21.985954 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:22.599575 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:23.865695 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 792 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:25.556784 140160493156096 tf_logging.py:116] Saving checkpoints for 792 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.3019056, step = 792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:26.548799 140160493156096 tf_logging.py:116] loss = 5.3019056, step = 792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 6.41485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:42.137277 140160493156096 tf_logging.py:116] global_step/sec: 6.41485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 4.700662, step = 892 (15.601 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:42.149377 140160493156096 tf_logging.py:116] loss = 4.700662, step = 892 (15.601 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 957 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:51.915363 140160493156096 tf_logging.py:116] Saving checkpoints for 957 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.8353243.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:53.099140 140160493156096 tf_logging.py:116] Loss for final step: 4.8353243.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:53.238686 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:53.585117 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:54.597166 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:51:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:54.636400 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:51:54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:54.775247 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:54.783290 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:55.247276 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:51:56.457099 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:52:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:15.198861 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:52:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 957: accuracy = 0.020000782, global_step = 957, loss = 5.671833, map_at_k = 0.050831944444444443, top_k_accuracy = 0.2076253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:15.208378 140160493156096 tf_logging.py:116] Saving dict for global step 957: accuracy = 0.020000782, global_step = 957, loss = 5.671833, map_at_k = 0.050831944444444443, top_k_accuracy = 0.2076253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:15.907637 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.252850 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.728923 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.751387 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.759009 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.761461 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:16.811928 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:17.213161 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126736'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:17.233545 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126736'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126736'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:17.798979 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126736'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:18.019726 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:18.679896 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:19.696104 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:19.711117 140160493156096 tf_logging.py:116] Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:19.870604 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:19.879732 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:20.421312 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:21.647674 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 958 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:23.527203 140160493156096 tf_logging.py:116] Saving checkpoints for 958 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 5.2628946, step = 958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:24.604949 140160493156096 tf_logging.py:116] loss = 5.2628946, step = 958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 1000 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:31.279750 140160493156096 tf_logging.py:116] Saving checkpoints for 1000 into hybrid_recommendation_trained/model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 4.7653136.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:33.624796 140160493156096 tf_logging.py:116] Loss for final step: 4.7653136.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:33.773897 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:34.179795 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:34.905661 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2019-04-01-13:52:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:34.947190 140160493156096 tf_logging.py:116] Starting evaluation at 2019-04-01-13:52:34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:35.103183 140160493156096 tf_logging.py:116] Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:35.111336 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:35.610015 140160493156096 tf_logging.py:116] Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:36.979136 140160493156096 tf_logging.py:116] Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2019-04-01-13:52:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:55.305978 140160493156096 tf_logging.py:116] Finished evaluation at 2019-04-01-13:52:55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.029805852, global_step = 1000, loss = 5.681636, map_at_k = 0.05303690476190476, top_k_accuracy = 0.1995781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:55.314557 140160493156096 tf_logging.py:116] Saving dict for global step 1000: accuracy = 0.029805852, global_step = 1000, loss = 5.681636, map_at_k = 0.05303690476190476, top_k_accuracy = 0.1995781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:56.048921 140160493156096 tf_logging.py:116] Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:56.681764 140160493156096 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.158027 140160493156096 tf_logging.py:116] Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.190009 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.198053 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.200084 140160493156096 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.247030 140160493156096 tf_logging.py:116] Restoring parameters from hybrid_recommendation_trained/model.ckpt-1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.646656 140160493156096 tf_logging.py:116] Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126777'/assets\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:57.668166 140160493156096 tf_logging.py:116] Assets written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126777'/assets\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126777'/saved_model.pb\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0401 13:52:58.427087 140160493156096 tf_logging.py:116] SavedModel written to: b\"hybrid_recommendation_trained/export/exporter/temp-b'1554126777'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "# Call train and evaluate loop\n",
    "import shutil\n",
    "\n",
    "outdir = 'hybrid_recommendation_trained'\n",
    "shutil.rmtree(outdir, ignore_errors = True) # start fresh each time\n",
    "\n",
    "arguments = {\n",
    "  'bucket': BUCKET,\n",
    "  'train_data_paths': \"gs://{}/hybrid_recommendation/preproc/features/train.csv*\".format(BUCKET),\n",
    "  'eval_data_paths': \"gs://{}/hybrid_recommendation/preproc/features/eval.csv*\".format(BUCKET),\n",
    "  'output_dir': outdir,\n",
    "  'batch_size': 128,\n",
    "  'learning_rate': 0.1,\n",
    "  'hidden_units': [256, 128, 64],\n",
    "  'content_id_embedding_dimensions': 10,\n",
    "  'author_embedding_dimensions': 10,\n",
    "  'top_k': 10,\n",
    "  'train_steps': 1000,\n",
    "  'start_delay_secs': 30,\n",
    "  'throttle_secs': 30\n",
    "}\n",
    "\n",
    "train_and_evaluate(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on module locally\n",
    "\n",
    "Now let's place our code into a python module with model.py and task.py files so that we can train using Google Cloud's ML Engine! First, let's test our module locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%writefile requirements.txt\n",
    "tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket=qwiklabs-gcp-ca86714dede2236a\n",
      "number_of_content_ids = 15634\n",
      "number_of_categories = 3\n",
      "number_of_authors = 1103\n",
      "mean_months_since_epoch = 573.60733908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0321 10:05:11.164171 140015820941056 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "INFO:tensorflow:vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n",
      "I0321 10:05:12.515268 140015820941056 tf_logging.py:116] vocabulary_size = 3 in category is inferred from the number of elements in the vocabulary_file gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/preproc/vocabs/category_vocab.txt-00000-of-00001.\n",
      "INFO:tensorflow:Using default config.\n",
      "I0321 10:05:12.567122 140015820941056 tf_logging.py:116] Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpv5d2gtrf\n",
      "W0321 10:05:12.567881 140015820941056 tf_logging.py:126] Using temporary folder as model directory: /tmp/tmpv5d2gtrf\n",
      "INFO:tensorflow:Using config: {'_session_config': None, '_tf_random_seed': None, '_task_type': 'worker', '_service': None, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57db29e128>, '_num_ps_replicas': 0, '_evaluation_master': '', '_model_dir': '/tmp/tmpv5d2gtrf', '_task_id': 0, '_keep_checkpoint_max': 5, '_train_distribute': None, '_save_checkpoints_secs': 600, '_master': '', '_is_chief': True, '_save_summary_steps': 100, '_global_id_in_cluster': 0}\n",
      "I0321 10:05:12.568919 140015820941056 tf_logging.py:116] Using config: {'_session_config': None, '_tf_random_seed': None, '_task_type': 'worker', '_service': None, '_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f57db29e128>, '_num_ps_replicas': 0, '_evaluation_master': '', '_model_dir': '/tmp/tmpv5d2gtrf', '_task_id': 0, '_keep_checkpoint_max': 5, '_train_distribute': None, '_save_checkpoints_secs': 600, '_master': '', '_is_chief': True, '_save_summary_steps': 100, '_global_id_in_cluster': 0}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "I0321 10:05:12.571728 140015820941056 tf_logging.py:116] Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "I0321 10:05:12.572043 140015820941056 tf_logging.py:116] Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:05:12.730532 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:05:13.067089 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:05:21.945232 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0321 10:05:21.947633 140015820941056 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:05:22.369710 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "2019-03-21 10:05:22.476651: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:05:24.718751: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:05:24.945648 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:05:26.150343 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:05:27.945282 140015820941056 tf_logging.py:116] Saving checkpoints for 1 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 9.656153\n",
      "I0321 10:05:28.375269 140015820941056 tf_logging.py:116] step = 1, loss = 9.656153\n",
      "INFO:tensorflow:global_step/sec: 6.58676\n",
      "I0321 10:05:43.556842 140015820941056 tf_logging.py:116] global_step/sec: 6.58676\n",
      "INFO:tensorflow:step = 101, loss = 5.127722 (15.183 sec)\n",
      "I0321 10:05:43.558103 140015820941056 tf_logging.py:116] step = 101, loss = 5.127722 (15.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.88916\n",
      "I0321 10:05:58.072424 140015820941056 tf_logging.py:116] global_step/sec: 6.88916\n",
      "INFO:tensorflow:step = 201, loss = 4.960372 (14.516 sec)\n",
      "I0321 10:05:58.073629 140015820941056 tf_logging.py:116] step = 201, loss = 4.960372 (14.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.81633\n",
      "I0321 10:06:12.743108 140015820941056 tf_logging.py:116] global_step/sec: 6.81633\n",
      "INFO:tensorflow:step = 301, loss = 4.663126 (14.671 sec)\n",
      "I0321 10:06:12.744419 140015820941056 tf_logging.py:116] step = 301, loss = 4.663126 (14.671 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 367 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:06:22.344448 140015820941056 tf_logging.py:116] Saving checkpoints for 367 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.9534445.\n",
      "I0321 10:06:23.559215 140015820941056 tf_logging.py:116] Loss for final step: 4.9534445.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:06:23.681075 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:06:24.015726 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:06:24.668001 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21-10:06:24\n",
      "I0321 10:06:24.691646 140015820941056 tf_logging.py:116] Starting evaluation at 2019-03-21-10:06:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:06:24.815823 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "I0321 10:06:24.816503 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "2019-03-21 10:06:25.179831: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:06:25.368976: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:06:25.573814 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:06:26.831753 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-10:07:03\n",
      "I0321 10:07:03.741220 140015820941056 tf_logging.py:116] Finished evaluation at 2019-03-21-10:07:03\n",
      "INFO:tensorflow:Saving dict for global step 367: accuracy = 0.02824329, global_step = 367, loss = 5.761032, map_at_k = 0.05567380952380956, top_k_accuracy = 0.19672644\n",
      "I0321 10:07:03.741884 140015820941056 tf_logging.py:116] Saving dict for global step 367: accuracy = 0.02824329, global_step = 367, loss = 5.761032, map_at_k = 0.05567380952380956, top_k_accuracy = 0.19672644\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:07:04.737026 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:07:05.302920 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:07:05.751920 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0321 10:07:05.766442 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "I0321 10:07:05.767023 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0321 10:07:05.767189 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "I0321 10:07:05.800428 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "2019-03-21 10:07:05.849464: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:07:06.060531: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0321 10:07:06.235268 140015820941056 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162825'/assets\"\n",
      "I0321 10:07:06.247756 140015820941056 tf_logging.py:116] Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162825'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162825'/saved_model.pb\"\n",
      "I0321 10:07:06.813666 140015820941056 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162825'/saved_model.pb\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:07:07.002555 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:07:07.337177 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:07:08.254697 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0321 10:07:08.257286 140015820941056 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:07:08.593527 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "I0321 10:07:08.595090 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-367\n",
      "2019-03-21 10:07:08.666110: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:07:08.860251: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:07:09.065774 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:07:10.269709 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 368 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:07:11.979998 140015820941056 tf_logging.py:116] Saving checkpoints for 368 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:step = 368, loss = 5.8966393\n",
      "I0321 10:07:13.314078 140015820941056 tf_logging.py:116] step = 368, loss = 5.8966393\n",
      "INFO:tensorflow:global_step/sec: 6.68434\n",
      "I0321 10:07:28.274178 140015820941056 tf_logging.py:116] global_step/sec: 6.68434\n",
      "INFO:tensorflow:step = 468, loss = 5.1058836 (14.962 sec)\n",
      "I0321 10:07:28.275785 140015820941056 tf_logging.py:116] step = 468, loss = 5.1058836 (14.962 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.90142\n",
      "I0321 10:07:42.763721 140015820941056 tf_logging.py:116] global_step/sec: 6.90142\n",
      "INFO:tensorflow:step = 568, loss = 4.1829505 (14.489 sec)\n",
      "I0321 10:07:42.764862 140015820941056 tf_logging.py:116] step = 568, loss = 4.1829505 (14.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.94194\n",
      "I0321 10:07:57.168970 140015820941056 tf_logging.py:116] global_step/sec: 6.94194\n",
      "INFO:tensorflow:step = 668, loss = 4.7681937 (14.406 sec)\n",
      "I0321 10:07:57.170518 140015820941056 tf_logging.py:116] step = 668, loss = 4.7681937 (14.406 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 746 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:08:08.397488 140015820941056 tf_logging.py:116] Saving checkpoints for 746 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.699459.\n",
      "I0321 10:08:10.028292 140015820941056 tf_logging.py:116] Loss for final step: 4.699459.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:08:10.172677 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:08:10.482991 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:08:11.135680 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21-10:08:11\n",
      "I0321 10:08:11.159751 140015820941056 tf_logging.py:116] Starting evaluation at 2019-03-21-10:08:11\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:08:11.275726 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "I0321 10:08:11.276396 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "2019-03-21 10:08:11.325425: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:08:11.510924: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:08:11.764003 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:08:12.944927 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-10:08:48\n",
      "I0321 10:08:48.760165 140015820941056 tf_logging.py:116] Finished evaluation at 2019-03-21-10:08:48\n",
      "INFO:tensorflow:Saving dict for global step 746: accuracy = 0.026211962, global_step = 746, loss = 5.6511607, map_at_k = 0.05418293650793655, top_k_accuracy = 0.21512559\n",
      "I0321 10:08:48.760721 140015820941056 tf_logging.py:116] Saving dict for global step 746: accuracy = 0.026211962, global_step = 746, loss = 5.6511607, map_at_k = 0.05418293650793655, top_k_accuracy = 0.21512559\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:08:49.456525 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:08:50.041969 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:08:50.490950 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0321 10:08:50.505581 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "I0321 10:08:50.506120 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0321 10:08:50.506264 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "I0321 10:08:50.541059 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "2019-03-21 10:08:50.580101: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:08:50.799756: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0321 10:08:50.987410 140015820941056 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162930'/assets\"\n",
      "I0321 10:08:51.000934 140015820941056 tf_logging.py:116] Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162930'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162930'/saved_model.pb\"\n",
      "I0321 10:08:51.583062 140015820941056 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553162930'/saved_model.pb\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:08:51.771954 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:08:52.111362 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:08:53.035711 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "I0321 10:08:53.039194 140015820941056 tf_logging.py:116] Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:08:53.382632 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "I0321 10:08:53.384222 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-746\n",
      "2019-03-21 10:08:53.456873: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:08:53.655201: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:08:53.962131 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:08:55.178126 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 747 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:08:56.827338 140015820941056 tf_logging.py:116] Saving checkpoints for 747 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:step = 747, loss = 5.5109835\n",
      "I0321 10:08:58.204771 140015820941056 tf_logging.py:116] step = 747, loss = 5.5109835\n",
      "INFO:tensorflow:global_step/sec: 6.78892\n",
      "I0321 10:09:12.934331 140015820941056 tf_logging.py:116] global_step/sec: 6.78892\n",
      "INFO:tensorflow:step = 847, loss = 4.8405485 (14.731 sec)\n",
      "I0321 10:09:12.935608 140015820941056 tf_logging.py:116] step = 847, loss = 4.8405485 (14.731 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.91555\n",
      "I0321 10:09:27.394464 140015820941056 tf_logging.py:116] global_step/sec: 6.91555\n",
      "INFO:tensorflow:step = 947, loss = 4.328061 (14.460 sec)\n",
      "I0321 10:09:27.395734 140015820941056 tf_logging.py:116] step = 947, loss = 4.328061 (14.460 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "I0321 10:09:35.233446 140015820941056 tf_logging.py:116] Saving checkpoints for 1000 into /tmp/tmpv5d2gtrf/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.857939.\n",
      "I0321 10:09:36.893922 140015820941056 tf_logging.py:116] Loss for final step: 4.857939.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:09:37.050549 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:09:37.372421 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:09:38.031782 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-03-21-10:09:38\n",
      "I0321 10:09:38.056528 140015820941056 tf_logging.py:116] Starting evaluation at 2019-03-21-10:09:38\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "I0321 10:09:38.175807 140015820941056 tf_logging.py:116] Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-1000\n",
      "I0321 10:09:38.176546 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-1000\n",
      "2019-03-21 10:09:38.225133: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:09:38.418219: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "I0321 10:09:38.676652 140015820941056 tf_logging.py:116] Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "I0321 10:09:39.866435 140015820941056 tf_logging.py:116] Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-03-21-10:10:15\n",
      "I0321 10:10:15.794449 140015820941056 tf_logging.py:116] Finished evaluation at 2019-03-21-10:10:15\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.02890738, global_step = 1000, loss = 5.626688, map_at_k = 0.05263680555555558, top_k_accuracy = 0.20653151\n",
      "I0321 10:10:15.795113 140015820941056 tf_logging.py:116] Saving dict for global step 1000: accuracy = 0.02890738, global_step = 1000, loss = 5.626688, map_at_k = 0.05263680555555558, top_k_accuracy = 0.20653151\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "I0321 10:10:16.532462 140015820941056 tf_logging.py:116] Calling model_fn.\n",
      "INFO:tensorflow:Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "I0321 10:10:17.095989 140015820941056 tf_logging.py:116] Initialize variable input_layer/title_hub_module_embedding/module/embeddings/part_0:0 from checkpoint b'/tmp/tfhub_modules/a7d8eed670ca9e0a562438724b64dacf646b3999/variables/variables' with embeddings\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "I0321 10:10:17.536554 140015820941056 tf_logging.py:116] Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "I0321 10:10:17.549746 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "I0321 10:10:17.550251 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Predict: ['predict_export_outputs', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "I0321 10:10:17.550397 140015820941056 tf_logging.py:116] Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-1000\n",
      "I0321 10:10:17.581782 140015820941056 tf_logging.py:116] Restoring parameters from /tmp/tmpv5d2gtrf/model.ckpt-1000\n",
      "2019-03-21 10:10:17.617266: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "2019-03-21 10:10:17.823840: W tensorflow/core/framework/allocator.cc:101] Allocation of 195793000 exceeds 10% of system memory.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "I0321 10:10:17.999580 140015820941056 tf_logging.py:116] Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553163017'/assets\"\n",
      "I0321 10:10:18.012617 140015820941056 tf_logging.py:116] Assets written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553163017'/assets\"\n",
      "INFO:tensorflow:SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553163017'/saved_model.pb\"\n",
      "I0321 10:10:18.561697 140015820941056 tf_logging.py:116] SavedModel written to: b\"/tmp/tmpv5d2gtrf/export/exporter/temp-b'1553163017'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"bucket=${BUCKET}\"\n",
    "rm -rf hybrid_recommendation_trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/hybrid_recommendations_module\n",
    "python -m trainer.task \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on Google Cloud ML Engine\n",
    "If our module locally trained fine, let's now use of the power of ML Engine to scale it out on Google Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-ca86714dede2236a/hybrid_recommendation/small_trained_model europe-west1 hybrid_recommendation_190321_101243\n",
      "jobId: hybrid_recommendation_190321_101243\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hybrid_recommendation_190321_101243] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hybrid_recommendation_190321_101243\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hybrid_recommendation_190321_101243\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/small_trained_model\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "``` \n",
    "Saving dict for global step 1008: accuracy = 0.02687605, global_step = 1008, loss = 5.470378, map_at_k = 0.05117718253968257, top_k_accuracy = 0.2249502\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some hyperparameter tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing hyperparam.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile hyperparam.yaml\n",
    "trainingInput:\n",
    "  hyperparameters:\n",
    "    goal: MAXIMIZE\n",
    "    maxTrials: 5\n",
    "    maxParallelTrials: 1\n",
    "    hyperparameterMetricTag: accuracy\n",
    "    params:\n",
    "    - parameterName: batch_size\n",
    "      type: INTEGER\n",
    "      minValue: 8\n",
    "      maxValue: 64\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: learning_rate\n",
    "      type: DOUBLE\n",
    "      minValue: 0.01\n",
    "      maxValue: 0.1\n",
    "      scaleType: UNIT_LINEAR_SCALE\n",
    "    - parameterName: hidden_units\n",
    "      type: CATEGORICAL\n",
    "      categoricalValues: ['1024 512 256', '1024 512 128', '1024 256 128', '512 256 128', '1024 512 64', '1024 256 64', '512 256 64', '1024 128 64', '512 128 64', '256 128 64', '1024 512 32', '1024 256 32', '512 256 32', '1024 128 32', '512 128 32', '256 128 32', '1024 64 32', '512 64 32', '256 64 32', '128 64 32']\n",
    "    - parameterName: content_id_embedding_dimensions\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 250\n",
    "      scaleType: UNIT_LOG_SCALE\n",
    "    - parameterName: author_embedding_dimensions\n",
    "      type: INTEGER\n",
    "      minValue: 5\n",
    "      maxValue: 30\n",
    "      scaleType: UNIT_LINEAR_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-79ea9b31a1bf3bcb/hybrid_recommendation/hypertuning europe-west1 hybrid_recommendation_190401_135413\n",
      "jobId: hybrid_recommendation_190401_135413\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hybrid_recommendation_190401_135413] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hybrid_recommendation_190401_135413\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hybrid_recommendation_190401_135413\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/hypertuning\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  --config=hyperparam.yaml \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=1000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results can be found in the *Job Details* under *Training Output*:\n",
    "\n",
    "```\n",
    "Training output\n",
    "{\n",
    "  \"completedTrialCount\": \"5\",\n",
    "  \"trials\": [\n",
    "    {\n",
    "      \"trialId\": \"5\",\n",
    "      \"hyperparameters\": {\n",
    "        \"batch_size\": \"40\",\n",
    "        \"learning_rate\": \"0.072136064767837529\",\n",
    "        \"author_embedding_dimensions\": \"19\",\n",
    "        \"hidden_units\": \"256 128 64\",\n",
    "        \"content_id_embedding_dimensions\": \"139\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1007\",\n",
    "        \"objectiveValue\": 0.0253916177899\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"2\",\n",
    "      \"hyperparameters\": {\n",
    "        \"hidden_units\": \"256 128 32\",\n",
    "        \"content_id_embedding_dimensions\": \"21\",\n",
    "        \"batch_size\": \"46\",\n",
    "        \"learning_rate\": \"0.031392376422882083\",\n",
    "        \"author_embedding_dimensions\": \"12\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1007\",\n",
    "        \"objectiveValue\": 0.022344622761\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"1\",\n",
    "      \"hyperparameters\": {\n",
    "        \"batch_size\": \"43\",\n",
    "        \"learning_rate\": \"0.073695758581161508\",\n",
    "        \"author_embedding_dimensions\": \"21\",\n",
    "        \"hidden_units\": \"512 256 64\",\n",
    "        \"content_id_embedding_dimensions\": \"78\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1006\",\n",
    "        \"objectiveValue\": 0.0157818663865\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"4\",\n",
    "      \"hyperparameters\": {\n",
    "        \"hidden_units\": \"1024 512 128\",\n",
    "        \"content_id_embedding_dimensions\": \"22\",\n",
    "        \"batch_size\": \"48\",\n",
    "        \"learning_rate\": \"0.084746223688125608\",\n",
    "        \"author_embedding_dimensions\": \"9\"\n",
    "      },\n",
    "      \"finalMetric\": {\n",
    "        \"trainingStep\": \"1004\",\n",
    "        \"objectiveValue\": 0.0108988629654\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"trialId\": \"3\",\n",
    "      \"hyperparameters\": {\n",
    "        \"hidden_units\": \"1024 512 128\",\n",
    "        \"content_id_embedding_dimensions\": \"245\",\n",
    "        \"batch_size\": \"8\",\n",
    "        \"learning_rate\": \"0.080643538236618045\",\n",
    "        \"author_embedding_dimensions\": \"8\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"consumedMLUnits\": 3.55,\n",
    "  \"isHyperparameterTuningJob\": true\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the best hyperparameters, run a big training job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-79ea9b31a1bf3bcb/hybrid_recommendation/big_trained_model europe-west1 hybrid_recommendation_190401_135303\n",
      "jobId: hybrid_recommendation_190401_135303\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [hybrid_recommendation_190401_135303] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe hybrid_recommendation_190401_135303\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs hybrid_recommendation_190401_135303\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "OUTDIR=gs://${BUCKET}/hybrid_recommendation/big_trained_model\n",
    "JOBNAME=hybrid_recommendation_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --region=$REGION \\\n",
    "  --module-name=trainer.task \\\n",
    "  --package-path=$(pwd)/hybrid_recommendations_module/trainer \\\n",
    "  --job-dir=$OUTDIR \\\n",
    "  --staging-bucket=gs://$BUCKET \\\n",
    "  --scale-tier=STANDARD_1 \\\n",
    "  --runtime-version=$TFVERSION \\\n",
    "  -- \\\n",
    "  --bucket=${BUCKET} \\\n",
    "  --train_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/train.csv* \\\n",
    "  --eval_data_paths=gs://${BUCKET}/hybrid_recommendation/preproc/features/eval.csv* \\\n",
    "  --output_dir=${OUTDIR} \\\n",
    "  --batch_size=128 \\\n",
    "  --learning_rate=0.1 \\\n",
    "  --hidden_units=\"256 128 64\" \\\n",
    "  --content_id_embedding_dimensions=10 \\\n",
    "  --author_embedding_dimensions=10 \\\n",
    "  --top_k=10 \\\n",
    "  --train_steps=10000 \\\n",
    "  --start_delay_secs=30 \\\n",
    "  --throttle_secs=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results:\n",
    "\n",
    "First run:\n",
    "\n",
    "```\n",
    "Saving dict for global step 10008: accuracy = 0.045392398, global_step = 10008, loss = 5.0295167, map_at_k = 0.04409563492063496, top_k_accuracy = 0.27708113\n",
    "```\n",
    "\n",
    "Second run:\n",
    "\n",
    "```\n",
    "Saving dict for global step 10008: accuracy = 0.059221063, global_step = 10008, loss = 4.820803, map_at_k = 0.04631904761904759, top_k_accuracy = 0.33321613\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
