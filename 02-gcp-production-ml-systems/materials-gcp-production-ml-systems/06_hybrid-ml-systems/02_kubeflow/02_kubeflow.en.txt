So, you know what is really good at composability, portability, and scalability? Containers and Kubernetes, except, turns out even then it's not so easy. If you want to do this all on Kubernetes, you've got to become an expert in a lot of stuff. Containers, packaging, scaling, immutable deployments, GPUs, drivers, Cloud APIs, the list goes on and on and on. Surely, we can introduce something to make this easier. That's where Kubeflow comes in. The Kubeflow mission is to make it easy for everyone to develop, deploy, and manage portable, distributed machine learning on Kubernetes, and the team is serious when they say everyone. We wanted to work everywhere that Kubernetes does, and so then, because we are using Kubernetes abstractions, this extremely complicated deployment. It becomes just an installation of Kubernetes and your entire stack becomes described by a Kubeflow stack that works everywhere. Your laptop via minikube, your on-premises training cluster, and your cloud deployment. So, Kubeflow is very new, but it already has core components that help you get started with machine learning in the box. So, what's in the box? Jupyter, distributed training, model serving, plus examples. Quite importantly, it uses a customizable Ksonnet packaging that allows you to add your own. Training, building a model, model validation, training at scale, and serving, they're already all currently in the box. Not surprisingly, this is exactly the pieces that Cloud ML Engine handles in a serverless way. So, what Kubeflow does is that Kubeflow offers portability and composability between your on-premises environment, where you use Kubeflow, and Cloud ML Engine which provides a serverless way to run these same components on Google Cloud. Or you can run Kubeflow on GKE the same way. So, in the next video, we will show you a demo of how this works