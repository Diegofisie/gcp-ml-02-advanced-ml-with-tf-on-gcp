We've seen this before. This is how you use the tf.data API to read CSV files. I'm creating a text line datasets and calling decode_csv on each line of the file or files because I'm using a glob here to do a pattern match. So, in each line of the input files decode_csv is called. The decode_csv jfunction called tf.decode_csv attaches the column name to it and sends back the features and labels to the graph. All of these TensorFlow classes and functions tf.data, tf.datamap, tf.decode_csv are all implemented in C++, so you can get very good performance. The key to this is not to bring the data back into Python, that context switch can be expensive. So, implement your input function in terms of TensorFlow native ops and you'll get really good performance. There is some Python code here in terms of the dict and zip calls. Unfortunately, that's necessary because the CSV file is not self-describing. Still, this does come at the very end, so it's not a back and forth context switch. A quick digression, did you notice the shuffle here? Why do you think we might need that? Remember data parallelism? Well, in data parallelism, if all of the workers are computing the gradient on the same set of data, there is no need to have all of those workers. Therefore, each of the workers needs to see a different slice of data. Given that we're reading from the same CSV file, how do we try to get each of the workers at different slice the data? Well, we do that by reading in 10 times the batch size, shuffling it and then serving it out one batch at a time. The chances are that each worker is holding the data in a different order. So, the batch size of examples that each worker processes will be different, and that's why we shuffle. Shuffling is essential when you do distributed data using data parallelism. We looked at using native TensorFlow ops for CSV files, but how about for images? If your model is an image model, this is how you use native TensorFlow ops. Assuming here I have two lists, a list of file names and their corresponding labels. But you could get the labels also by parsing the filename. Perhaps all the files in a specific folder could correspond to the same label. Then, for each file and labeled pair you call the _parse_function. Unlike decode_csv, which is parsed on a single line of a CSV, the _parse_function here reads the entire image, but it does use native TensorFlow ops to do so. So, here, as you can see, it uses tf.read_file to read in the entire file content. Then, tf.decode_image to parse the image formats and resize it to be 299 by 299 before it returns it. The point as before is to use native TensorFlow ops to keep all of the operations in C++ and therefore very-