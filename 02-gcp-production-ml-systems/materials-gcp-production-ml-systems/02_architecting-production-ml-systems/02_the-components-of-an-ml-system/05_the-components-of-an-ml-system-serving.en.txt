Next we'll talk about the serving component. The serving component should be low-latency to respond to users quickly. Highly efficient so that many instances can be run simultaneously, and scale horizontally in order to be reliable and robust to failures. In contrast to training when we care about scaling with our data, at serving we care about responding to variable user demand maximizing throughput and minimizing response latency. Another important feature, it should be easy to update to new versions of the model. When we get new data or engineer new features, we'll want to retrain and push a new version of the model and you want the system to seamlessly transition to the new model version. More generally, the system should allow you to set up a multi-armed bandit architecture to verify which model versions are the best. Just as with training, there are two options for serving on GCP. You can either use a fully managed TensorFlow serving service which is ML Engine or you can run TF serving on Kubernetes engine. The next component we'll look at is logging. Logging is critical for debugging and comparison and what's important is that all logs be easily accessible and integrated. With cloud reliability, you get easy integration with all the other GCP products, the ability to craft alerting policies, and the ability to detect when new errors occur.