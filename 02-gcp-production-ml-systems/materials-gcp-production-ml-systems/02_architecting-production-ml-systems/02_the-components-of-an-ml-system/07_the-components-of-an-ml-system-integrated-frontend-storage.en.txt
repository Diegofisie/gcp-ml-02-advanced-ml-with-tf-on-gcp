And just as everything needs to talk to everything else, the users of the system need to be able to easily accomplish their tasks, and as central a location as possible. In GCP, you can use TensorBoard and Cloud ML Engine. TensorBoard is the visualization software that comes bundled with TensorFlow. We saw in the first specialization about how it can be used to look at loss curves as models train, but TensorBoard is actually capable of a lot more. Out of the box, it comes ready to visualize the graphs of your models and the distributions of things like weights. Additionally, it's possible to write custom visualization modules for other types of input, and people have done so for sound and images. TensorBoard is also capable of showing what the model has learned about the input space, which you can see in the projector tab in the interface. We'll talk about this more in a later course on sequence models, but you can get a sense of what this part of the interface looks like at projectory.tensorflow.org. In the demo, the points represent the meanings of words in semantic space. If you type a word in the right hand search bar, you can find all of the semantically similar words that the model has learned. We've also just recently added the ability to debug models in an environment similar to what you'd find within an IDE with line-by-line execution, and the ability to set break points, and view the contents of tensors in the graph. This is an alpha feature though. Storage is necessary for staging intermediate output of these components. In GCP that's Google Cloud Storage.