1
00:00:00,000 --> 00:00:03,530
In this section, we'll apply what we've learned to a new use case.

2
00:00:03,530 --> 00:00:06,660
Let's pretend the head of a municipal transit system has

3
00:00:06,660 --> 00:00:10,400
contacted you to build a system that predicts the traffic levels on roads.

4
00:00:10,400 --> 00:00:12,810
As part of your preparation for this task,

5
00:00:12,810 --> 00:00:15,210
you're trying to thoroughly understand the business constraints

6
00:00:15,210 --> 00:00:18,145
in order to make the appropriate system design trade-offs.

7
00:00:18,145 --> 00:00:21,655
The data available consists of sensors deployed all over the city,

8
00:00:21,655 --> 00:00:24,300
which record whenever a cart car passes by.

9
00:00:24,300 --> 00:00:26,600
For each sensor, we know where it is.

10
00:00:26,600 --> 00:00:29,735
We also know the characteristics of the road that it's on.

11
00:00:29,735 --> 00:00:33,460
What sort of training architecture is appropriate.

12
00:00:33,650 --> 00:00:35,865
Well, you should ask yourself,

13
00:00:35,865 --> 00:00:38,585
what is the relationship between the features and the labels?

14
00:00:38,585 --> 00:00:41,850
Is it more like physics or fashion?

15
00:00:41,850 --> 00:00:44,135
In this case, it's more like fashion trends.

16
00:00:44,135 --> 00:00:46,145
Cities are very complex systems.

17
00:00:46,145 --> 00:00:47,490
If a train stop service,

18
00:00:47,490 --> 00:00:49,145
people will still need to get home.

19
00:00:49,145 --> 00:00:51,105
Technologies also always changing.

20
00:00:51,105 --> 00:00:53,270
On-demand taxi services have reshaped

21
00:00:53,270 --> 00:00:55,860
urban transit in ways we didn't anticipate a decade ago.

22
00:00:55,860 --> 00:01:00,615
There are also episodic changes like sports events and parades for example.

23
00:01:00,615 --> 00:01:04,000
For dynamic relationships, we need to use dynamic training.

24
00:01:04,000 --> 00:01:07,255
Which sort of serving architecture is appropriate.

25
00:01:07,255 --> 00:01:09,185
Well, you should ask yourself,

26
00:01:09,185 --> 00:01:11,235
is the distribution of prediction requests,

27
00:01:11,235 --> 00:01:14,070
likely to be more peaked or less peaked?

28
00:01:14,070 --> 00:01:17,155
In this case is likely to be more peaked.

29
00:01:17,155 --> 00:01:20,360
The distribution of demand is peaked because it's likely to be

30
00:01:20,360 --> 00:01:24,440
dominated by the request for the most heavily trafficked roads.

31
00:01:24,740 --> 00:01:29,085
Is the cardinality of the set of all prediction requests likely to be low,

32
00:01:29,085 --> 00:01:32,760
moderate, high, or perhaps need more info?

33
00:01:32,760 --> 00:01:35,880
In this case, you need more info.

34
00:01:35,880 --> 00:01:39,230
Why is that? What does it depend upon?

35
00:01:39,230 --> 00:01:41,595
Consider historical traffic data,

36
00:01:41,595 --> 00:01:45,780
problem framing, or the variance of traffic levels.

37
00:01:46,520 --> 00:01:51,605
In this case, the answers are both historical traffic data and the problem framing,

38
00:01:51,605 --> 00:01:53,860
but not the variants of traffic levels.

39
00:01:53,860 --> 00:01:57,230
The reason that the cardinality depends upon the framing of the problem,

40
00:01:57,230 --> 00:01:59,030
is that we don't know whether the task is to make

41
00:01:59,030 --> 00:02:01,540
predictions for every minute, hour, or day.

42
00:02:01,540 --> 00:02:03,920
Similarly, we don't know how big a region

43
00:02:03,920 --> 00:02:06,040
of space each prediction and should correspond to.

44
00:02:06,040 --> 00:02:08,860
It could be anything from a few feet to a few blocks.

45
00:02:08,860 --> 00:02:11,295
As we learned in the first specialization,

46
00:02:11,295 --> 00:02:13,430
machine learning is all about generalization.

47
00:02:13,430 --> 00:02:15,780
The leap of faith to unseen input.

48
00:02:15,780 --> 00:02:19,820
What we don't know is whether our users want to generalize in space, i.e.

49
00:02:19,820 --> 00:02:23,330
by making predictions far away from the sensors in time,

50
00:02:23,330 --> 00:02:24,830
by making predictions in the future with

51
00:02:24,830 --> 00:02:28,065
finer granularity than the historical data or both.

52
00:02:28,065 --> 00:02:30,800
In all likelihood, you'd start conservatively which

53
00:02:30,800 --> 00:02:34,335
corresponds to a lower rather than higher cardinality.

54
00:02:34,335 --> 00:02:38,870
Variants of traffic levels wouldn't matter because that's a label and not a feature.