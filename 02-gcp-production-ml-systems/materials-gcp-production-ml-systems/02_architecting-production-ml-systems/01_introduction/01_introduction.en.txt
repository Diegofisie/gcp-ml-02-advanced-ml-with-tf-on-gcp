Hi, welcome back to the production ML systems course. This is the second module in the course and we'll be covering what architectures are composed of, why and how to make good systems design decisions. We're going to begin today in a untypical way with a quiz. What percent of system code does the ML model accounts for? Five percent? Twenty five percent? Fifty percent or ninety percent? Recall that in the earlier specialization we talked about how time is distributed among data wrangling and feature engineering and other tasks. Surprisingly, modeling accounted for far less than most people expect. A similar relationship holds with respect to the code. ML model code typically accounts for about five percent of the overall codebase. The reason that ML models account for such a small percentage is that to keep the system running in production, it requires a lot more than just computing the model's outputs for a given set of inputs. In this module, we'll talk about what else the production ML system needs to do and how you can meet those needs. We'll then review some important high-level decisions around training and model serving that you'll need to make in order to get the right performance profile for your model. By the end of this module, you should be able to choose the appropriate training and serving per paradigm. Serve ML model scalably and design and architecture from scratch. So, what are the components that make up the other 95 percent of system code? There are quite a few. In this first section we're going to go through them one by one. For every component, we'll talk about what it does, why that function is important for the system overall and how GCP products align to these components. But even though we're talking about GCP, you should always try and reuse generic systems where you can. There are lots of good reusable often open-source frameworks, so don't reinvent the wheel. Additionally, what's true of software frameworks like TensorFlow, Spark or Apache Beam is also true of the underlying infrastructure on which you execute them. Rather than spend time and effort provisioning infrastructure, use managed services like Cloud Dataproc, Cloud ML Engine or Cloud Dataflow to execute your Spark, TensorFlow, and Beam code.