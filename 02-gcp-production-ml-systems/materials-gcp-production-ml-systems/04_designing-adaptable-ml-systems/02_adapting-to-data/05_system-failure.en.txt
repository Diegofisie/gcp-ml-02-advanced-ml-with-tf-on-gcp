Here's another slightly different scenario. You've trained the product recommendation model based upon users click and purchasing behavior on your e-commerce site. On Black Friday, your server responsible for transactions and payments goes down even while the web server stays up, so the model thinks that no one who clicks is buying anything. It's impossible to have models unlearn things that they've learned already, but one thing you can do is to roll back your model state to a time prior to the data pollution. Of course, in order to do this, you'll need infrastructure that automatically creates and saves models as well as their meta information. Here's another scenario. You've trained the static product recommendation model, which alone will determine which products users see when they're on the homepage and when they're viewing individual products. The model works by using purchasing behavior of other users. After deploying it, user session time and conversion rate initially increase but in the months that follow the release of the model, both of these metrics steadily decline to slightly below the levels that they were before the launch of the model. What went wrong? What went wrong is that your model's not updating to new users and new products, and new patterns and user preference. Because the model knows only about your older models because it was statically trained, it continues to recommend them long after they've fallen out of favor. Ultimately, users simply ignore the recommendations altogether and may do with the site search functionality. This cold start problem is common for this recommendation model. We'll talk more about recommendation systems in course ten. The solution here is to dynamically retrain your model on newer data, and secondly, to understand the limits of your model. Here's another scenario. You've deployed a statically trained fraud detection model and its performance starts off good but quickly degrades. In adversarial environments where one party is trying to beat another, it's particularly important to dynamically retrain the model to keep up with the most recent strategies.