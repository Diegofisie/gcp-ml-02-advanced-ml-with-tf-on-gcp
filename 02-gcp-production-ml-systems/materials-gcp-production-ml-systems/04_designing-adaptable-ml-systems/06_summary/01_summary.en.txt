So now you've gotten a taste of all the ways that ML systems depend on data, and the sorts of real-world events that can cause data to change. Sometimes it's data that are owned by other teams, sometimes it's the failure of other parts of the system, and sometimes it's feedback loops that influenced the data that we're trying to collect. There isn't a single practice that will insulate your system from these sorts of changes. Instead, there are a number of things you should do. Firstly, you should keep humans in the loop. You need to monitor everything, from the distribution of your inputs to the distribution of your outputs, but also critically to your business performance metrics. Secondly, you should prioritize maintainability. You need to constantly assess the value of all data sources, and weigh their performance benefit against the cost to maintain them. Finally, you need to get ready to roll back. There is no way to unteach a model something that it has learned already. The only thing you can do is to roll back to a model version that didn't learn from polluted data. Design your infrastructure with this in mind.