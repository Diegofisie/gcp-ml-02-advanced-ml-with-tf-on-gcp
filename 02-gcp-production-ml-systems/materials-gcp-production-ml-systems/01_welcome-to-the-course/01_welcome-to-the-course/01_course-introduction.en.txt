Hi, I'm Valentine Fontama. I'm a machine learning and AI practice lead at Google Professional Services. I want to warmly welcome you to this second course in our advanced specialization. The second course is on building production ML models. The considerations behind them, static training, dynamic training, static inference, dynamic inference, distributed TensorFlow, and TPUs. So far, we've focused our attention on how to build models that can do a good job predicting on previously unseen data. That of course, is the heart of any machine learning system. But real-world production ML systems are large ecosystem of which the model code itself is just a small part. The rest, consists of code that perform critical functions some of which we've seen already like data pipelining, and some that we've not. This course is devoted to exploring the characteristics that make for a good ML system beyond its ability to make good predictions. We'll start at a high level in module one, where we will discuss many of the things that the system should be able to do, and the components that take responsibility for doing these things. We'll also review two important decisions that system architects will have to make. In module two, we'll talk about how to bring your data to the Cloud because that's a prerequisite for much of the system's architecture we discuss in this course and indeed in this specialization. In module three, we'll talk about change. How it can affect an ML system, and what we can do to mitigate those effects? In module four, we'll talk about how to squeeze the most performance out of your ML system by choosing the right hardware and removing bottlenecks. Finally, in module five, we'll talk at a high level about the technology behind hybrid systems, which may run on the Cloud, or the Edge, or in fact, on-premises. I'll now hand it over to my colleague Max, who will start us off with architecting production ML systems.