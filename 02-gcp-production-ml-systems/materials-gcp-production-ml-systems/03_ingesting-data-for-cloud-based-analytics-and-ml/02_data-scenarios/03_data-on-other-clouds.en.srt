1
00:00:00,000 --> 00:00:04,890
A common use case is your organization has a multi-cloud solution,

2
00:00:04,890 --> 00:00:09,150
and data already exists on another cloud provider.

3
00:00:09,150 --> 00:00:12,990
The cloud to cloud transfer service transfers

4
00:00:12,990 --> 00:00:16,780
data from an online data source to a data sink.

5
00:00:16,780 --> 00:00:22,805
Your data source can be an Amazon simple storage service or Amazon S3 bucket,

6
00:00:22,805 --> 00:00:27,040
it can be an HTTP or HTTPS location,

7
00:00:27,040 --> 00:00:29,685
a Google Cloud Storage bucket.

8
00:00:29,685 --> 00:00:34,840
Now why, would your source via Google Cloud Storage bucket?

9
00:00:34,840 --> 00:00:40,440
Well, if you're transferring data between regions within Google,

10
00:00:40,570 --> 00:00:47,840
your data sink or the destination is always a Google Cloud storage bucket.

11
00:00:47,840 --> 00:00:51,500
The GS Command Line Tool also enables you to

12
00:00:51,500 --> 00:00:57,110
transfer data between Google Cloud storage and other locations.

13
00:00:57,110 --> 00:01:02,000
While you can use gsutil to work with Amazon S3 buckets and

14
00:01:02,000 --> 00:01:06,710
transfer data from Amazon S3 to Google Cloud storage,

15
00:01:06,710 --> 00:01:11,950
the storage transfer service is highly recommended for this use.

16
00:01:12,190 --> 00:01:16,055
Creating a transfer job is simple.

17
00:01:16,055 --> 00:01:19,690
You first specify the source and sink,

18
00:01:19,690 --> 00:01:23,185
like from S3 to GCS.

19
00:01:23,185 --> 00:01:27,260
Then you configure the transfer as

20
00:01:27,260 --> 00:01:32,320
a one time job or a routine transfer job and that's it.