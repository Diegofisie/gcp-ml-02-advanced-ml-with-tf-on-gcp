{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Create TensorFlow model </h1>\n",
    "\n",
    "This notebook illustrates:\n",
    "<ol>\n",
    "<li> Creating a model using the high-level Estimator API \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-1611e5b8d02256c3\n",
      "inna-bckt-1611e5b8d02256c3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "output = os.popen(\"gcloud config get-value project\").readlines()\n",
    "project_name = output[0][:-1]\n",
    "\n",
    "# change these to try this notebook out\n",
    "PROJECT = project_name\n",
    "BUCKET = project_name\n",
    "BUCKET = BUCKET.replace(\"qwiklabs-gcp-\", \"inna-bckt-\")\n",
    "REGION = 'eu-west3'\n",
    "\n",
    "print(PROJECT)\n",
    "print(BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if ! gsutil ls | grep -q gs://${BUCKET}/; then\n",
    "  gsutil mb -l ${REGION} gs://${BUCKET}\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "## enable eager execution (mostly to see mistakes right away):\n",
    "## TURN OFF FOR BETTER PERFORMANCE. \n",
    "## also doesn't work for estimator API.\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Code Snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval.csv  train.csv\n",
      "6.0009827716399995,False,14,Single(1),40.0,4740473290291881219\n",
      "7.3744626639,False,17,Single(1),42.0,4740473290291881219\n",
      "cat: write error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "## [[todo]]\n",
    "## see also `lab-snippets.py`\n",
    "%pwd\n",
    "%ls *.csv\n",
    "%cat train.csv | head -n 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create TensorFlow model using TensorFlow's Estimator API </h2>\n",
    "<p>\n",
    "First, write an input_fn to read the data.\n",
    "<p>\n",
    "\n",
    "## Lab Task 1\n",
    "Verify that the headers match your CSV output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine CSV, label, and key columns\n",
    "CSV_COLUMNS = 'weight_pounds,is_male,mother_age,plurality,gestation_weeks,key'.split(',')\n",
    "LABEL_COLUMN = 'weight_pounds'\n",
    "KEY_COLUMN = 'key'\n",
    "\n",
    "# Set default values for each CSV column\n",
    "DEFAULTS = [[0.0], ['null'], [0.0], ['null'], [0.0], ['nokey']]\n",
    "TRAIN_STEPS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 2\n",
    "\n",
    "Fill out the details of the input function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'DecodeCSV_1:0' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV_1:1' shape=() dtype=string>, <tf.Tensor 'DecodeCSV_1:2' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV_1:3' shape=() dtype=string>, <tf.Tensor 'DecodeCSV_1:4' shape=() dtype=float32>, <tf.Tensor 'DecodeCSV_1:5' shape=() dtype=string>]\n",
      "\n",
      "{'gestation_weeks': <tf.Tensor 'DecodeCSV_1:4' shape=() dtype=float32>, 'key': <tf.Tensor 'DecodeCSV_1:5' shape=() dtype=string>, 'plurality': <tf.Tensor 'DecodeCSV_1:3' shape=() dtype=string>, 'is_male': <tf.Tensor 'DecodeCSV_1:1' shape=() dtype=string>, 'mother_age': <tf.Tensor 'DecodeCSV_1:2' shape=() dtype=float32>}\n",
      "Tensor(\"DecodeCSV_1:0\", shape=(), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## stuff to try out some of the code below:\n",
    "line_of_text = '5.43659938092,True,12,Single(1),39.0,1451354159195218418'\n",
    "parsed_line = tf.decode_csv(line_of_text, record_defaults = DEFAULTS, field_delim = ',')\n",
    "print(parsed_line)\n",
    "print()\n",
    "\n",
    "features = dict(zip(CSV_COLUMNS, parsed_line))\n",
    "label = features.pop(LABEL_COLUMN)\n",
    "print(features)\n",
    "print(label)\n",
    "print()\n",
    "\n",
    "def change_indent:\n",
    "  \"\"\"\n",
    "  ```javascript\n",
    "var cell = Jupyter.notebook.get_selected_cell();\n",
    "var config = cell.config;\n",
    "var patch = {\n",
    "      CodeCell:{\n",
    "        cm_config:{indentUnit:2}\n",
    "      }\n",
    "    }\n",
    "config.update(patch)\n",
    "  ```\n",
    "  ou can enter the previous snippet in your browserâ€™s \n",
    "  JavaScript console once. Then reload the notebook page \n",
    "  in your browser. Now, the preferred indent unit should \n",
    "  be equal to two spaces. The custom setting persists and \n",
    "  you do not need to reissue the patch on new notebooks.\n",
    "  \"\"\"\n",
    "  return 1;\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input function reading a file using the Dataset API\n",
    "# Then provide the results to the Estimator API\n",
    "def read_dataset(filename_pattern, mode, batch_size = 512):\n",
    "  def _input_fn():\n",
    "    tf.logging.info('Defining input function.')\n",
    "    def decode_csv(line_of_text):\n",
    "      #tf.logging.info('Parsing line {}'.format(line_of_text))\n",
    "      # TODO #1: Use tf.decode_csv to parse the provided line\n",
    "      parsed_line = tf.decode_csv(line_of_text, record_defaults = DEFAULTS, field_delim = ',')\n",
    "      # TODO #2: Make a Python dict.  The keys are the column names, the values are from the parsed data\n",
    "      features = dict(zip(CSV_COLUMNS, parsed_line))\n",
    "      # TODO #3: Return a tuple of features, label where features is a Python dict and label a float\n",
    "      label = features.pop(LABEL_COLUMN)\n",
    "      return features, label\n",
    "\n",
    "    # TODO #4: Use tf.gfile.Glob to create list of files that match pattern\n",
    "    file_list = tf.gfile.Glob(filename_pattern)\n",
    "    # Create dataset from file list\n",
    "    dataset = (tf.data.TextLineDataset(file_list)  # Read text file\n",
    "             .map(decode_csv))  # Transform each elem by applying decode_csv fn\n",
    "    # TODO #5: In training mode, shuffle the dataset and repeat indefinitely\n",
    "    #                (Look at the API for tf.data.dataset shuffle)\n",
    "    #          The mode input variable will be tf.estimator.ModeKeys.TRAIN if in training mode\n",
    "    #          Tell the dataset to provide data in batches of batch_size \n",
    "    if (mode == tf.estimator.ModeKeys.TRAIN):\n",
    "      num_epochs = None  ## train indefinitely\n",
    "      dataset = dataset.shuffle(buffer_size = 10 * batch_size)\n",
    "    else:\n",
    "      num_epochs = 1\n",
    "    \n",
    "    dataset = dataset.repeat(num_epochs).batch(batch_size)\n",
    "    # This will now return batches of features, label\n",
    "    # * features = dictionary of {<featurename> : <tensor>}\n",
    "    # * label = <tensor> of one or more labels\n",
    "    return dataset\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 3\n",
    "\n",
    "Use the TensorFlow feature column API to define appropriate feature columns for your raw features that come from the CSV.\n",
    "\n",
    "<b> Bonus: </b> Separate your columns into wide columns (categorical, discrete, etc.) and deep columns (numeric, embedding, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define feature columns: wide-deep-model:\n",
    "\n",
    "def get_wide_deep_features():\n",
    "  tf.logging.info('Getting feature columns.')\n",
    "  ## define column types:\n",
    "  is_male = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'is_male',\n",
    "    ['True', 'False', 'Unknown'])\n",
    "  mother_age = tf.feature_column.numeric_column('mother_age')\n",
    "  plurality = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'plurality',\n",
    "    ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', \n",
    "     'Quintuplets(5), Multiple(2+)'])\n",
    "  gestation_weeks = tf.feature_column.numeric_column('gestation_weeks')\n",
    "  \n",
    "  ## feature transformations:\n",
    "  \n",
    "  ## bucketize mother_age:\n",
    "  age_buckets = tf.feature_column.bucketized_column(\n",
    "    mother_age,   ## input: tf.feature_column variable\n",
    "    boundaries = np.arange(15, 45, 1).tolist())\n",
    "  gestation_buckets = tf.feature_column.bucketized_column(\n",
    "    gestation_weeks,\n",
    "    boundaries = np.arange(17, 47, 1).tolist())\n",
    "  \n",
    "  ## define list of \"wide columns\", i.e., categorical variables\n",
    "  ## (linear relationships):\n",
    "  wide = [is_male,\n",
    "         plurality,\n",
    "         age_buckets,\n",
    "         gestation_buckets]\n",
    "  \n",
    "  ## feature cross all the wide columns [[?]]\n",
    "  ## and embed into a lower dimension:\n",
    "  crossed = tf.feature_column.crossed_column(wide, hash_bucket_size = 20000)\n",
    "  embed = tf.feature_column.embedding_column(crossed, 3)\n",
    "  \n",
    "  ## define list of continuous columns (plus embeded columns);\n",
    "  ## they have a \"deep\", complex relationship with the output:\n",
    "  deep = [mother_age,\n",
    "         gestation_weeks,\n",
    "         embed]\n",
    "  \n",
    "  return wide, deep\n",
    "\n",
    "## define feature columns: DNN-model: \n",
    "def get_features_dnn():\n",
    "  tf.logging.info('Getting feature columns (DNN).')\n",
    "  ## define column types:\n",
    "  is_male = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'is_male', ['True', 'False', 'Unknown'])\n",
    "  mother_age = tf.feature_column.numeric_column('mother_age')\n",
    "  plurality = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    'plurality',\n",
    "    ['Single(1)', 'Twins(2)', 'Triplets(3)', 'Quadruplets(4)', \n",
    "     'Quintuplets(5), Multiple(2+)'])\n",
    "  gestation_weeks = tf.feature_column.numeric_column('gestation_weeks')\n",
    "  ## don't do any bucketing here, just return feature list:\n",
    "  features = [\\\n",
    "             is_male,\n",
    "             mother_age,\n",
    "             plurality,\n",
    "             gestation_weeks]\n",
    "  return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 4\n",
    "\n",
    "To predict with the TensorFlow model, we also need a serving input function (we'll use this in a later lab). We will want all the inputs from our user.\n",
    "\n",
    "Verify and change the column names and types here as appropriate. These should match your CSV_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create serving input function to be able to serve predictions later using provided inputs\n",
    "def serving_input_fn():\n",
    "  tf.logging.info('Serving input (function).')\n",
    "  feature_placeholders = {\n",
    "    'is_male': tf.placeholder(tf.string, [None]),\n",
    "    'mother_age': tf.placeholder(tf.float32, [None]),\n",
    "    'plurality': tf.placeholder(tf.string, [None]),\n",
    "    'gestation_weeks': tf.placeholder(tf.float32, [None])\n",
    "  }\n",
    "  features = {\n",
    "    key: tf.expand_dims(tensor, -1)\n",
    "    for key, tensor in feature_placeholders.items()\n",
    "  }\n",
    "  input_receiver = tf.estimator.export.ServingInputReceiver(\n",
    "    features, feature_placeholders)\n",
    "  return input_receiver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Task 5\n",
    "\n",
    "Complete the TODOs in this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator to train and evaluate\n",
    "def train_and_evaluate(output_dir):\n",
    "  tf.logging.info('Entering train and evaluate function.')\n",
    "  ## create a run configuration:\n",
    "  EVAL_INTERVAL = 300\n",
    "  run_config = tf.estimator.RunConfig(\n",
    "    save_checkpoints_secs = EVAL_INTERVAL,\n",
    "    keep_checkpoint_max = 3)\n",
    "\n",
    "  ## TODO #1: Create your model estimator:\n",
    "\n",
    "  ## Linear Classifier:\n",
    "  estimator = tf.estimator.LinearRegressor(\n",
    "    model_dir = output_dir,\n",
    "    feature_columns = get_features_dnn(),\n",
    "    config = run_config\n",
    "  )\n",
    "    \n",
    "  ## DNN Classifier:\n",
    "  estimator = tf.estimator.DNNRegressor(\n",
    "    model_dir = output_dir,\n",
    "    feature_columns = get_features_dnn(),\n",
    "    hidden_units = [10, 10],\n",
    "    config = run_config\n",
    "  )\n",
    "\n",
    "  ## Wide-and-Deep-Model:\n",
    "  wide, deep = get_wide_deep_features()\n",
    "  estimator = tf.estimator.DNNLinearCombinedRegressor(\n",
    "    model_dir = output_dir,\n",
    "    linear_feature_columns = wide,\n",
    "    dnn_feature_columns = deep,\n",
    "    dnn_hidden_units = [64, 32],\n",
    "    config = run_config\n",
    "  )\n",
    "    \n",
    "  ## Training specification:\n",
    "  train_spec = tf.estimator.TrainSpec(\n",
    "                       # TODO #2: Call read_dataset passing in the training CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset(    ## pass the function, not call it\n",
    "                           filename_pattern = 'train.csv',\n",
    "                           mode = tf.estimator.ModeKeys.TRAIN),  \n",
    "                       max_steps = TRAIN_STEPS)\n",
    "  exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\n",
    "  eval_spec = tf.estimator.EvalSpec(\n",
    "                       # TODO #3: Call read_dataset passing in the evaluation CSV file and the appropriate mode\n",
    "                       input_fn = read_dataset(\n",
    "                           filename_pattern = 'eval.csv',\n",
    "                           mode = tf.estimator.ModeKeys.EVAL),\n",
    "                       steps = None,\n",
    "                       start_delay_secs = 60, # start evaluating after N seconds\n",
    "                       throttle_secs = EVAL_INTERVAL,  # evaluate every N seconds\n",
    "                       exporters = exporter)\n",
    "  tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Entering train and evaluate function.\n",
      "INFO:tensorflow:Getting feature columns (DNN).\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 3, '_task_id': 0, '_log_step_count_steps': 100, '_save_checkpoints_secs': 300, '_task_type': 'worker', '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3050351a58>, '_master': '', '_is_chief': True, '_model_dir': 'babyweight_trained', '_tf_random_seed': None, '_train_distribute': None, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Getting feature columns (DNN).\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 3, '_task_id': 0, '_log_step_count_steps': 100, '_save_checkpoints_secs': 300, '_task_type': 'worker', '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3050351a20>, '_master': '', '_is_chief': True, '_model_dir': 'babyweight_trained', '_tf_random_seed': None, '_train_distribute': None, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Getting feature columns.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 3, '_task_id': 0, '_log_step_count_steps': 100, '_save_checkpoints_secs': 300, '_task_type': 'worker', '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_session_config': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f3050351978>, '_master': '', '_is_chief': True, '_model_dir': 'babyweight_trained', '_tf_random_seed': None, '_train_distribute': None, '_save_summary_steps': 100, '_service': None, '_global_id_in_cluster': 0, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_save_checkpoints_steps': None}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Defining input function.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Feature (key: gestation_weeks) cannot have rank 0. Give: Tensor(\"IteratorGetNext:0\", shape=(), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-874976481781>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Run the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'babyweight_trained'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# start fresh each time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'babyweight_trained'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-cb97ab04dcf9>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(output_dir)\u001b[0m\n\u001b[1;32m     52\u001b[0m                        \u001b[0mthrottle_secs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEVAL_INTERVAL\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# evaluate every N seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                        exporters = exporter)\n\u001b[0;32m---> 54\u001b[0;31m   \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    437\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m   \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    517\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m           hooks=train_hooks)\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 856\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    566\u001b[0m           \u001b[0mdnn_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m           config=config)\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     super(DNNLinearCombinedRegressor, self).__init__(\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_dnn_linear_combined_model_fn\u001b[0;34m(features, labels, mode, head, linear_feature_columns, linear_optimizer, dnn_feature_columns, dnn_optimizer, dnn_hidden_units, dnn_activation_fn, dnn_dropout, input_layer_partitioner, config)\u001b[0m\n\u001b[1;32m    166\u001b[0m           \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdnn_dropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m           input_layer_partitioner=input_layer_partitioner)\n\u001b[0;32m--> 168\u001b[0;31m       \u001b[0mdnn_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mlinear_parent_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m     89\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[1;32m     90\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[0;32m---> 91\u001b[0;31m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m       with variable_scope.variable_scope(\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[1;32m    275\u001b[0m   \"\"\"\n\u001b[1;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[0;32m--> 277\u001b[0;31m                                trainable, cols_to_vars)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[0;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mweight_collections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_collections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             trainable=trainable)\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_dense_tensor\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2295\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2296\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2297\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_transform_feature\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2264\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_transform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2265\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2087\u001b[0;31m       \u001b[0mfeature_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_raw_feature_as_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2088\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feature_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2089\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/python/feature_column/feature_column.py\u001b[0m in \u001b[0;36m_get_raw_feature_as_tensor\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2139\u001b[0m         raise ValueError(\n\u001b[1;32m   2140\u001b[0m             'Feature (key: {}) cannot have rank 0. Give: {}'.format(\n\u001b[0;32m-> 2141\u001b[0;31m                 key, feature_tensor))\n\u001b[0m\u001b[1;32m   2142\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_tensor\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Feature (key: gestation_weeks) cannot have rank 0. Give: Tensor(\"IteratorGetNext:0\", shape=(), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Run the model\n",
    "shutil.rmtree('babyweight_trained', ignore_errors = True) # start fresh each time\n",
    "train_and_evaluate('babyweight_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran it, the final lines of the output (above) were:\n",
    "<pre>\n",
    "INFO:tensorflow:Saving dict for global step 1000: average_loss = 1.2693067, global_step = 1000, loss = 635.9226\n",
    "INFO:tensorflow:Restoring parameters from babyweight_trained/model.ckpt-1000\n",
    "INFO:tensorflow:Assets added to graph.\n",
    "INFO:tensorflow:No assets to write.\n",
    "INFO:tensorflow:SavedModel written to: babyweight_trained/export/exporter/temp-1517899936/saved_model.pb\n",
    "</pre>\n",
    "The exporter directory contains the final model and the final RMSE (the average_loss) is 1.2693067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Monitor and experiment with training </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('./babyweight_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017-2018 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
