In this lab, we'll download a copy of the inception model that has been trained on millions of images and then train it to work on our dataset. This should be what you see within Qwiklabs after you've started your lab. In this lab, what you need to do first is login to your GCP console with your Qwiklabs generated account, launch datalab, and clone the training data analyst Repo. Recall that transfer learning basically means re-purposing a network trained for another task for our task. To do that, we need to keep in mind that parts of the network are task-dependent. Specifically, as you go from the input to the output, the closer you are to the outputs the more task-dependent the model becomes. In this case, we're going to make use of inception, which is a model that Google published in 2014, that has been trained on millions and millions of input-output pairs, and take the feature extraction part and retain that and cut off the task-dependent classification part. The task-dependent classification part in this case are really only the final fully-connected layers of the network. You can see that depicted within Qwiklabs. In order to run the lab, we're going make use of both the Cloud machine learning API as well as the Dataflow API. We'll be using Dataflow in this case to run a pre-processing pipeline and materialize our inputs as TF records, and that the model can read from much more quickly and it can normal CSV files. Once you're within the console, you need to launch the Cloud datashell, and install the Cloud ML SDK, and export some variables to your path. After that, you need to clone the Cloud ML samples Repo, which contains the code that will be running, and CD into the Cloud ML samples flowers directory. I've already cloned the Repo, so I'm simply going to CD into that directory. You have about 3,600 flower images across five categories that are listed in the dictionary file dict.txt and it looks like this. This file is used to translate labels into an internal ID, internal number set that are simply discrete numbers. So, daisy equals zero and dandelion equals one etc. The two files will be pre-processing or train_set.csv and eval_set.csv we'll be doing them in independent Dataflow pipelines. Because each of these pipelines takes awhile to run, it's best to actually open up a new Cloud shell, and add the variables we've created and export them, and then run a separate pipeline in the newly created shell. So, that both your training pipeline and your ETL pipeline can run at the same time. I'll demo what that looks like. Let's start with the evaluation set. First one I'm going to do is I'm going to export some variables inside the environment, and now I'm going to make a bucket. In this case I've already made my bucket. Now I call the Python trainer pre-process py file. You'll notice here that we're parsing in some parameters that are eval specific. The input path corresponds to the Google Cloud storage address where the eval_set.csv file lives, and the output path is our GCS bucket/preprocress/eval. If you run this, it will create a Dataflow pipeline that will take about 30 minutes to run. Once it run, you can look inside the cloud Dataflow menu, and you should see a UI that looks like this. Notice how we have both a read input file and parse the input which is our CSV. We also have to read the dictionary file, because the pipeline needs to know the mapping between our label names and the number that the model will use internally. Then the steps should be very similar to things we've done in our redone preprocess function within the code before. We read and convert it to a JPEG, and then we embed and make a TF example, we serialize it to string and then we save it to disk as a TF record. After we pre-process the training set, we do the same process, but we parse in slightly different parameters. In a new shell, you will once again have to CD into the appropriate directory. You'll have to add some more variables to your environment. Then finally, you run the pre-processed file again, but with slightly different parameters. In this case, we're going to parse the input path set to the train_set.csv file, and our output path is going to be the GCS bucket that we've just made slash preprocess slash train. Notice too that we're passing in the cloud parameter to tell the dataflow pipeline to run the cloud. This pipeline because it's a little bit bigger, can take between 10 and 45 minutes to run. We can confirm that it's run in the Dataflow UI, but also simply by addressing the bucket that we've just created. So, if we run the LS command and search for files that begin with eval, we'll see all of our eval files. Notice that they are dot Tfrecorg dot gz because they're TF records. We can do the same thing, but with trained to see that our train files and I've also been materialized. Notice that there are many more. Once we've done that, the next step is to train an ML model. Training ML model, we're going to submit a job to Cloud ML engine. First, we need to create a job ID. The next thing we need to do is parse in the code that's in our module name, which in this case lives in trainers/test.py. At staging bucket, we need to tell which region to run, where we want the resulting output to go, and the path to our input and eval on training datasets. Submitting this job, it should show up within Cloud ML engine inside the jobs window. It could easily take 10 minutes to run. After 1,000 training steps, you should see a message like below. This means that the model has achieved 100% accuracy of the training set and 93.7 accuracy for the eval set. Once it has been trained, you can finally deploy the resulting model to Cloud ML engine. Deploying the model, we make use of the gcloud ml-engine versions create command, and parse in the origin parameter, which points to the path where our trained model lives. We provide a model name as well as a version name. In this case, we also set the model version name default to other model version name we've just created. Then finally, we test out our model in production by using some command line Python. In this case, all that we do is we encode a representation of a particular image using the base 64 encode library. Then we create a JSON file that maps a key to this particular image. We then parse our request.json file to the model that we've just deployed and what you'll get back is something that looks like this. Where it tells you the key and the prediction for each one. That's it. While implementing transfer learning in your code isn't too bad, sometimes it's too much of an expense. Thankfully, if you have some labeled training data, there is now a code list solution that allows you to train and deploy a vision model offer as part of Google's auto ML offering. Auto ML uses a combination of transfer learning using some of Google's best models and neural architecture search. All you have to do is upload your images into Google Cloud storage, and the product does the rest. We'll talk more about auto ML and neural architecture search in a later module.