Hi, I'm Evan, my Big Data curriculum developer for Google Cloud. We're excited to share with you today the history, the methods, and the latest in theory and hardware advances, that'll help us tackle the difficult domain of extracting features from and ultimately classifying image data. This is the third course in the Advanced Machine Learning with TensorFlow on GCP specialization. In this course, we'll look at the different strategies for building image classifier using methods that you've seen before as well as a new model type called the Convolutional Neural Network. We'll improve the model's accuracy with augmentation, feature extraction, and fine tuning hyper parameters, all the while trying to avoid over fitting or memorizing our training dataset. We'll also look at some practical issues that arise like not having enough image data to even train on and how to incorporate the latest research findings into our models to overcome these challenges. You get hands-on practice building and optimizing your own image classification models and a variety of public datasets in the Qwiklabs that we're going work on together. In this course, you'll learn about the rapid growth and the high resolution image data available in the types of business applications that image classification models can be applied to. Then we'll cover how unstructured data like images is very different than that we've seen before. Now, you can actually pre-process and feed that into your models. After learning how to harness image data as input, you'll then classify images using traditional machine learning techniques. First, you'll use a linear model, then a neural network, both using the popular MNIST handwritten digits dataset. Then after you discover the limitations of these traditional methods, you'll follow the rise of convolutional neural networks or CNNs. The major leap forward being that CNN allow a model to share weights, thus reducing the total number of weights and allowing the machine learning model to be slightly more tolerant of variations in images. When you practice it, it's pretty cool you'll see. Then we'll move on to a variety of tips and tricks that have been discovered over time that work really well on image classification problems. Here, you'll learn how to deal with things like data scarcity and improving the model performance through augmentation, batch normalization, and even leveraging some fun pre-built models. Now, one common problem you'll face out there in the wild, is that modern image classification models require hundreds of thousands of images in order to work really well. Now, one way to overcome this challenge is to leverage transfer learning. You'll learn about that in a different module. Then you'll learn how to implement state of the art image models and discover that they're really slow in standard hardware. You'll then learn how to implement these models of your image data using TPUs or Tensor Processing Units that's specialized hardware and you can monitor your performance gain. Lastly, you can use pre-built models like Google Cloud Vision API or AutoML platforms. Often these tools will be the first thing that you'll go to in your toolbox, when you're faced with an image classification problem. After all, in practice you don't want to reinvent the wheel, if there's already a high-quality pre-trained model out there that you can use first.