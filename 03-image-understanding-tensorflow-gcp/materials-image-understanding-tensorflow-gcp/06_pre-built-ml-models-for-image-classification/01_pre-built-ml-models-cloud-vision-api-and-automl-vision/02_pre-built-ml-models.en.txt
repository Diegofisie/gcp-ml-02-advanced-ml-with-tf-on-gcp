It takes so much work to keep up with advances in machine learning and AI, because both are rapidly evolving fields of study and practice. By the time you watch this recording, chances are there is a new ML model available for training out there in the world. So, it's worthwhile to understand the entire spectrum of a ML tools available on Google Cloud platform at the time of this recording, and better understand who should use which tools. Here's, the spectrum of a ML tools on GCP that you as a data scientist, or as a data practitioner should know. On the left-side, are the TensorFlow models that you have been building so far in this course. You've already got experience building custom CNN's in your last lab. On the far right-side of the diagram, is machine learning with AutoML. Remember that with AutoML, there's zero code for you to write. Let's walk through each of these options in more detail. You've already got plenty of experience building TensorFlow models, like the one in the end-to-end lab you did at the start of the specialization. The code from the lab should be a go-to library for customer ML models. But it's not the only tool you should keep in mind for yourself, or for your team. BigQuery is a fast serverless data warehousing platform on GCP. Did you know that it has a machine learning feature aimed at data analysts? BigQuery ML models can be built using regular SQL, and are created and stored right where your data already lives, in BigQuery. It's a great starting place for building quick, batch prediction linear, and logistic regression models to check if your data is a good fit for ML. BigQuery machine learning models are built on structured data sets. So, don't count on them to help with image classification. But if you, or data analysts on your team work with structured data, you should give BigQuery ML a closer look. Next is a suite of pre-trained ML APIs. Here, pre-trained means you don't even need to have a label training dataset to use them. These APIs like the Vision API, or the natural language processing, translation, already trained for common ML use cases like image classification. They save you the time and effort of building, curating and training a new dataset, so you can just jump ahead right to predictions. For pre-trained models, Google has already figured out a lot of the hard problems. Vision API is based on Google's image datasets. Speech API is trained on YouTube captions. Machine Translation API is built on parallel texts for language translations. Recall that how well your model is strained, depends on how much data you have. As you would expect, Google has a lot of images, text, and ML researchers to train its pre-built bottles. So, you can use those instead of reinventing the wheel. For example, if you're looking to have captions included in a recent webinar hosted by accompany, consider using the translate a speech APIs instead of trying to build a language recognition ML model yourself. Another example, if you have text documents like expense receipts that you need classified by expense type, consider using the Cloud Vision APIs for OCR, so we can mine the text from the receipts and drop the data into something like BigQuery. In your next lab, you will be invoking these APIs for the Cloud Shell console. It should be no surprise that these APIs make ML look easy. The AutoML platform you saw earlier is all about cordless transfer learning was AutoML vision, you upload or link your images training dataset, and with a click of a button, AutoML trains a high-performance custom image classification model, that's ready for evaluation and prediction. The platform also provides direct integration with Google's human labeling program. So, in cases where you have images with no labels, Google will provide you with access to an in-house team of human labelers that will classify your images based on your instructions. These are the same teams as Google uses for its own ML APIs and other ML products. Here are just a few customer examples of companies who have used the ML tools on Google Cloud Platform on their datasets. As you review them from left to right, note that the examples tell about the journey from low-level programming to more abstraction and UI based ML training. AUCNET built their own custom model to classify images of car parts and estimate their price. Ocado used passed results from the ML APIs to route customer emails to the appropriate customer service representatives. GIPHY uses the out-of-the-box vision APIs to find the text and memes, using optical character recognition. It then can reject inappropriate uploads based on sentiment or keywords. UNIQLO designed a shopping chatbot using dialogue flow UI. Dialogflow, is a Google owned company which specializes in building ML based interfaces like intelligent chatbots. I'll provide a link to where you can watch more customer stories as well.