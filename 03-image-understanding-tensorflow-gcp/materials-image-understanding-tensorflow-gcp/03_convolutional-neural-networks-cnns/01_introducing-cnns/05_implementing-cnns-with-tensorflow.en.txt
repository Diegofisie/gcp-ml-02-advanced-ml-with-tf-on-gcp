Before concluding this part of the module, take some time to compare what it means to use a convolutional instead of a dense layer for the first hidden layer of a deep neural net trained on the MNIST digit classification task. Since the MNIST digits have 784 pixels with a single grayscale channel, a dense hidden layer would require 784 weights for every neuron of the layer was the deep neural network, the one we trained early in this module. This means almost a quarter million weights, just for the first layer. In contrast, using five by five Kernels, in the convolutional layer was four channels means carying only one 100 weights for the corresponding layer. Here's a visual diagram showing how the front part of a convolutional neural network for the MNIST image data works. As you can see, they're free convolutional layers. If you look closely, you'll realize that the first layer uses the same pattern which gives us output, the same shape before it's squeezed down in subsequent pulling in convolutional layers until it's finally flattened for a deep neural network to classify. Let's see what it looks like in code. When using the TensorFlow layers API, it's easy to set up this type of a CNN architecture. Notice that in the corresponding code implementation above, the original gray-scale, 28 by 28 input image is processed by three convolutional layers. The outputs of the layers are shown in the comments to the right of the calls to the tf.layers.conv2d function. The horizontal and vertical dimensions are cut in half, in the second and the third layer because they're using a stride of two. Also, the convolutional layers are using an increasing number of filters so that the original grayscale channel is converted to four, then eight and finally 12 channels. The remaining part of the code simply reshapes the seven by seven by 12 output of the last convolutional layer as an array, and uses the array as an input to the remaining two dense layers that classify the digits. That's it. This part of the module begin by describing the challenges with processing images using only the dense layers in a deep neural network. You saw that using a dense layer as the first hidden layer of a deep neural network meant that every pixel of the input image had to be connected to every neuron on the first layer. You also learned how kernels enable convolution layers to detect patterns, and how pixels are placed next to each other so that the convolution layer can be trained to find edges, corners, textures and other visual patterns. Lastly, you saw that convolutional layers are just collections of these filters which are sometimes used together with pooling layers. Remember that the goal of the convolutional and pooling layers is to recognize patterns and reduce the dimensionality of the image before ultimately passing it off as a flattened feature vector into a fully connected to deep neural network like the one you see here. What is so remarkable about convolutional layers is that they dramatically improve the accuracy of deep neural networks across many pattern recognition tasks while using orders of magnitude fewer weights. This means shorter training times and better performance. All right. Last quiz before your lab. Choose the advantages of processing a small patch of the image at a time using a convolution kernel instead of using a dense layer for the entire image. Is it fewer weights? Faster processing? Weights are shared across the input? Or all of the above? The correct answer is all of the above, which ties together everything you learned so far in this course. Next up, is your quick lab where you will build a CNN for image classification.