Finally, let's look at an exciting development, neural architecture search. So far, we've looked at a variety of neural network architectures. All these architectures, whether it was AlexNet, or GoogleNet, or ResNet, they were painstakingly designed by machine learning researchers. After they did the design, these models where basically put into hyperparameter tuning, and the parameters of these models, they were hyperparameter tuned to optimize the performance of the model on some chosen dataset, typically ImageNet. Something that a lot of researchers have considered is whether you can automate the building of models. Maybe you can simply try adding layers one at a time to see if they help. Sure. But the combinatorial space that you will have to search is extremely large. How large? A 10-layer network can have about 10 billion candidate networks that you will have to explore. A brute force approach will simply not work. Researchers also tried using approaches like genetic algorithms to combine high-performing models to create even better models. But they were not all that successful. They were not able to approach the skill of human-designed networks. In 2017, Google researchers proposed using reinforcement learning to address this problem. The idea is to have two neural networks: a controller, shown here in pink, and a child, shown here in blue. The controller network proposes a child model architecture, which is then trained and evaluated for quality on a particular task, perhaps to do image classification on the CIFAR-10 dataset. The evaluation measurement is then used to inform the controller how to improve its proposals for the next round. The researchers repeated this process thousands of times generating new architectures, testing them, and giving that feedback to the controller to learn from. Eventually, the controller learns to assign high probability to areas of the architecture space that achieve better accuracy on a holdout validation set and low probability to areas of architectural space that score poorly. The researchers call this Auto ML. It forms the basis of the Google Cloud product that you will see in the next module. Fortunately, you don't have to retrain and rediscover a neural network for image classification. Remember the official repository of TPU models? It includes a model called AmoebaNet-D. This model as a result of neural architecture search on the CIFAR-10 dataset but with a twist. The researchers explicitly look for neural networks that will be very efficient on a TPU. So, if you're looking for a high-performing fast training image classification model, AmoebaNet is what it should use. You can use it the same way that you use a ResNet-50 model in the previous lesson.