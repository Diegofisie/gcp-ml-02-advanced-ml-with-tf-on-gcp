Hi. In this lab, the idea is to train a state of the art image model, in this case on ResNet 50, on the Tensor Processing Unit or TPU. To do this, we don't actually have to write any code because, the code for ResNet 50 that runs on the TPU, it's already open source, it's in a GitHub repository, we just have to get the code. The other thing that we need to do, of course, is to basically take our data and put it into a form that that code reads. The code that runs on the TPU wants your image data in Tensor Processing records. So, first thing that we will do will be to take our JPEG data and convert them into TensorFlow records. Fortunately, the same repository also includes an Apache Beam Pipeline, that we can run to do this conversion. So, our lab is going to consist of two steps. One to run the pipeline, take our image data, converted into TensorFlow records. Then, and once we have the TensorFlow records, we then go ahead and run the image model code on the TPU. In order to do that, we can use Cloud ML Engine pointed at a Python package that essentially consists of the code that we downloaded from the Repo. So, let's get started. So, this is the code lab instructions and the basic steps are number one, to convert the JPEG files in TensorFlow records. Number two, to train the image classifier. But at that point, you have a trained model, that's not enough. We want to take that trained model, we want to deploy the trained model as a web service and we can do that also in ML Engine, and then we can invoke the web service by sending it a JPEG image. When you want to send a JPEG image to the web service, we have to base 64 encode the JPEG image contents, and we'll see how to do that as well. So, the the code lab starts with a brief primer on resonated TPUs. We looked at this already in the course, which is essentially the key idea behind the ResNet 50 or residual connection, is that whatever input you get basically passes through a shortcut connection directly to the output. So, that's your shallow connection and then the residual, that difference between the output and the input, that's the left hand side and that's not so shallow, that's a deeper side of the network. So, the idea is that if you build a neural network consisting of these blocks, they turn out to be much easier to train and that's the basic idea behind a ResNet model. But the idea also is that you still have the deeper layers available, and if you have a deep network and you have a large dataset, it takes a while to train. So, it's good to basically do the training on the TPU. In our case because it's just a lab, we're not going to take a humongous dataset, we're going to take a relatively small dataset, the Flowers dataset and we're going to see how to essentially train a state of the art model on the Flowers dataset, the ResNet model. But to do this on a TPU. First step then is to essentially set up our environment. The reason we're setting up the environment, is so that we can convert our Flowers data which is that JPEG data into TensorFlow records. In order to do that, we're asked to basically go ahead and start Cloud Shell. So, let me go ahead and do that. I will start Cloud Shell from the GCP Console. Having started CloudShell, we're basically asked to go ahead and make sure that the project is set appropriately and that we have the ML Engine API enabled, which we can do by going to the library page and making sure that the ML Engine. So, we can do ML Engine, Cloud Machine Learning Engine and there it is, and let's make sure that it is enable. So, this is already enabled for me, that's why it shows me the "Manage" button. If it shows you the "Enable" button, you would basically go ahead and enable it. Then, we also need to enable the Dataflow API. So, we can do the same thing, we can go into Dataflow and there is the Cloud Dataflow API and that too is enabled. That's why I see the "Manage" button. So, that's also enabled and now we can basically go into the Cloud Shell repository and git clone these Repo. But let's just make sure, that the project it is correctly set as cloud training demos, so I'm fine there as far as the project is concerned. The UI will be different regardless of now, the UI keep changing. So, it's going to be looks something like this with the same set of steps. If the UI looks slightly different for you, don't be worried, it's all okay. So, let's go ahead and get clone the repository. So, we can do this and that also, I may have done already. So, git clone that repository. At this point, the code repository is cloned into my Cloud Shell account. The next thing that we're asked to do, is to basically go ahead and explore the data. So, this data is a set of professional photographs of flowers, which basically has your training dataset and evaluation dataset. So, let's go look at what the training dataset looks like. So, the training dataset, which got downloaded here, this is basically what it looks like. It basically has a URL of the image and the category, the classification or the label of the image. The first image is that of a daisy. The second image is that of a dandelion and the third, this image is that of roses. So, we could basically say let's go ahead and look at this image. Now, because this is a public data set, I can actually look at this image by changing the gs URL to API storage, let me just go ahead and try that or actually the code lab probably tells us to do this. Okay. So, let's go ahead and view the image. So, you see the storage.cloud.google.com with, this is the bucket name and the rest of the image. So, we can go ahead and click on this image and we basically get the photograph of what this is and this is, if you go ahead and look at this image, the image that just came up, that image was a very first one and so, it is a daisy. I wouldn't know the names of the flowers, but I'll trust that the labels are correct.. So, let's go back here and look at this one. So, what this does is basically go to GS, the Google Cloud Storage and look at the first five lines and create a file called temp input dot CSV. So, let's go ahead and do that. So I can turn off this, let's go here. So here, if I were to go down here and do this, at this point, the first five lines will go into /tmp/input.csv and you can see that those are what-if lines look like. That's essentially what we looked at earlier. The format of the file, it looks like it's a comma separated file. How would you find all of the types of flowers in the dataset? Well, what we could do, is to basically go ahead and look at this tmp.csv. I can do cat/tmp/input.csv and replace all of the commas by spaces and I could print dollar one and that would print the URL, and if I print dollar two, that would print the labels. So, if I were to take those labels and I were to sort them. Now, those are now sorted and it can do unique and that'll give me just a unique numbers and that's my dictionary. My set of labels. Of course instead of doing the tmp/input.csv, I could basically do gsutil cat and that's what this thing is doing. So, it's doing a gsutil cat and doing the comma to spaces, printing out the second field, sorting it, find the unique values and finding all of the labels. So, let's go ahead and do that and once we do that, we should be able to do cat/tmp/labels.txt, and we find that there are 2,3,4,5 labels in the dataset, and we've already viewed the image. So, now we are ready to go ahead and convert all the JPEG images to TensorFlow records and as I mentioned in the intro, this is already part of the open source repository and we basically have some code that is written all ready to go and grab the data in that repository. Let's go ahead and let me copy this again into my buffer. There we go, that's now copied. So in here, there is a script to copy all the ResNet files and what this does, is that it basically goes ahead and starts with a git checkout of a particular version. So, in this case I'll be checking out a version say 1.8 of the TensorFlow code from that repository and having done that basically creating it and making a Python package out of it. So, let's go ahead and do this. So, bash./ copy_resnet_files for TensorFlow version 1.8. When you are doing it we might have updated the version but the steps are going to remain the same. So at this point then, we have my model which basically has the familiar Cloud ML Engine packaging instructions with a trainer setup.py et cetera, but it also includes the resnet_ main.py which is basically the code that we're going to run our training on, and a preprocess.py which is an Apache Beam pipeline. So, let's go ahead and specify environment variables for the bucket, the project name. So, in my case, my bucket is called Cloud Training Demos ML, and my project name is, I can just get the project name from my Cloud Shell which is what we're doing here. So, let's go ahead and get the project name from the Cloud Shell, and we can echo the bucket and the project to make sure they look reasonable and yes, that is a bucket. Actually no, the bucket is wrong, it should be Cloud Training Demos ML. Good thing I checked. Now, if I do that, yes the bucket name is correct and the project name is correct. So now let's go ahead and install Apache Beam. Apache Beam for those of you who've been here in our previous courses, this is a way to do Batch processing and Stream processing using the same code. It essentially distributes all of the processing onto multiple machines, does these things in parallel and we'll get our output. So, we are now installing the package for Apache Beam and then we can then run the conversion program. So, that's conversion program is a pre-process program that came from that open source repository consisting of TPU models, and we're saying that our training CSV file is in that particular file and our validation CSV is that file, and our labels consist of the tmp/labels.txt that I just created by doing the sort and the unique et cetera, specifying my project ID. So, we know where to send the bill for doing this distributed conversion of JPEG files to TensorFlow records where to send that bill. Then specifying an output directory. So, we can go ahead and do this, clear that, so here. Okay. I still made a mistake. It's a good thing I made a mistake because what I'll do just to save time, is that I will not remove the previous bucket. So, what I'll do is simply is now to remove the bucket. So, I'll keep that original data as it is and instead just run the pre-processing. But I'll do the pre-processing into a different directory just to see it running but it will be data two or data delete. Let me just call it data delete. So it runs and then I'll delete that later. The reason I'm doing that is that if I go into my cloud storage bucket, storage in my browser and go into Cloud Training Demos ML and in there, there is a thing called TPU. Whole bunch of other stuff, I have to run these things but there should be a TPU version somewhere. There it is TPU, and ResNet and I already had a data, I'm just creating now a data delete that the new things are going to go in. So, inside my data, when the whole thing has been run, I will have my training files and I'll have my validation files. Meanwhile, if I go into dataflow. So, scroll down into dataflow which is where I submitted the job, you should see a job running for pre-processing of images and this particular job currently right's basically reading from the CSV files during the conversion from JPEG to TensorFlow records and writing out the TF records. Over time this will auto-scale to multiple robe workers, and about 15-20 minutes later I will have it all done and the pipeline options in this case, let's see the project name is that and that's the job name et cetera. So we can wait for this to run but fortunately we already have it run. So, at this point we have started the dataflow job. It's going to take about 15 minutes and at the end of 15 minutes, you will see all of those files, a training files, a validation files et cetera in your bucket, and that's where you would basically continue. So, you're going to be waiting for the dataflow job to finish. I on the other hand have already run this before. So what I'll do is I'll continue with the results of my dataflow job from the previous run. But if you watch over time, this will basically turn to running and then the number of workers here will increase beyond one, it'll start getting parallelized, getting autoscaled, it'll start getting processed and this entire dataset will all get converted into TF records. So, the CSV files would get read, they would get converted and they will get written out. So, wait for to finish, me on the other hand, I'm going to say my data is already there so let me go ahead and move on. So, me on the other hand, I'm basically going to essentially go with the files that I already have and move on to the next step which is to train the model. To train the model, let's just go ahead and make sure that the data actually exists. So, we can go in here because that job is still running. I'll open up a new Cloud Shell tab. Remember that output is going into data too, so, it's not really going to affect anything here. Let me go ahead and say that this may not work because export bucket hasn't been set. No, bucket hasn't been set. So, export BUCKET=cloud-training-demos-ml and export. Project equals cloud training demos. So now, let's make sure that the data exists, and the data does exist, I have my training files and I have my validation files. So, let's go ahead and enable ML engine to be able to access these things. So, I need to be in the training demos directory. What was the directory there? Training analyst quest steep, actually what I can do I'll do Ctrl+Z, background it and so now I'm actually in the original thing, original window itself and I can enable the TPU. So, let's go ahead and and enable the TPU and having done that, I can then submit my training job. So, let's walk through what this does. It says that this is the top directory, the directory where I have the data. In my case, I would like to run this in central one because that's where I have TPU quarter and I want my output to go into the trained directory and I will remove the prior outputs that way because remember that the way TensorFlow works is that if it sees a checkpoint, it starts from that checkpoint. So, if you've already trained, you want to remove that old one and restart it. So, we do that and then we will basically go ahead and submit your training job for a particular region, the module that we want to start as trained resnet main, resnet_main. Again, the file that we downloaded from the official TPU repo and specifying the package path and specifying that the scale tier is BASIC_TPU and that the runtime version is 1.8. Remember that we downloaded TensorFlow version 1.8 version of the files. So, in this case, we're also training with TensorFlow 1.8. We pointed at the data directory, the directory that contains a TensorFlow records and we want the output to go into the output directory that we specify. We want to use ResNet 18. Why 18? Because my dataset isn't very big. If I use ResNet 152, I just don't have enough data, I need a million images, I have a few thousands. So, ResNet 18 is small enough that maybe okay. So, I'll use ResNet 18 on this data and I want to specify my batch size. We talked about this, right? For ideal training, your TensorFlow batch size for training should be a multiple of 128. So, that's what I'm doing here, I'm passing it a multiple of 128 to basically do my training, that's the smallest batch size that I can sort of get away with. My dataset again is in very large. In reality, you want this to be something like 1,024 or something larger. Number of steps per eval, 250 steps. So, evaluate every 250 steps, train for a 1,000 steps and the number of training images is 3,300, number of evaluation images are 370, this is what is actually in my dataset and the number of label classes is five. Then, I ask for the model to get exported into this output directory. So, let's go ahead and run this, but as before with the dataflow, I've already run this before, that way I can move on to the next step in my demo. So, I will change my output directory to be not that directory, but something slightly different. So, I will do this, the output directory I will say is trained delete. So, I know how to delete it later and then I can go ahead and run the rest of the stuff. All right, go ahead and do that. At this point, the training job will be submitted and on ML engine if we go, we should find that there is a job running. So, I can go into ML Engine, I can go into jobs and I should see a training job for image classification that has just started, it's now under preparation. So again, this thing is going to run, it's going to train on the TPU, it's going to take about 20 minutes at the end of it, we will basically have a trained model. So, where would that be? That would be in our output directory. So, if we could also go ahead and look at TensorBoard and we could look at the model training. So, let's go ahead and do that. Around here, model training and set preview on 8080. So, this is the web preview, preview on 8080 and we should see TensorBoard come up and once TensorBoard has loaded, we can go ahead and look at the scalar graphs, we can look at the accuracy plots et cetera. So, there they are. So, this tells you the speed at which things got loaded, but we can go look at the top one accuracy which is like the probability that it got the label correctly and you will see that it basically started out at about 62 percent and then overtime right it basically ended up at 75 percent. It looks like the accuracy has kept increasing. So in reality, we trained for more than 1,000 steps. We want to basically see this thing saturate and it hasn't, but again, this is a lab, we wanted it to finish relatively quickly, so we cut this training relatively short is a trained for just a 1,000 steps. In reality, you train until this thing saturates wherever it does. So, we got about 75 percent accuracy on ResNet. Again, out of the box model, we just ran it on our data and we were able to do this very quickly, right about 20 to 25 minutes for training and we're done, which is actually quite cool. We can also look at the loss curves. So, that's the loss curve and you basically see the result and you see that it isn't actually very overfit, they're pretty close to each other. So, at any point in time, right? They are relatively close. Let's see. Again, if you say, "Well, my sand if I press it isn't good enough, how do I get better?" Well, you need more data. That's your typical, for such a small dataset, this is pretty reasonable on a deep learning model. So, once we have our model, the last step is to deploy the model. So, once a model training is done, we should be able to go down here. So notice that this thing that training has started. So, it's going to take a while. So again, as before, I will do Ctrl+Z, put that into the background, it's going to this other directory, but I know that my actual output directory, the export already exists because I ran it before and I can make sure that in my export directory, I do have an exported model. So, let's wait, make sure there it is. There's an exported model in that directory and we should be able to go ahead and deploy the model. So, to deploy the model, we use gcloud ml-engine models, create a model called "flowers" with the version ResNet and then go ahead and create a version of the model, let's call it resnet and that version should exist. So again, let me just make sure that if I go into ML Engine, models, does "flowers" ResNet exist? There's not, flowers ResNet doesn't exist, so I should be able to create it. Since my model already exists, I'll skip that part. So, let's just do this, I'll go ahead and there. So, that's one model location and I don't need to create the model because a model already exists, I just need to create a ResNet version of the model. So, I can do that by specifying that and once you do this, then we should be able to invoke the model. So, we can invoke the model by doing this, change mod plus invoke model.py model. So, this is the first time the model is being invoked in a while, so it's going to take a little bit to warm up and then I should get the results. At the end of it, go ahead and you can remove everything because this all serverless, there's actually no VMs to delete or anything, but you can delete the directories from the storage or the model versions and you can delete the storage bucket as well. So, there it is, we just got back the response for the model and we said we sent in and obviously we sent in a sunflower and what we got back were predictions, five predictions. Those are the probabilities, the actual class number is three, that is 0, 1, 2, 3 and we could look at cat/tmp/labels.txt, and 0, 1, 2, 3, there are sunflowers. So, the model got sunflowers correct and so that's pretty much the process then. Take your data, take your image data, put it into that form, input that CSV, eval that CSV where you have the Cloud storage locations of all your images and the labels for each one of them and then run two scripts. One script to convert the images into TF records and a second script to run the model training and then if you want to deploy an ML Engine, run the deploy command to basically deploy it on ML engine and that's it, the model is now a microservice and it can be invoked, you can basically send in the image and you can get the response back and if you look at invoke_image.py, you will basically see that what it's doing, is that it's basically doing a base 64 encode of the entire content of the datafile, of the JPEG file and that's pretty much it.