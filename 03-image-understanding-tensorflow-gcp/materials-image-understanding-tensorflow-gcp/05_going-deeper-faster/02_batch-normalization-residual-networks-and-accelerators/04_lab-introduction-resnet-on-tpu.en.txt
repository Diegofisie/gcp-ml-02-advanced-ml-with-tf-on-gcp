The code that was submitted for Stanford DAWN benchmark is open source, and it's readily available on GitHub. In the optional lab that follows, you can try training the ResNet model on your own data. You will start with a dataset of JPEG images each of which has been labeled. You will then convert the JPEG images to TensorFlow records. This is particularly important for the TPU because otherwise, the TPU will waste its time waiting for inputs to be processed and read into the pipeline. When you're using TPUs, you want to read data the fastest possible way. So, it's worth converting the images into TF records first. Once you have the TF records, you will run a cloud ML Engine job, specifying the scale tier to be BASIC_TPU. The lab is optional. Why is it optional? Because you have to do it in your own Google Cloud account. You cannot do it on Qwiklabs labs because of technical difficulties today around getting TPU quarter. The total cost to do this lab on Google Cloud, if you decide to do it in your account, it's about three dollars, but the lab is optional. It doesn't involve any coding. It's just a question of running several scripts. So, I'll walk through it, so you could just wait for the debrief.