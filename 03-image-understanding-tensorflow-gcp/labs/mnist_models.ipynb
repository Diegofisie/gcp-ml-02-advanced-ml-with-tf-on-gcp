{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image Classification with TensorFlow on Cloud ML Engine\n",
    "\n",
    "This notebook demonstrates how to implement different image models on MNIST using Estimator. \n",
    "\n",
    "Note the MODEL_TYPE; change it to try out different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = 'cloud-training-demos' # REPLACE WITH YOUR PROJECT ID\n",
    "BUCKET = 'cloud-training-demos-ml' # REPLACE WITH YOUR BUCKET NAME\n",
    "REGION = 'us-central1' # REPLACE WITH YOUR BUCKET REGION e.g. us-central1\n",
    "MODEL_TYPE='cnn'  # 'linear', 'dnn', 'dnn_dropout', or 'cnn'\n",
    "\n",
    "# do not change these\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['MODEL_TYPE'] = MODEL_TYPE\n",
    "os.environ['TFVERSION'] = '1.8'  # Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-d1510d1177dc7fc8\n",
      "qwiklabs-gcp-d1510d1177dc7fc8\n",
      "gsutil mb -l europe-west1 gs://qwiklabs-gcp-d1510d1177dc7fc8\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "output = os.popen(\"gcloud config get-value project\").readlines()\n",
    "project_name = output[0][:-1]\n",
    "\n",
    "# change these to try this notebook out\n",
    "PROJECT = project_name\n",
    "BUCKET = project_name\n",
    "#BUCKET = BUCKET.replace(\"qwiklabs-gcp-\", \"inna-bckt-\")\n",
    "REGION = 'europe-west1'  ## note: Cloud ML Engine not availabe in europe-west3!\n",
    "\n",
    "# set environment variables:\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "\n",
    "print(PROJECT)\n",
    "print(BUCKET)\n",
    "print(\"gsutil mb -l {0} gs://{1}\".format(REGION, BUCKET))\n",
    "\n",
    "## set config for gcp config: [[?]]\n",
    "print(os.popen(\"gcloud config set project $PROJECT\").readlines())\n",
    "print(os.popen(\"gcloud config set compute/region $REGION\").readlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run as a Python module\n",
    "\n",
    "In the previous notebook (mnist_linear.ipynb) we ran our code directly from the notebook.\n",
    "\n",
    "Now since we want to run our code on Cloud ML Engine, we've packaged it as a python module.\n",
    "\n",
    "The `model.py` and `task.py` containing the model code is in <a href=\"mnistmodel/trainer\">mnistmodel/trainer</a>\n",
    "\n",
    "**Complete the TODOs in `model.py` before proceeding!**\n",
    "\n",
    "Once you've completed the TODOs, set MODEL_TYPE and run it locally for a few steps to test the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn\r\n"
     ]
    }
   ],
   "source": [
    "!echo $MODEL_TYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING:tensorflow:From /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnistmodel/trainer/model.py:176: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:TF_CONFIG environment variable: {'environment': 'cloud', 'job': {'job_name': 'trainer.task', 'args': ['--output_dir=/content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained', '--train_steps=100', '--learning_rate=0.01', '--model=cnn']}, 'task': {}, 'cluster': {}}\n",
      "INFO:tensorflow:Using config: {'_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ffaf118f400>, '_session_config': None, '_service': None, '_model_dir': '/content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/', '_keep_checkpoint_every_n_hours': 10000, '_tf_random_seed': None, '_train_distribute': None, '_task_id': 0, '_save_checkpoints_secs': 60, '_master': '', '_task_type': 'worker', '_log_step_count_steps': 100, '_is_chief': True, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_keep_checkpoint_max': 5, '_evaluation_master': ''}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 60 secs (eval_spec.throttle_secs) or training is finished.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 2.3083272\n",
      "INFO:tensorflow:Saving checkpoints for 100 into /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1017629.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-22-08:06:20\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-22-08:06:28\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9604, global_step = 100, loss = 0.12256279\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"/content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/export/exporter/temp-b'1550822788'/saved_model.pb\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['classes', 'serving_default']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Restoring parameters from /content/datalab/gcp-ml-02-advanced-ml-with-tf-on-gcp/03-image-understanding-tensorflow-gcp/labs/mnist_trained/model.ckpt-100\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: b\"saved_model/temp-b'1550822789'/saved_model.pb\"\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "rm -rf mnistmodel.tar.gz mnist_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/mnistmodel/trainer \\\n",
    "   -- \\\n",
    "   --output_dir=${PWD}/mnist_trained \\\n",
    "   --train_steps=100 \\\n",
    "   --learning_rate=0.01 \\\n",
    "   --model=$MODEL_TYPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, let's do it on Cloud ML Engine so we can train on GPU:** `--scale-tier=BASIC_GPU`\n",
    "\n",
    "Note the GPU speed up depends on the model type. You'll notice the more complex CNN model trains significantly faster on GPU, however the speed up on the simpler models is not as pronounced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn europe-west1 mnist_cnn_190222_080759\n",
      "jobId: mnist_cnn_190222_080759\n",
      "state: QUEUED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\n",
      "Job [mnist_cnn_190222_080759] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe mnist_cnn_190222_080759\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs mnist_cnn_190222_080759\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "OUTDIR=gs://${BUCKET}/mnist/trained_${MODEL_TYPE}\n",
    "JOBNAME=mnist_${MODEL_TYPE}_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=trainer.task \\\n",
    "   --package-path=${PWD}/mnistmodel/trainer \\\n",
    "   --job-dir=$OUTDIR \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC_GPU \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=10000 --learning_rate=0.01 --train_batch_size=512 \\\n",
    "   --model=$MODEL_TYPE --batch_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring training with TensorBoard\n",
    "\n",
    "Use this cell to launch tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p>TensorBoard was started successfully with pid 4000. Click <a href=\"/_proxy/45171/\" target=\"_blank\">here</a> to access it.</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start('gs://{}/mnist/trained_{}'.format(BUCKET, MODEL_TYPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped TensorBoard with pid 4000\n"
     ]
    }
   ],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some of the Logs for CNN model\n",
    "\n",
    "(Rather at the end, only selected lines)\n",
    "\n",
    "```\n",
    "global_step/sec: 139.711\n",
    "loss = 0.017031638, step = 9900 (0.716 sec)\n",
    "Saving checkpoints for 10000 into gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt.\n",
    "Starting evaluation at 2019-02-22-08:13:20\n",
    "Restoring parameters from gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-10000\n",
    "Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
    "Finished evaluation at 2019-02-22-08:13:22\n",
    "Saving dict for global step 10000: accuracy = 0.9836, global_step = 10000, loss = 0.08720327\n",
    "Signatures INCLUDED in export for Classify: None\n",
    "Signatures INCLUDED in export for Regress: None\n",
    "Signatures INCLUDED in export for Predict: ['serving_default', 'classes']\n",
    "Adding visible gpu devices: 0\n",
    "Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10764 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
    "Restoring parameters from gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-10000\n",
    "Assets added to graph.\n",
    "No assets to write.\n",
    "SavedModel written to: gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/temp-1550823202/saved_model.pb\n",
    "Loss for final step: 0.086979106.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are my results:\n",
    "\n",
    "```\n",
    "Model | Accuracy | Time taken | Model description | Run time parameters\n",
    "--- | :---: | ---\n",
    "linear | 91.53 | 3 min | linear | 100 steps, LR=0.01, Batch=512\n",
    "linear | 92.73 | 8 min | linear | 1000 steps, LR=0.01, Batch=512\n",
    "linear | 92.29 | 18 min | linear | 10000 steps, LR=0.01, Batch=512\n",
    "dnn | 98.14 | 15 min | 300-100-30 nodes fully connected | 10000 steps, LR=0.01, Batch=512\n",
    "dnn | 97.99 | 48 min | 300-100-30 nodes fully connected | 100000 steps, LR=0.01, Batch=512\n",
    "dnn_dropout | 97.84 | 29 min | 300-100-30-DL(0.1)- nodes | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 98.97 | 35 min | maxpool(10 5x5 cnn, 2)-maxpool(20 5x5 cnn, 2)-300-DL(0.25) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 98.93 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.17 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25), batch_norm (logits only) | 20000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.27 | 35 min | maxpool(10 11x11 cnn, 2)-maxpool(20 3x3 cnn, 2)-300-DL(0.25), batch_norm (logits, deep) | 10000 steps, LR=0.01, Batch=512\n",
    "cnn | 99.48 | 12 hr | as-above but nfil1=20, nfil2=27, dprob=0.1, lr=0.001, batchsize=233 | (hyperparameter optimization)\n",
    "```\n",
    "\n",
    "Create a table to keep track of your own results as you experiment with model type and hyperparameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From logs in Cloud ML GCP Page:\n",
    "\n",
    "```\n",
    "| Model            | Loss for final step |\n",
    "| ---------------- | -----------------  |\n",
    "| DNN              | 0.0024385566        |\n",
    "| DNN with dropout | 0.08717914          | Saving dict for global step 10000: accuracy = 0.9714, global_step = 10000, loss = 0.19375572\n",
    "| CNN              | 0.086979106         | Saving dict for global step 10000: accuracy = 0.9836, global_step = 10000, loss = 0.08720327\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying and predicting with model\n",
    "\n",
    "Deploy the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting and deploying mnist cnn from gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823202/ ... this will take a few minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: (gcloud.ml-engine.models.create) Resource in project [qwiklabs-gcp-d1510d1177dc7fc8] is the subject of a conflict: Field: model.name Error: A model with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A model with the same name already exists.\n",
      "    field: model.name\n",
      "ERROR: (gcloud.ml-engine.versions.create) ALREADY_EXISTS: Field: version.name Error: A version with the same name already exists.\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: A version with the same name already exists.\n",
      "    field: version.name\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "MODEL_NAME=\"mnist\"\n",
    "MODEL_VERSION=${MODEL_TYPE}\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/mnist/trained_${MODEL_TYPE}/export/exporter | tail -1)\n",
    "echo \"Deleting and deploying $MODEL_NAME $MODEL_VERSION from $MODEL_LOCATION ... this will take a few minutes\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version=$TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To predict with the model, let's take one of the example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-0bc50dc1890f>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /usr/local/envs/py3env/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/matplotlib/font_manager.py:1320: UserWarning: findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f41c6c41b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json, codecs\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "HEIGHT=28\n",
    "WIDTH=28\n",
    "\n",
    "mnist = input_data.read_data_sets('mnist/data', one_hot=True, reshape=False)\n",
    "IMGNO=5 #CHANGE THIS to get different images\n",
    "jsondata = {'image': mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH).tolist()}\n",
    "json.dump(jsondata, codecs.open('test.json', 'w', encoding='utf-8'))\n",
    "plt.imshow(mnist.test.images[IMGNO].reshape(HEIGHT, WIDTH));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction with DNN with dropout:\n",
    "```\n",
    "CLASSES  PROBABILITIES\n",
    "1        [6.296275000631441e-30, 1.0, 1.8646024367974916e-28, 6.413484539171141e-29, 6.740793685627217e-20, 8.823438499032172e-27, 3.183225285434738e-36, 2.819988924516263e-20, 2.6393468285896378e-15, 3.232898161415615e-13]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send it to the prediction service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSES  PROBABILITIES\n",
      "1        [1.5641251023849324e-30, 1.0, 6.316736522120792e-26, 0.0, 9.330423633981259e-22, 1.630922713149645e-25, 3.4916248038090473e-28, 1.8372297000545262e-27, 1.0361169061632659e-16, 4.647386317162386e-29]\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "gcloud ml-engine predict \\\n",
    "   --model=mnist \\\n",
    "   --version=${MODEL_TYPE} \\\n",
    "   --json-instances=./test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/checkpoint...\n",
      "/ [0 files][    0.0 B/  178.0 B]                                                \r",
      "/ [1 files][  178.0 B/  178.0 B]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/eval/events.out.tfevents.1550823090.cmle-training-13168643516927694946...\n",
      "/ [1 files][  178.0 B/109.5 KiB]                                                \r",
      "-\r",
      "- [2 files][109.5 KiB/109.5 KiB]                                                \r\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/events.out.tfevents.1550823062.cmle-training-13168643516927694946...\n",
      "- [2 files][109.5 KiB/540.5 KiB]                                                \r",
      "- [3 files][540.5 KiB/540.5 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823092/saved_model.pb...\n",
      "- [3 files][540.5 KiB/565.4 KiB]                                                \r",
      "\\\r",
      "\\ [4 files][565.4 KiB/565.4 KiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823092/variables/variables.data-00000-of-00001...\n",
      "\\ [4 files][565.4 KiB/  1.7 MiB]                                                \r",
      "\\ [5 files][  1.7 MiB/  1.7 MiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823092/variables/variables.index...\n",
      "\\ [5 files][  1.7 MiB/  1.7 MiB]                                                \r",
      "|\r",
      "| [6 files][  1.7 MiB/  1.7 MiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823202/saved_model.pb...\n",
      "| [6 files][  1.7 MiB/  1.7 MiB]                                                \r",
      "| [7 files][  1.7 MiB/  1.7 MiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823202/variables/variables.data-00000-of-00001...\n",
      "| [7 files][  1.7 MiB/  2.9 MiB]                                                \r",
      "/\r",
      "/ [8 files][  2.9 MiB/  2.9 MiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/export/exporter/1550823202/variables/variables.index...\n",
      "/ [8 files][  2.9 MiB/  2.9 MiB]                                                \r",
      "/ [9 files][  2.9 MiB/  2.9 MiB]                                                \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/graph.pbtxt...\n",
      "/ [9 files][  2.9 MiB/  3.2 MiB]                                                \r",
      "-\r",
      "- [10 files][  3.2 MiB/  3.2 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-1.data-00000-of-00001...\n",
      "- [10 files][  3.2 MiB/  6.7 MiB]                                               \r",
      "- [11 files][  6.7 MiB/  6.7 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-1.index...\n",
      "- [11 files][  6.7 MiB/  6.7 MiB]                                               \r",
      "- [12 files][  6.7 MiB/  6.7 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-1.meta...\n",
      "- [12 files][  6.7 MiB/  6.8 MiB]                                               \r",
      "\\\r",
      "\\ [13 files][  6.8 MiB/  6.8 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-10000.data-00000-of-00001...\n",
      "\\ [13 files][  6.8 MiB/ 10.2 MiB]                                               \r",
      "\\ [14 files][ 10.2 MiB/ 10.2 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-10000.index...\n",
      "\\ [14 files][ 10.2 MiB/ 10.2 MiB]                                               \r",
      "\\ [15 files][ 10.2 MiB/ 10.2 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-10000.meta...\n",
      "\\ [15 files][ 10.2 MiB/ 10.4 MiB]                                               \r",
      "|\r",
      "| [16 files][ 10.4 MiB/ 10.4 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-3931.data-00000-of-00001...\n",
      "| [16 files][ 10.4 MiB/ 13.8 MiB]                                               \r",
      "| [17 files][ 13.8 MiB/ 13.8 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-3931.index...\n",
      "| [17 files][ 13.8 MiB/ 13.8 MiB]                                               \r",
      "/\r",
      "/ [18 files][ 13.8 MiB/ 13.8 MiB]                                               \r",
      "Copying gs://qwiklabs-gcp-d1510d1177dc7fc8/mnist/trained_cnn/model.ckpt-3931.meta...\n",
      "/ [18 files][ 13.8 MiB/ 14.0 MiB]                                               \r",
      "/ [19 files][ 14.0 MiB/ 14.0 MiB]                                               \r\n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "\n",
      "Operation completed over 19 objects/14.0 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "## download model to local file system:\n",
    "\n",
    "## not:\n",
    "##inna-bckt-120695964d64ec72/mnist_dnn_dropout_190221_141035/9cf3b9b97d342bdc3693fa2db71bb3f23181dcebbe3abca3cb67b16374b7bcb8\n",
    "#gsutil cp -r gs://$BUCKET/mnist_dnn_dropout_190221_141035/9cf3b9b97d342bdc3693fa2db71bb3f23181dcebbe3abca3cb67b16374b7bcb8/* .\n",
    "\n",
    "# ## download DNN, hard-coded directory:\n",
    "# ##inna-bckt-120695964d64ec72/mnist/trained_dnn_dropout\n",
    "# gsutil cp -r gs://$BUCKET/mnist/trained_dnn_dropout .\n",
    "\n",
    "## download CNN:\n",
    "gsutil cp -r gs://$BUCKET/mnist/trained_${MODEL_TYPE} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 124\r\n",
      "-rw-r--r-- 1 root root 10305 Feb 22 07:48 flowers_fromscratch.ipynb\r\n",
      "drwxr-xr-x 2 root root  4096 Feb 22 07:48 \u001b[0m\u001b[01;34mflowersmodel\u001b[0m/\r\n",
      "drwxr-xr-x 3 root root  4096 Feb 22 08:31 \u001b[01;34mmnist\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 33824 Feb 22 07:48 mnist_linear.ipynb\r\n",
      "drwxr-xr-x 5 root root  4096 Feb 22 08:08 \u001b[01;34mmnistmodel\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root 46507 Feb 22 08:32 mnist_models.ipynb\r\n",
      "drwxr-xr-x 4 root root  4096 Feb 22 08:06 \u001b[01;34mmnist_trained\u001b[0m/\r\n",
      "-rw-r--r-- 1 root root  5234 Feb 22 08:31 test.json\r\n",
      "drwxr-xr-x 4 root root  4096 Feb 22 08:33 \u001b[01;34mtrained_cnn\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxr-xr-x 3 root root 4096 Feb 22 08:33 1550823092\n",
      "drwxr-xr-x 3 root root 4096 Feb 22 08:33 1550823202\n"
     ]
    }
   ],
   "source": [
    "%bash\n",
    "ls -l ./trained_${MODEL_TYPE}/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_cnn/export/exporter/1550823202\n"
     ]
    }
   ],
   "source": [
    "## find lates model on local disk:\n",
    "from pathlib import Path\n",
    "\n",
    "export_dir = 'trained_cnn/export/exporter'\n",
    "subdirs = [x for x in Path(export_dir).iterdir()\n",
    "           if x.is_dir() and 'temp' not in str(x)]\n",
    "latest = str(sorted(subdirs)[-1])\n",
    "\n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from b'trained_cnn/export/exporter/1550823202/variables/variables'\n",
      "{'classes': array([7, 2], dtype=uint8), 'probabilities': array([[0.0000000e+00, 3.2878167e-30, 1.2056782e-30, 0.0000000e+00,\n",
      "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
      "        0.0000000e+00, 5.3508532e-33],\n",
      "       [0.0000000e+00, 6.6826002e-27, 1.0000000e+00, 6.7902008e-32,\n",
      "        0.0000000e+00, 0.0000000e+00, 2.7345995e-38, 6.4616102e-31,\n",
      "        0.0000000e+00, 0.0000000e+00]], dtype=float32)}\n",
      "[7 2]\n"
     ]
    }
   ],
   "source": [
    "## load model from local disk and make predictions:\n",
    "from tensorflow.contrib import predictor\n",
    "\n",
    "predict_fn = predictor.from_saved_model(latest)\n",
    "\n",
    "pred = predict_fn({'image': mnist.test.images[0:2, :, :, 0]})\n",
    "print(pred)\n",
    "print(pred['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pred  correct\n",
      "0      7     7     True\n",
      "1      2     2     True\n",
      "2      1     1     True\n",
      "3      0     0     True\n",
      "4      4     4     True\n",
      "Accuracy =  0.9836\n",
      "\n",
      "\n",
      "Accuracy by label:\n",
      "        correct\n",
      "label          \n",
      "0      0.987755\n",
      "1      0.991189\n",
      "2      0.978682\n",
      "3      0.995050\n",
      "4      0.986762\n",
      "5      0.968610\n",
      "6      0.983299\n",
      "7      0.989300\n",
      "8      0.987680\n",
      "9      0.965312\n"
     ]
    }
   ],
   "source": [
    "## make pandas dataframe from predictions:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pred = predict_fn({'image': mnist.test.images[:, :, :, 0]})['classes']\n",
    "\n",
    "dat_pred = pd.DataFrame({'label': np.argmax(mnist.test.labels, axis = 1),\n",
    "                         'pred' : pred})\n",
    "dat_pred['correct'] = (dat_pred['label'] == dat_pred['pred'])\n",
    "print(dat_pred.head(n = 5))\n",
    "\n",
    "\n",
    "acc = dat_pred['correct'].mean()\n",
    "print('Accuracy = ', acc)\n",
    "\n",
    "print('\\n')\n",
    "print('Accuracy by label:')\n",
    "print(dat_pred.groupby(['label'])[['correct']].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "# Copyright 2017 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
